In computational complexity theory, Savitch's theorem, proved by Walter Savitch in 1970, gives a relationship between deterministic and non-deterministic space complexity.  It states that for any function 
  
    
      
        f
        ∈
        Ω
        (
        log
        ⁡
        (
        n
        )
        )
      
    
    {\displaystyle f\in \Omega (\log(n))}
  ,

  
    
      
        
          
            N
            S
            P
            A
            C
            E
          
        
        
          (
          
            f
            
              (
              n
              )
            
          
          )
        
        ⊆
        
          
            D
            S
            P
            A
            C
            E
          
        
        
          (
          
            f
            
              
                (
                n
                )
              
              
                2
              
            
          
          )
        
        .
      
    
    {\displaystyle {\mathsf {NSPACE}}\left(f\left(n\right)\right)\subseteq {\mathsf {DSPACE}}\left(f\left(n\right)^{2}\right).}
  In other words, if a nondeterministic Turing machine can solve a problem using 
  
    
      
        f
        (
        n
        )
      
    
    {\displaystyle f(n)}
   space, a deterministic Turing machine can solve the same problem in the square of that space bound.  Although it seems that nondeterminism may produce exponential gains in time (as formalized in the unproven exponential time hypothesis), Savitch's theorem shows that it has a markedly more limited effect on space requirements.

Proof
The proof relies on an algorithm for STCON, the problem of determining whether there is a path between two vertices in a directed graph, which runs in 
  
    
      
        O
        
          (
          
            (
            log
            ⁡
            n
            
              )
              
                2
              
            
          
          )
        
      
    
    {\displaystyle O\left((\log n)^{2}\right)}
   space for 
  
    
      
        n
      
    
    {\displaystyle n}
   vertices. The basic idea of the algorithm is to solve recursively a somewhat more general problem, testing the existence of a path from a vertex 
  
    
      
        s
      
    
    {\displaystyle s}
   to another vertex 
  
    
      
        t
      
    
    {\displaystyle t}
   that uses at most 
  
    
      
        k
      
    
    {\displaystyle k}
   edges, for a parameter 
  
    
      
        k
      
    
    {\displaystyle k}
   given as input. STCON is a special case of this problem where 
  
    
      
        k
      
    
    {\displaystyle k}
   is set large enough to impose no restriction on the paths (for instance, equal to the total number of vertices in the graph, or any larger value). To test for a 
  
    
      
        k
      
    
    {\displaystyle k}
  -edge path from 
  
    
      
        s
      
    
    {\displaystyle s}
   to 
  
    
      
        t
      
    
    {\displaystyle t}
  ,
a deterministic algorithm can iterate through all vertices 
  
    
      
        u
      
    
    {\displaystyle u}
  , and recursively search for paths of half the length from 
  
    
      
        s
      
    
    {\displaystyle s}
   to 
  
    
      
        u
      
    
    {\displaystyle u}
   and from 
  
    
      
        u
      
    
    {\displaystyle u}
   to 
  
    
      
        t
      
    
    {\displaystyle t}
  .
This algorithm can be expressed in pseudocode (in Python syntax) as follows:

Because each recursive call halves the parameter 
  
    
      
        k
      
    
    {\displaystyle k}
  , the number of levels of recursion is 
  
    
      
        ⌈
        
          log
          
            2
          
        
        ⁡
        n
        ⌉
      
    
    {\displaystyle \lceil \log _{2}n\rceil }
  . Each level requires 
  
    
      
        O
        (
        log
        ⁡
        n
        )
      
    
    {\displaystyle O(\log n)}
   bits of storage for its function arguments and local variables: 
  
    
      
        k
      
    
    {\displaystyle k}
   and the vertices 
  
    
      
        s
      
    
    {\displaystyle s}
  , 
  
    
      
        t
      
    
    {\displaystyle t}
  , and 
  
    
      
        u
      
    
    {\displaystyle u}
   require 
  
    
      
        ⌈
        
          log
          
            2
          
        
        ⁡
        n
        ⌉
      
    
    {\displaystyle \lceil \log _{2}n\rceil }
   bits each. The total auxiliary space complexity is thus 
  
    
      
        O
        
          (
          
            (
            log
            ⁡
            n
            
              )
              
                2
              
            
          
          )
        
      
    
    {\displaystyle O\left((\log n)^{2}\right)}
  . The input graph is considered to be represented in a separate read-only memory and does not contribute to this auxiliary space bound. Alternatively, it may be represented as an implicit graph. Although described above in the form of a program in a high-level language, the same algorithm may be implemented with the same asymptotic space bound on a Turing machine.
This algorithm can be applied to an implicit graph whose vertices represent the configurations of a nondeterministic Turing machine and its tape, running within a given space bound 
  
    
      
        f
        (
        n
        )
      
    
    {\displaystyle f(n)}
  . The edges of this graph represent the nondeterministic transitions of the machine, 
  
    
      
        s
      
    
    {\displaystyle s}
   is set to the initial configuration of the machine, and 
  
    
      
        t
      
    
    {\displaystyle t}
   is set to a special vertex representing all accepting halting states. In this case, the algorithm returns true when the machine has a nondeterministic accepting path, and false otherwise. The number of configurations in this graph is 
  
    
      
        O
        (
        
          2
          
            f
            (
            n
            )
          
        
        )
      
    
    {\displaystyle O(2^{f(n)})}
  , from which it follows that applying the algorithm to this implicit graph uses space 
  
    
      
        O
        (
        f
        (
        n
        
          )
          
            2
          
        
        )
      
    
    {\displaystyle O(f(n)^{2})}
  . Thus by deciding connectivity in a graph representing nondeterministic Turing machine configurations, one can decide membership in the language recognized by that machine, in space proportional to the square of the space used by the Turing machine.

Corollaries
Some important corollaries of the theorem include:

PSPACE = NPSPACE
That is, the languages that can be recognized by deterministic polynomial-space Turing machines and nondeterministic polynomial-space Turing machines are the same. This follows directly from the fact that the square of a polynomial function is still a polynomial function. It is believed that a similar relationship  does not exist between the polynomial time complexity classes, P and NP, although this is still an open question.
NL ⊆ L2
That is, all languages that can be solved nondeterministically in logarithmic space can be solved deterministically in the complexity class  This follows from the fact that STCON is NL-complete.

See also
Immerman–Szelepcsényi theorem – Closure of nondeterministic space under complementation

Notes
References
Arora, Sanjeev; Barak, Boaz (2009), Computational complexity. A modern approach, Cambridge University Press, ISBN 978-0-521-42426-4, Zbl 1193.68112
Papadimitriou, Christos (1993), "Section 7.3: The Reachability Method", Computational Complexity (1st ed.), Addison Wesley, pp. 149–150, ISBN 0-201-53082-1
Savitch, Walter J. (1970), "Relationships between nondeterministic and deterministic tape complexities", Journal of Computer and System Sciences, 4 (2): 177–192, doi:10.1016/S0022-0000(70)80006-X, hdl:10338.dmlcz/120475
Sipser, Michael (1997), "Section 8.1: Savitch's Theorem", Introduction to the Theory of Computation, PWS Publishing, pp. 279–281, ISBN 0-534-94728-X

External links
Lance Fortnow, Foundations of Complexity, Lesson 18: Savitch's Theorem. Accessed 09/09/09.
Richard J. Lipton, Savitch’s Theorem. Gives a historical account on how the proof was discovered.