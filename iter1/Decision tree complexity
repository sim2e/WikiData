In computational complexity the decision tree model is the model of computation in which an algorithm is considered to be basically a decision tree, i.e., a sequence of queries or tests that are done adaptively, so the outcome of previous tests can influence the tests performed next.
Typically, these tests have a small number of outcomes (such as a yes–no question) and can be performed quickly (say, with unit computational cost), so the worst-case time complexity of an algorithm in the decision tree model corresponds to the depth of the corresponding decision tree. This notion of computational complexity of a problem or an algorithm in the decision tree model is called its decision tree complexity or query complexity.
Decision trees models are instrumental in establishing lower bounds for complexity theory for certain classes of computational problems and algorithms. Several variants of decision tree models have been introduced, depending on the computational model and type of query algorithms are allowed to perform.
For example, a decision tree argument is used to show that a comparison sort of 
  
    
      
        n
      
    
    {\displaystyle n}
   items must take 
  
    
      
        n
        log
        ⁡
        (
        n
        )
      
    
    {\displaystyle n\log(n)}
   comparisons. For comparison sorts, a query is a comparison of two items 
  
    
      
        a
        ,
        
        b
      
    
    {\displaystyle a,\,b}
  , with two outcomes (assuming no items are equal): either 
  
    
      
        a
        <
        b
      
    
    {\displaystyle a<b}
   or 
  
    
      
        a
        >
        b
      
    
    {\displaystyle a>b}
  . Comparison sorts can be expressed as a decision tree in this model, since such sorting algorithms only perform these types of queries.

Comparison trees and lower bounds for sorting
Decision trees are often employed to understand algorithms for sorting and other similar problems; this was first done by Ford and Johnson.For example, many sorting algorithms are comparison sorts, which means that they only gain information about an input sequence 
  
    
      
        
          x
          
            1
          
        
        ,
        
          x
          
            2
          
        
        ,
        …
        ,
        
          x
          
            n
          
        
      
    
    {\displaystyle x_{1},x_{2},\ldots ,x_{n}}
   via local comparisons: testing whether 
  
    
      
        
          x
          
            i
          
        
        <
        
          x
          
            j
          
        
      
    
    {\displaystyle x_{i}<x_{j}}
  , 
  
    
      
        
          x
          
            i
          
        
        =
        
          x
          
            j
          
        
      
    
    {\displaystyle x_{i}=x_{j}}
  , or 
  
    
      
        
          x
          
            i
          
        
        >
        
          x
          
            j
          
        
      
    
    {\displaystyle x_{i}>x_{j}}
  . Assuming that the items to be sorted are all distinct and comparable, this can be rephrased as a yes-or-no question: is 
  
    
      
        
          x
          
            i
          
        
        >
        
          x
          
            j
          
        
      
    
    {\displaystyle x_{i}>x_{j}}
  ?
These algorithms can be modeled as binary decision trees, where the queries are comparisons: an internal node corresponds to a query, and the node's children correspond to the next query when the answer to the question is yes or no. For leaf nodes, the output corresponds to a permutation 
  
    
      
        π
      
    
    {\displaystyle \pi }
   that describes how the input sequence was scrambled from the fully ordered list of items. (The inverse of this permutation, 
  
    
      
        
          π
          
            −
            1
          
        
      
    
    {\displaystyle \pi ^{-1}}
  , re-orders the input sequence.)
One can show that comparison sorts must use 
  
    
      
        Ω
        (
        n
        log
        ⁡
        (
        n
        )
        )
      
    
    {\displaystyle \Omega (n\log(n))}
   comparisons through a simple argument: for an algorithm to be correct, it must be able to output every possible permutation of 
  
    
      
        n
      
    
    {\displaystyle n}
   elements; otherwise, the algorithm would fail for that particular permutation as input. So, its corresponding decision tree must have at least as many leaves as permutations: 
  
    
      
        n
        !
      
    
    {\displaystyle n!}
   leaves. Any binary tree with at least 
  
    
      
        n
        !
      
    
    {\displaystyle n!}
   leaves has depth at least 
  
    
      
        
          log
          
            2
          
        
        ⁡
        (
        n
        !
        )
        =
        Ω
        (
        n
        
          log
          
            2
          
        
        ⁡
        (
        n
        )
        )
      
    
    {\displaystyle \log _{2}(n!)=\Omega (n\log _{2}(n))}
  , so this is a lower bound on the run time of a comparison sorting algorithm. In this case, the existence of numerous comparison-sorting algorithms having this time complexity, such as mergesort and heapsort, demonstrates that the bound is tight.: 91 This argument does not use anything about the type of query, so it in fact proves a lower bound for any sorting algorithm that can be modeled as a binary decision tree. In essence, this is a rephrasing of the information-theoretic argument that a correct sorting algorithm must learn at least 
  
    
      
        
          log
          
            2
          
        
        ⁡
        (
        n
        !
        )
      
    
    {\displaystyle \log _{2}(n!)}
   bits of information about the input sequence. As a result, this also works for randomized decision trees as well.
Other decision tree lower bounds do use that the query is a comparison. For example, consider the task of only using comparisons to find the smallest number among 
  
    
      
        n
      
    
    {\displaystyle n}
   numbers. Before the smallest number can be determined, every number except the smallest must "lose" (compare greater) in at least one comparison. So, it takes at least 
  
    
      
        n
        −
        1
      
    
    {\displaystyle n-1}
   comparisons to find the minimum. (The information-theoretic argument here only gives a lower bound of 
  
    
      
        log
        ⁡
        (
        n
        )
      
    
    {\displaystyle \log(n)}
  .) A similar argument works for general lower bounds for computing order statistics.: 214

Linear and algebraic decision trees
Linear decision trees generalize the above comparison decision trees to computing functions that take real vectors 
  
    
      
        x
        ∈
        
          
            R
          
          
            n
          
        
      
    
    {\displaystyle x\in \mathbb {R} ^{n}}
   as input. The tests in linear decision trees are linear functions: for a particular choice of real numbers 
  
    
      
        
          a
          
            0
          
        
        ,
        …
        ,
        
          a
          
            n
          
        
      
    
    {\displaystyle a_{0},\dots ,a_{n}}
  , output the sign of 
  
    
      
        
          a
          
            0
          
        
        +
        
          
            ∑
            
              i
              =
              1
            
            
              n
            
          
          
            a
            
              i
            
          
          
            x
            
              i
            
          
        
      
    
    {\displaystyle a_{0}+\textstyle \sum _{i=1}^{n}a_{i}x_{i}}
  . (Algorithms in this model can only depend on the sign of the output.) Comparison trees are linear decision trees, because the comparison between 
  
    
      
        
          x
          
            i
          
        
      
    
    {\displaystyle x_{i}}
   and 
  
    
      
        
          x
          
            j
          
        
      
    
    {\displaystyle x_{j}}
   corresponds to the linear function 
  
    
      
        
          x
          
            i
          
        
        −
        
          x
          
            j
          
        
      
    
    {\displaystyle x_{i}-x_{j}}
  . From its definition, linear decision trees can only specify functions 
  
    
      
        f
      
    
    {\displaystyle f}
   whose fibers can be constructed by taking unions and intersections of half-spaces.
Algebraic decision trees are a generalization of linear decision trees that allow the test functions to be polynomials of degree 
  
    
      
        d
      
    
    {\displaystyle d}
  . Geometrically, the space is divided into semi-algebraic sets (a generalization of hyperplane).
These decision tree models, defined by Rabin and Reingold, are often used for proving lower bounds in computational geometry. For example, Ben-Or showed that element uniqueness (the task of computing 
  
    
      
        f
        :
        
          
            R
          
          
            n
          
        
        →
        {
        0
        ,
        1
        }
      
    
    {\displaystyle f:\mathbb {R} ^{n}\to \{0,1\}}
  , where 
  
    
      
        f
        (
        x
        )
      
    
    {\displaystyle f(x)}
   is 0 if and only if there exist distinct coordinates 
  
    
      
        i
        ,
        j
      
    
    {\displaystyle i,j}
   such that 
  
    
      
        
          x
          
            i
          
        
        =
        
          x
          
            j
          
        
      
    
    {\displaystyle x_{i}=x_{j}}
  ) requires an algebraic decision tree of depth 
  
    
      
        Ω
        (
        n
        log
        ⁡
        (
        n
        )
        )
      
    
    {\displaystyle \Omega (n\log(n))}
  . This was first showed for linear decision models by Dobkin and Lipton. They also show a 
  
    
      
        
          n
          
            2
          
        
      
    
    {\displaystyle n^{2}}
   lower bound for linear decision trees on the knapsack problem, generalized to algebraic decision trees by Steele and Yao.

Boolean decision tree complexities
For Boolean decision trees, the task is to compute the value of an n-bit Boolean function 
  
    
      
        f
        :
        {
        0
        ,
        1
        
          }
          
            n
          
        
        →
        {
        0
        ,
        1
        }
      
    
    {\displaystyle f:\{0,1\}^{n}\to \{0,1\}}
   for an input 
  
    
      
        x
        ∈
        {
        0
        ,
        1
        
          }
          
            n
          
        
      
    
    {\displaystyle x\in \{0,1\}^{n}}
  . The queries correspond to reading a bit of the input, 
  
    
      
        
          x
          
            i
          
        
      
    
    {\displaystyle x_{i}}
  , and the output is 
  
    
      
        f
        (
        x
        )
      
    
    {\displaystyle f(x)}
  . Each query may be dependent on previous queries. There are many types of computational models using decision trees that could be considered, admitting multiple complexity notions, called complexity measures.

Deterministic decision tree
If the output of a decision tree is 
  
    
      
        f
        (
        x
        )
      
    
    {\displaystyle f(x)}
  , for all 
  
    
      
        x
        ∈
        {
        0
        ,
        1
        
          }
          
            n
          
        
      
    
    {\displaystyle x\in \{0,1\}^{n}}
  , the decision tree is said to "compute" 
  
    
      
        f
      
    
    {\displaystyle f}
  . The depth of a tree is the maximum number of queries that can happen before a leaf is reached and a result obtained. 
  
    
      
        D
        (
        f
        )
      
    
    {\displaystyle D(f)}
  , the deterministic decision tree complexity of 
  
    
      
        f
      
    
    {\displaystyle f}
   is the smallest depth among all deterministic decision trees that compute 
  
    
      
        f
      
    
    {\displaystyle f}
  .

Randomized decision tree
One way to define a randomized decision tree is to add additional nodes to the tree, each controlled by a probability 
  
    
      
        
          p
          
            i
          
        
      
    
    {\displaystyle p_{i}}
  .  Another equivalent definition is to define it as a distribution over deterministic decision trees.  Based on this second definition, the complexity of the randomized tree is defined as the largest depth among all the trees in the support of the underlying distribution.  
  
    
      
        
          R
          
            2
          
        
        (
        f
        )
      
    
    {\displaystyle R_{2}(f)}
   is defined as the complexity of the lowest-depth randomized decision tree whose result is 
  
    
      
        f
        (
        x
        )
      
    
    {\displaystyle f(x)}
   with probability at least 
  
    
      
        2
        
          /
        
        3
      
    
    {\displaystyle 2/3}
   for all 
  
    
      
        x
        ∈
        {
        0
        ,
        1
        
          }
          
            n
          
        
      
    
    {\displaystyle x\in \{0,1\}^{n}}
   (i.e., with bounded 2-sided error).

  
    
      
        
          R
          
            2
          
        
        (
        f
        )
      
    
    {\displaystyle R_{2}(f)}
   is known as the Monte Carlo randomized decision-tree complexity, because the result is allowed to be incorrect with bounded two-sided error.  The Las Vegas decision-tree complexity 
  
    
      
        
          R
          
            0
          
        
        (
        f
        )
      
    
    {\displaystyle R_{0}(f)}
   measures the expected depth of a decision tree that must be correct (i.e., has zero-error).  There is also a one-sided bounded-error version which is denoted by 
  
    
      
        
          R
          
            1
          
        
        (
        f
        )
      
    
    {\displaystyle R_{1}(f)}
  .

Nondeterministic decision tree
The nondeterministic decision tree complexity of a function is known more commonly as the certificate complexity of that function. It measures the number of input bits that a nondeterministic algorithm would need to look at in order to evaluate the function with certainty.
Formally, the certificate complexity of 
  
    
      
        f
      
    
    {\displaystyle f}
   at 
  
    
      
        x
      
    
    {\displaystyle x}
   is the size of the smallest subset of indices 
  
    
      
        S
        ⊂
        [
        n
        ]
      
    
    {\displaystyle S\subset [n]}
   such that, for all 
  
    
      
        y
        ∈
        {
        0
        ,
        1
        
          }
          
            n
          
        
      
    
    {\displaystyle y\in \{0,1\}^{n}}
  , if 
  
    
      
        
          y
          
            i
          
        
        =
        
          x
          
            i
          
        
      
    
    {\displaystyle y_{i}=x_{i}}
   for all 
  
    
      
        i
        ∈
        S
      
    
    {\displaystyle i\in S}
  , then 
  
    
      
        f
        (
        y
        )
        =
        f
        (
        x
        )
      
    
    {\displaystyle f(y)=f(x)}
  . The certificate complexity of 
  
    
      
        f
      
    
    {\displaystyle f}
   is the maximum certificate complexity over all 
  
    
      
        x
      
    
    {\displaystyle x}
  . The analogous notion where one only requires the verifier to be correct with 2/3 probability is denoted 
  
    
      
        R
        C
        (
        f
        )
      
    
    {\displaystyle RC(f)}
  .

Quantum decision tree
The quantum decision tree complexity 
  
    
      
        
          Q
          
            2
          
        
        (
        f
        )
      
    
    {\displaystyle Q_{2}(f)}
   is the depth of the lowest-depth quantum decision tree that gives the result 
  
    
      
        f
        (
        x
        )
      
    
    {\displaystyle f(x)}
   with probability at least 
  
    
      
        2
        
          /
        
        3
      
    
    {\displaystyle 2/3}
   for all 
  
    
      
        x
        ∈
        {
        0
        ,
        1
        
          }
          
            n
          
        
      
    
    {\displaystyle x\in \{0,1\}^{n}}
  .  Another quantity, 
  
    
      
        
          Q
          
            E
          
        
        (
        f
        )
      
    
    {\displaystyle Q_{E}(f)}
  , is defined as the depth of the lowest-depth quantum decision tree that gives the result 
  
    
      
        f
        (
        x
        )
      
    
    {\displaystyle f(x)}
   with probability 1 in all cases (i.e. computes 
  
    
      
        f
      
    
    {\displaystyle f}
   exactly).  
  
    
      
        
          Q
          
            2
          
        
        (
        f
        )
      
    
    {\displaystyle Q_{2}(f)}
   and 
  
    
      
        
          Q
          
            E
          
        
        (
        f
        )
      
    
    {\displaystyle Q_{E}(f)}
   are more commonly known as quantum query complexities, because the direct definition of a quantum decision tree is more complicated than in the classical case. Similar to the randomized case, we define 
  
    
      
        
          Q
          
            0
          
        
        (
        f
        )
      
    
    {\displaystyle Q_{0}(f)}
   and 
  
    
      
        
          Q
          
            1
          
        
        (
        f
        )
      
    
    {\displaystyle Q_{1}(f)}
  .
These notions are typically bounded by the notions of degree and approximate degree. The degree of 
  
    
      
        f
      
    
    {\displaystyle f}
  , denoted 
  
    
      
        deg
        ⁡
        (
        f
        )
      
    
    {\displaystyle \deg(f)}
  , is the smallest degree of any polynomial 
  
    
      
        p
      
    
    {\displaystyle p}
   satisfying 
  
    
      
        f
        (
        x
        )
        =
        p
        (
        x
        )
      
    
    {\displaystyle f(x)=p(x)}
   for all 
  
    
      
        x
        ∈
        {
        0
        ,
        1
        
          }
          
            n
          
        
      
    
    {\displaystyle x\in \{0,1\}^{n}}
  . The approximate degree of 
  
    
      
        f
      
    
    {\displaystyle f}
  , denoted 
  
    
      
        
          
            
              deg
              ~
            
          
        
        (
        f
        )
      
    
    {\displaystyle {\widetilde {\deg }}(f)}
  , is the smallest degree of any polynomial 
  
    
      
        p
      
    
    {\displaystyle p}
   satisfying 
  
    
      
        p
        (
        x
        )
        ∈
        [
        0
        ,
        1
        
          /
        
        3
        ]
      
    
    {\displaystyle p(x)\in [0,1/3]}
   whenever 
  
    
      
        f
        (
        x
        )
        =
        0
      
    
    {\displaystyle f(x)=0}
   and 
  
    
      
        p
        (
        x
        )
        ∈
        [
        2
        
          /
        
        3
        ,
        1
        ]
      
    
    {\displaystyle p(x)\in [2/3,1]}
   whenever 
  
    
      
        f
        (
        x
        )
        =
        1
      
    
    {\displaystyle f(x)=1}
  .
Beals et al. established that 
  
    
      
        
          Q
          
            0
          
        
        (
        f
        )
        ≥
        deg
        ⁡
        (
        f
        )
        
          /
        
        2
      
    
    {\displaystyle Q_{0}(f)\geq \deg(f)/2}
   and 
  
    
      
        
          Q
          
            2
          
        
        (
        f
        )
        ≥
        
          
            
              deg
              ~
            
          
        
        (
        f
        )
        
          /
        
        2
      
    
    {\displaystyle Q_{2}(f)\geq {\widetilde {\deg }}(f)/2}
  .

Relationships between boolean function complexity measures
It follows immediately from the definitions that for all 
  
    
      
        n
      
    
    {\displaystyle n}
  -bit Boolean functions 
  
    
      
        f
      
    
    {\displaystyle f}
  ,
  
    
      
        
          Q
          
            2
          
        
        (
        f
        )
        ≤
        
          R
          
            2
          
        
        (
        f
        )
        ≤
        
          R
          
            1
          
        
        (
        f
        )
        ≤
        
          R
          
            0
          
        
        (
        f
        )
        ≤
        D
        (
        f
        )
        ≤
        n
      
    
    {\displaystyle Q_{2}(f)\leq R_{2}(f)\leq R_{1}(f)\leq R_{0}(f)\leq D(f)\leq n}
  , and 
  
    
      
        
          Q
          
            2
          
        
        (
        f
        )
        ≤
        
          Q
          
            0
          
        
        (
        f
        )
        ≤
        D
        (
        f
        )
        ≤
        n
      
    
    {\displaystyle Q_{2}(f)\leq Q_{0}(f)\leq D(f)\leq n}
  . Finding the best upper bounds in the converse direction is a major goal in the field of query complexity.
All of these types of query complexity are polynomially related. Blum and Impagliazzo, Hartmanis and Hemachandra, and Tardos independently discovered that 
  
    
      
        D
        (
        f
        )
        ≤
        
          R
          
            0
          
        
        (
        f
        
          )
          
            2
          
        
      
    
    {\displaystyle D(f)\leq R_{0}(f)^{2}}
  . Noam Nisan found that the Monte Carlo randomized decision tree complexity is also polynomially related to deterministic decision tree complexity: 
  
    
      
        D
        (
        f
        )
        =
        O
        (
        
          R
          
            2
          
        
        (
        f
        
          )
          
            3
          
        
        )
      
    
    {\displaystyle D(f)=O(R_{2}(f)^{3})}
  .  (Nisan also showed that 
  
    
      
        D
        (
        f
        )
        =
        O
        (
        
          R
          
            1
          
        
        (
        f
        
          )
          
            2
          
        
        )
      
    
    {\displaystyle D(f)=O(R_{1}(f)^{2})}
  .) A tighter relationship is known between the Monte Carlo and Las Vegas models: 
  
    
      
        
          R
          
            0
          
        
        (
        f
        )
        =
        O
        (
        
          R
          
            2
          
        
        (
        f
        
          )
          
            2
          
        
        log
        ⁡
        
          R
          
            2
          
        
        (
        f
        )
        )
      
    
    {\displaystyle R_{0}(f)=O(R_{2}(f)^{2}\log R_{2}(f))}
  . This relationship is optimal up to polylogarithmic factors. As for quantum decision tree complexities, 
  
    
      
        D
        (
        f
        )
        =
        O
        (
        
          Q
          
            2
          
        
        (
        f
        
          )
          
            4
          
        
        )
      
    
    {\displaystyle D(f)=O(Q_{2}(f)^{4})}
  , and this bound is tight. Midrijanis showed that 
  
    
      
        D
        (
        f
        )
        =
        O
        (
        
          Q
          
            0
          
        
        (
        f
        
          )
          
            3
          
        
        )
      
    
    {\displaystyle D(f)=O(Q_{0}(f)^{3})}
  , improving a quartic bound due to Beals et al.It is important to note that these polynomial relationships are valid only for total Boolean functions.  For partial Boolean functions, that have a domain a subset of 
  
    
      
        {
        0
        ,
        1
        
          }
          
            n
          
        
      
    
    {\displaystyle \{0,1\}^{n}}
  , an exponential separation between 
  
    
      
        
          Q
          
            0
          
        
        (
        f
        )
      
    
    {\displaystyle Q_{0}(f)}
   and 
  
    
      
        D
        (
        f
        )
      
    
    {\displaystyle D(f)}
   is possible; the first example of such a problem was discovered by Deutsch and Jozsa.

Sensitivity conjecture
For a Boolean function 
  
    
      
        f
        :
        {
        0
        ,
        1
        
          }
          
            n
          
        
        →
        {
        0
        ,
        1
        }
      
    
    {\displaystyle f:\{0,1\}^{n}\to \{0,1\}}
  , the sensitivity of 
  
    
      
        f
      
    
    {\displaystyle f}
   is defined to be the maximum sensitivity of 
  
    
      
        f
      
    
    {\displaystyle f}
   over all 
  
    
      
        x
      
    
    {\displaystyle x}
  , where the sensitivity of 
  
    
      
        f
      
    
    {\displaystyle f}
   at 
  
    
      
        x
      
    
    {\displaystyle x}
   is the number of single-bit changes in 
  
    
      
        x
      
    
    {\displaystyle x}
   that change the value of 
  
    
      
        f
        (
        x
        )
      
    
    {\displaystyle f(x)}
  . Sensitivity is related to the notion of total influence from the analysis of Boolean functions, which is equal to average sensitivity over all 
  
    
      
        x
      
    
    {\displaystyle x}
  .
The sensitivity conjecture is the conjecture that sensitivity is polynomially related to query complexity; that is, there exists exponent 
  
    
      
        c
        ,
        
          c
          ′
        
      
    
    {\displaystyle c,c'}
   such that, for all 
  
    
      
        f
      
    
    {\displaystyle f}
  , 
  
    
      
        D
        (
        f
        )
        =
        O
        (
        s
        (
        f
        
          )
          
            c
          
        
        )
      
    
    {\displaystyle D(f)=O(s(f)^{c})}
   and 
  
    
      
        s
        (
        f
        )
        =
        O
        (
        D
        (
        f
        
          )
          
            
              c
              ′
            
          
        
        )
      
    
    {\displaystyle s(f)=O(D(f)^{c'})}
  . One can show through a simple argument that 
  
    
      
        s
        (
        f
        )
        ≤
        D
        (
        f
        )
      
    
    {\displaystyle s(f)\leq D(f)}
  , so the conjecture is specifically concerned about finding a lower bound for sensitivity. Since all of the previously-discussed complexity measures are polynomially related, the precise type of complexity measure is not relevant. However, this is typically phrased as the question of relating sensitivity with block sensitivity.
The block sensitivity of 
  
    
      
        f
      
    
    {\displaystyle f}
  , denoted 
  
    
      
        b
        s
        (
        f
        )
      
    
    {\displaystyle bs(f)}
  , is defined to be the maximum block sensitivity of 
  
    
      
        f
      
    
    {\displaystyle f}
   over all 
  
    
      
        x
      
    
    {\displaystyle x}
  . The block sensitivity of 
  
    
      
        f
      
    
    {\displaystyle f}
   at 
  
    
      
        x
      
    
    {\displaystyle x}
   is the maximum number 
  
    
      
        t
      
    
    {\displaystyle t}
   of disjoint subsets 
  
    
      
        
          S
          
            1
          
        
        ,
        …
        ,
        
          S
          
            t
          
        
        ⊂
        [
        n
        ]
      
    
    {\displaystyle S_{1},\ldots ,S_{t}\subset [n]}
   such that, for any of the subsets 
  
    
      
        
          S
          
            i
          
        
      
    
    {\displaystyle S_{i}}
  , flipping the bits of 
  
    
      
        x
      
    
    {\displaystyle x}
   corresponding to 
  
    
      
        
          S
          
            i
          
        
      
    
    {\displaystyle S_{i}}
   changes the value of 
  
    
      
        f
        (
        x
        )
      
    
    {\displaystyle f(x)}
  .Since block sensitivity takes a maximum over more choices of subsets, 
  
    
      
        s
        (
        f
        )
        ≤
        b
        s
        (
        f
        )
      
    
    {\displaystyle s(f)\leq bs(f)}
  . Further, block sensitivity is polynomially related to the previously discussed complexity measures; for example, Nisan's paper introducing block-sensitivity showed that 
  
    
      
        b
        s
        (
        f
        )
        ≤
        D
        (
        f
        )
        =
        O
        (
        b
        s
        (
        f
        
          )
          
            4
          
        
        )
      
    
    {\displaystyle bs(f)\leq D(f)=O(bs(f)^{4})}
  . So, one could rephrase the sensitivity conjecture as showing that, for some 
  
    
      
        c
      
    
    {\displaystyle c}
  , 
  
    
      
        b
        s
        (
        f
        )
        =
        O
        (
        s
        (
        f
        
          )
          
            c
          
        
        )
      
    
    {\displaystyle bs(f)=O(s(f)^{c})}
  . In 1992, Nisan and Szegedy conjectured that 
  
    
      
        c
        =
        2
      
    
    {\displaystyle c=2}
   suffices. This would be tight, as Rubinstein in 1995 showed a quadratic separation between sensitivity and block sensitivity.In July 2019, 27 years after the conjecture was initially posed, Hao Huang from Emory University proved the sensitivity conjecture, showing that 
  
    
      
        b
        s
        (
        f
        )
        =
        O
        (
        s
        (
        f
        
          )
          
            4
          
        
        )
      
    
    {\displaystyle bs(f)=O(s(f)^{4})}
  . This proof is notably succinct, proving this statement in two pages when prior progress towards the sensitivity conjecture had been limited.

Summary of known results
This table summarizes results on separations between Boolean function complexity measures. The complexity measures are, in order, deterministic, zero-error randomized, two-sided-error randomized, certificate, randomized certificate, block sensitivity, sensitivity, exact quantum, degree, quantum, and approximate degree complexities.
The number in the 
  
    
      
        A
      
    
    {\displaystyle A}
  -th row and 
  
    
      
        B
      
    
    {\displaystyle B}
  -th column denotes bounds on the exponent 
  
    
      
        c
      
    
    {\displaystyle c}
  , which is the infimum of all 
  
    
      
        k
      
    
    {\displaystyle k}
   satisfying 
  
    
      
        A
        (
        f
        )
        =
        O
        (
        B
        (
        f
        
          )
          
            k
          
        
        )
      
    
    {\displaystyle A(f)=O(B(f)^{k})}
   for all boolean functions 
  
    
      
        f
      
    
    {\displaystyle f}
  . For example, the entry in the D-th row and s-th column is "3, 6", so 
  
    
      
        D
        (
        f
        )
        =
        O
        (
        s
        ⁡
        (
        f
        
          )
          
            6
            +
            o
            (
            1
            )
          
        
        )
      
    
    {\displaystyle D(f)=O(\operatorname {s} (f)^{6+o(1)})}
   for all 
  
    
      
        f
      
    
    {\displaystyle f}
  , and there exists a function 
  
    
      
        g
      
    
    {\displaystyle g}
   such that 
  
    
      
        D
        (
        g
        )
        =
        Ω
        (
        s
        ⁡
        (
        g
        
          )
          
            3
            −
            o
            (
            1
            )
          
        
        )
      
    
    {\displaystyle D(g)=\Omega (\operatorname {s} (g)^{3-o(1)})}
  .

See also
Comparison sort
Decision tree
Aanderaa–Karp–Rosenberg conjecture
Minimum spanning tree § Decision trees

References
Surveys
Buhrman, Harry; de Wolf, Ronald (2002), "Complexity Measures and Decision Tree Complexity: A Survey" (PDF), Theoretical Computer Science, 288 (1): 21–43, doi:10.1016/S0304-3975(01)00144-X