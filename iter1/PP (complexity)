In complexity theory, PP is the class of decision problems solvable by a probabilistic Turing machine in polynomial time, with an error probability of less than 1/2 for all instances. The abbreviation PP refers to probabilistic polynomial time. The complexity class was defined by Gill in 1977.
If a decision problem is in PP, then there is an algorithm for it that is allowed to flip coins and make random decisions. It is guaranteed to run in polynomial time. If the answer is YES, the algorithm will answer YES with probability more than 1/2. If the answer is NO, the algorithm will answer YES with probability less than 1/2. In more practical terms, it is the class of problems that can be solved to any fixed degree of accuracy by running a randomized, polynomial-time algorithm a sufficient (but bounded) number of times.
Turing machines that are polynomially-bound and probabilistic are characterized as PPT, which stands for probabilistic polynomial-time machines. This characterization of Turing machines does not require a bounded error probability. Hence, PP is the complexity class containing all problems solvable by a PPT machine with an error probability of less than 1/2.
An alternative characterization of PP is the set of problems that can be solved by a nondeterministic Turing machine in polynomial time where the acceptance condition is that a majority (more than half) of computation paths accept. Because of this some authors have suggested the alternative name Majority-P.

Definition
A language L is in PP if and only if there exists a probabilistic Turing machine M, such that

M runs for polynomial time on all inputs
For all x in L, M outputs 1 with probability strictly greater than 1/2
For all x not in L, M outputs 1 with probability strictly less than 1/2.Alternatively, PP can be defined using only deterministic Turing machines. A language L is in PP if and only if there exists a polynomial p and deterministic Turing machine M, such that

M runs for polynomial time on all inputs
For all x in L, the fraction of strings y of length p(|x|) which satisfy M(x,y) = 1 is greater than 1/2
For all x not in L, the fraction of strings y of length p(|x|) which satisfy M(x,y) = 1 is less than 1/2.In both definitions, "less than" can be changed to "less than or equal to" (see below), and the threshold 1/2 can be replaced by any fixed rational number in (0,1), without changing the class.

PP vs BPP
BPP is a subset of PP; it can be seen as the subset for which there are efficient probabilistic algorithms. The distinction is in the error probability that is allowed: in BPP, an algorithm must give correct answer (YES or NO) with probability exceeding some fixed constant c > 1/2, such as 2/3 or 501/1000. If this is the case, then we can run the algorithm a number of times and take a majority vote to achieve any desired probability of correctness less than 1, using the Chernoff bound. This number of repeats increases if c becomes closer to 1/2, but it does not depend on the input size n.
The important thing is that this constant c is not allowed to depend on the input. On the other hand, a PP algorithm is permitted to do something like the following:

On a YES instance, output YES with probability 1/2 + 1/2n, where n is the length of the input.
On a NO  instance, output YES with probability 1/2 − 1/2n.Because these two probabilities are so close together, especially for large n, even if we run it a large number of times it is very difficult to tell whether we are operating on a YES instance or a NO instance. Attempting to achieve a fixed desired probability level using a majority vote and the Chernoff bound requires a number of repetitions that is exponential in n.

PP compared to other complexity classes
PP includes BPP, since probabilistic algorithms described in the definition of BPP form a subset of those in the definition of PP.
PP also includes NP. To prove this, we show that the NP-complete satisfiability problem belongs to PP. Consider a probabilistic algorithm that, given a formula F(x1, x2, ..., xn) chooses an assignment x1, x2, ..., xn uniformly at random. Then, the algorithm checks if the assignment makes the formula F true. If yes, it outputs YES. Otherwise, it outputs YES with probability 
  
    
      
        
          
            1
            2
          
        
        −
        
          
            1
            
              2
              
                n
                +
                1
              
            
          
        
      
    
    {\displaystyle {\frac {1}{2}}-{\frac {1}{2^{n+1}}}}
   and NO with probability 
  
    
      
        
          
            1
            2
          
        
        +
        
          
            1
            
              2
              
                n
                +
                1
              
            
          
        
      
    
    {\displaystyle {\frac {1}{2}}+{\frac {1}{2^{n+1}}}}
  .
If the formula is unsatisfiable, the algorithm will always output YES with probability 
  
    
      
        
          
            1
            2
          
        
        −
        
          
            1
            
              2
              
                n
                +
                1
              
            
          
        
        <
        
          
            1
            2
          
        
      
    
    {\displaystyle {\frac {1}{2}}-{\frac {1}{2^{n+1}}}<{\frac {1}{2}}}
  . If there exists a satisfying assignment, it will output YES with probability at least

  
    
      
        
          (
          
            
              
                1
                2
              
            
            −
            
              
                1
                
                  2
                  
                    n
                    +
                    1
                  
                
              
            
          
          )
        
        ⋅
        
          (
          
            1
            −
            
              
                1
                
                  2
                  
                    n
                  
                
              
            
          
          )
        
        +
        1
        ⋅
        
          
            1
            
              2
              
                n
              
            
          
        
        =
        
          
            1
            2
          
        
        +
        
          
            1
            
              2
              
                2
                n
                +
                1
              
            
          
        
        >
        
          
            1
            2
          
        
      
    
    {\displaystyle \left({\frac {1}{2}}-{\frac {1}{2^{n+1}}}\right)\cdot \left(1-{\frac {1}{2^{n}}}\right)+1\cdot {\frac {1}{2^{n}}}={\frac {1}{2}}+{\frac {1}{2^{2n+1}}}>{\frac {1}{2}}}
  
(exactly 1/2 if it picked an unsatisfying assignment and 1 if it picked a satisfying assignment, averaging to some number greater than 1/2). Thus, this algorithm puts satisfiability in PP. As SAT is NP-complete, and we can prefix any deterministic polynomial-time many-one reduction onto the PP algorithm, NP is included in PP. Because PP is closed under complement, it also includes co-NP.
Furthermore, PP includes MA, which subsumes the previous two inclusions.
PP also includes BQP, the class of decision problems solvable by efficient polynomial time quantum computers. In fact, BQP is low for PP, meaning that a PP machine achieves no benefit from being able to solve BQP problems instantly. The class of polynomial time on quantum computers with postselection, PostBQP, is equal to PP (see #PostBQP below).
Furthermore, PP includes QMA, which subsumes inclusions of MA and BQP.
A polynomial time Turing machine with a PP oracle (PPP) can solve all problems in  PH, the entire polynomial hierarchy. This result was shown by Seinosuke Toda in 1989 and is known as Toda's theorem. This is evidence of how hard it is to solve problems in PP. The class #P is in some sense about as hard, since P#P = PPP and therefore P#P includes PH as well.
PP strictly includes TC0, the class of constant-depth, unbounded-fan-in uniform boolean circuits with majority gates. (Allender 1996, as cited in Burtschick 1999).
PP is included in PSPACE. This can be easily shown by exhibiting a polynomial-space algorithm for MAJSAT, defined below; simply try all assignments and count the number of satisfying ones.
PP is not included in SIZE(nk) for any k (proof).

Complete problems and other properties
Unlike BPP, PP is a syntactic, rather than semantic class. Any polynomial-time probabilistic machine recognizes some language in PP. In contrast, given a description of a polynomial-time probabilistic machine, it is undecidable in general to determine if it recognizes a language in BPP.
PP has natural complete problems, for example, MAJSAT. MAJSAT is a decision problem in which one is given a Boolean formula F. The answer must be YES if more than half of all assignments x1, x2, ..., xn make F true and NO otherwise.

Proof that PP is closed under complement
Let L be a language in PP. Let 
  
    
      
        
          L
          
            c
          
        
      
    
    {\displaystyle L^{c}}
   denote the complement of L. By the definition of PP there is a polynomial-time probabilistic algorithm A with the property that 

  
    
      
        x
        ∈
        L
        ⇒
        Pr
        [
        A
        
           accepts 
        
        x
        ]
        >
        
          
            1
            2
          
        
        
        
          and
        
        
        x
        ∉
        L
        ⇒
        Pr
        [
        A
        
           accepts 
        
        x
        ]
        ≤
        
          
            1
            2
          
        
        .
      
    
    {\displaystyle x\in L\Rightarrow \Pr[A{\text{ accepts }}x]>{\frac {1}{2}}\quad {\text{and}}\quad x\not \in L\Rightarrow \Pr[A{\text{ accepts }}x]\leq {\frac {1}{2}}.}
  We claim that without loss of generality, the latter inequality is always strict; the theorem can be deduced from this claim: let 
  
    
      
        
          A
          
            c
          
        
      
    
    {\displaystyle A^{c}}
   denote the machine which is the same as A except that 
  
    
      
        
          A
          
            c
          
        
      
    
    {\displaystyle A^{c}}
   accepts when A would reject, and vice versa. Then 

  
    
      
        x
        ∈
        
          L
          
            c
          
        
        ⇒
        Pr
        [
        
          A
          
            c
          
        
        
           accepts 
        
        x
        ]
        >
        
          
            1
            2
          
        
        
        
          and
        
        
        x
        ∉
        
          L
          
            c
          
        
        ⇒
        Pr
        [
        
          A
          
            c
          
        
        
           accepts 
        
        x
        ]
        <
        
          
            1
            2
          
        
        ,
      
    
    {\displaystyle x\in L^{c}\Rightarrow \Pr[A^{c}{\text{ accepts }}x]>{\frac {1}{2}}\quad {\text{and}}\quad x\not \in L^{c}\Rightarrow \Pr[A^{c}{\text{ accepts }}x]<{\frac {1}{2}},}
  which implies that 
  
    
      
        
          L
          
            c
          
        
      
    
    {\displaystyle L^{c}}
   is in PP.
Now we justify our without loss of generality assumption. Let 
  
    
      
        f
        (
        
          |
        
        x
        
          |
        
        )
      
    
    {\displaystyle f(|x|)}
   be the polynomial upper bound on the running time of A on input x. Thus A makes at most 
  
    
      
        f
        (
        
          |
        
        x
        
          |
        
        )
      
    
    {\displaystyle f(|x|)}
   random coin flips during its execution. In particular the probability of acceptance is an integer multiple of 
  
    
      
        
          2
          
            −
            f
            (
            
              |
            
            x
            
              |
            
            )
          
        
      
    
    {\displaystyle 2^{-f(|x|)}}
   and we have:

  
    
      
        x
        ∈
        L
        ⇒
        Pr
        [
        A
        
           accepts 
        
        x
        ]
        ≥
        
          
            1
            2
          
        
        +
        
          
            1
            
              2
              
                f
                (
                
                  |
                
                x
                
                  |
                
                )
              
            
          
        
        .
      
    
    {\displaystyle x\in L\Rightarrow \Pr[A{\text{ accepts }}x]\geq {\frac {1}{2}}+{\frac {1}{2^{f(|x|)}}}.}
  Define a machine A′ as follows: on input x, A′ runs A as a subroutine, and rejects if A would reject; otherwise, if A would accept, A′ flips 
  
    
      
        f
        (
        
          |
        
        x
        
          |
        
        )
        +
        1
      
    
    {\displaystyle f(|x|)+1}
   coins and rejects if they are all heads, and accepts otherwise. Then 

  
    
      
        x
        ∉
        L
        ⇒
        Pr
        [
        
          A
          ′
        
        
           accepts 
        
        x
        ]
        ≤
        
          
            1
            2
          
        
        ⋅
        
          (
          
            1
            −
            
              
                1
                
                  2
                  
                    f
                    (
                    
                      |
                    
                    x
                    
                      |
                    
                    )
                    +
                    1
                  
                
              
            
          
          )
        
        <
        
          
            1
            2
          
        
        
        
          and
        
        
        x
        ∈
        L
        ⇒
        Pr
        [
        
          A
          ′
        
        
           accepts 
        
        x
        ]
        ≥
        
          (
          
            
              
                1
                2
              
            
            +
            
              
                1
                
                  2
                  
                    f
                    (
                    
                      |
                    
                    x
                    
                      |
                    
                    )
                  
                
              
            
          
          )
        
        ⋅
        
          (
          
            1
            −
            
              
                1
                
                  2
                  
                    f
                    (
                    
                      |
                    
                    x
                    
                      |
                    
                    )
                    +
                    1
                  
                
              
            
          
          )
        
        >
        
          
            1
            2
          
        
        .
      
    
    {\displaystyle x\not \in L\Rightarrow \Pr[A'{\text{ accepts }}x]\leq {\frac {1}{2}}\cdot \left(1-{\frac {1}{2^{f(|x|)+1}}}\right)<{\frac {1}{2}}\quad {\text{and}}\quad x\in L\Rightarrow \Pr[A'{\text{ accepts }}x]\geq \left({\frac {1}{2}}+{\frac {1}{2^{f(|x|)}}}\right)\cdot \left(1-{\frac {1}{2^{f(|x|)+1}}}\right)>{\frac {1}{2}}.}
  This justifies the assumption (since A′ is still a polynomial-time probabilistic algorithm) and completes the proof.
David Russo proved in his 1985 Ph.D. thesis that PP is closed under symmetric difference. It was an open problem for 14 years whether PP was closed under union and intersection; this was settled in the affirmative by Beigel, Reingold, and Spielman. Alternate proofs were later given by Li and Aaronson (see #PostBQP below).

Other equivalent complexity classes
PostBQP
The quantum complexity class BQP is the class of problems solvable in polynomial time on a quantum Turing machine. By adding postselection, a larger class called PostBQP is obtained. Informally, postselection gives the computer the following power: whenever some event (such as measuring a qubit in a certain state) has nonzero probability, you are allowed to assume that it takes place. Scott Aaronson showed in 2004 that PostBQP is equal to PP. This reformulation of PP makes it easier to show certain results, such as that PP is closed under intersection (and hence, under union), that BQP is low for PP, and that QMA is included in PP.

PQP
PP is also equal to another quantum complexity class known as PQP, which is the unbounded error analog of BQP. It denotes the class of decision problems solvable by a quantum computer in polynomial time, with an error probability of less than 1/2 for all instances. Even if all amplitudes used for PQP-computation are drawn from algebraic numbers, still PQP coincides with PP.

Notes
References
Papadimitriou, C. (1994). "chapter 11". Computational Complexity. Addison-Wesley..
Allender, E. (1996). "A note on uniform circuit lower bounds for the counting hierarchy". Proceedings 2nd International Computing and Combinatorics Conference (COCOON). Lecture Notes in Computer Science. Vol. 1090. Springer-Verlag. pp. 127–135..
Burtschick, Hans-Jörg; Vollmer, Heribert (1999). "Lindström Quantifiers and Leaf Language Definability". ECCC TR96-005. {{cite journal}}: Cite journal requires |journal= (help).

External links
Complexity Zoo: PP