Falsifiability is a deductive standard of evaluation of scientific theories and hypotheses, introduced by the philosopher of science Karl Popper in his book The Logic of Scientific Discovery (1934). A theory or hypothesis is falsifiable (or refutable) if it can be logically contradicted by an empirical test.
Popper proposed falsifiability as the cornerstone solution to both the problem of induction and the problem of demarcation. He insisted that, as a logical criterion, falsifiability is distinct from the related concept "capacity to be proven wrong" discussed in Lakatos's falsificationism.  Even being a logical criterion, its purpose is to make the theory predictive and testable, and thus useful in practice.
Popper contrasted falsifiability to the intuitively similar concept of verifiability that was then current in logical positivism. He argues that the only way to verify a claim such as "All swans are white" would be if one could theoretically observe all swans, which is not possible. Instead, falsifiability searches for the anomalous instance, such that observing a single black swan is theoretically reasonable and sufficient to logically falsify the claim. On the other hand, the Duhem–Quine thesis says that definitive experimental falsifications are impossible and that no scientific hypothesis is by itself capable of making predictions, because an empirical test of the hypothesis requires one or more background assumptions.According to Popper there is a clean asymmetry on the logical side and falsifiability does not have the Duhem problem because it is a logical criterion. Experimental research has the Duhem problem and other problems, such as induction, but, according to Popper, statistical tests, which are only possible when a theory is falsifiable, can still be useful within a critical discussion.   Philosophers such as Deborah Mayo consider that Popper "comes up short" in his description of the scientific role of statistical and data models.As a key notion in the separation of science from non-science and pseudoscience, falsifiability has featured prominently in many scientific controversies and applications, even being used as legal precedent.

The problem of induction and demarcation
One of the questions in the scientific method is: how does one move from observations to scientific laws? This is the problem of induction. Suppose we want to put the hypothesis that all swans are white to the test. We come across a white swan. We cannot validly argue (or induce) from "here is a white swan" to "all swans are white"; doing so would require a logical fallacy such as, for example, affirming the consequent.Popper's idea to solve this problem is that while it is impossible to verify that every swan is white, finding a single black swan shows that not every swan is white. We might tentatively accept the proposal that every swan is white, while looking out for examples of non-white swans that would show our conjecture to be false. Falsification uses the valid inference modus tollens: if from a law 
  
    
      
        L
      
    
    {\displaystyle L}
    we logically deduce 
  
    
      
        Q
      
    
    {\displaystyle Q}
  , but what is observed is 
  
    
      
        ¬
        Q
      
    
    {\displaystyle \neg Q}
  , we infer that the law 
  
    
      
        L
      
    
    {\displaystyle L}
   is false. For example, given the statement  
  
    
      
        L
        =
      
    
    {\displaystyle L=}
   "all swans are white", we can deduce 
  
    
      
        Q
        =
      
    
    {\displaystyle Q=}
   "the specific swan here is white", but if what is observed is 
  
    
      
        ¬
        Q
        =
      
    
    {\displaystyle \neg Q=}
   "the specific swan here is not white" (say black), then "all swans are white" is false. More accurately, the statement 
  
    
      
        Q
      
    
    {\displaystyle Q}
   that can be deduced is broken into an initial condition and a prediction as in 
  
    
      
        C
        ⇒
        P
      
    
    {\displaystyle C\Rightarrow P}
   in which 
  
    
      
        C
        =
      
    
    {\displaystyle C=}
   "the thing here is a swan" and 
  
    
      
        P
        =
      
    
    {\displaystyle P=}
   "the thing here is a white swan". If what is observed is C being true while P is false (formally, 
  
    
      
        C
        ∧
        ¬
        P
      
    
    {\displaystyle C\wedge \neg P}
  ), we can infer that the law is false.  
For Popper, induction is actually never needed in science. Instead, in Popper's view, laws are conjectured in a non-logical manner on the basis of expectations and predispositions. This has led David Miller, a student and collaborator of Popper, to write "the mission is to classify truths, not to certify them". In contrast, the logical empiricism movement, which included such philosophers as Moritz Schlick, Rudolf Carnap, Otto Neurath, and A.J. Ayer wanted to formalize the idea that, for a law to be scientific, it must be possible to argue on the basis of observations either in favor of its truth or its falsity. There was no consensus among these philosophers about how to achieve that, but the thought expressed by Mach's dictum that "where neither confirmation nor refutation is possible, science is not concerned" was accepted as a basic precept of critical reflection about science.Popper said that a demarcation criterion was possible, but we have to use the logical possibility of falsifications, which is falsifiability. He cited his encounter with psychoanalysis in the 1910s. It did not matter what observation was presented, psychoanalysis could explain it. Unfortunately, the reason it could explain everything is that it did not exclude anything also. For Popper, this was a failure, because it meant that it could not make any prediction. From a logical standpoint, if one finds an observation that does not contradict a law, it does not mean that the law is true. A verification has no value in itself. But, if the law makes risky predictions and these are corroborated, Popper says, there is a reason to prefer this law over another law that makes less risky predictions or no predictions at all. In the definition of falsifiability, contradictions with observations are not used to support eventual falsifications, but for logical "falsifications" that show that the law makes risky predictions, which is completely different.
On the basic philosophical side of this issue, Popper said that some philosophers of the Vienna Circle had mixed two different problems, that of meaning and that of demarcation, and had proposed in verificationism a single solution to both: a statement that could not be verified was considered meaningless. In opposition to this view, Popper said that there are meaningful theories that are not scientific, and that, accordingly, a criterion of meaningfulness does not coincide with a criterion of demarcation.

From Hume's problem to non problematic induction
The problem of induction is often called Hume's problem. David Hume studied how human beings obtain new knowledge that goes beyond known laws and observations, including how we can discover new laws.  He understood that deductive logic could not explain this learning process and argued in favour of a mental or psychological process of learning that would not require deductive logic. He even argued that this learning process cannot be justified by any general rules, deductive or not.  Popper accepted Hume's argument and therefore viewed progress in science as the result of quasi-induction, which does the same as induction, but has no inference rules to justify it.  Philip N. Johnson-Laird, professor of psychology, also accepted Hume's conclusion that induction has no justification. For him induction does not require justification and therefore can exist in the same manner as Popper's quasi-induction does.When Johnson-Laird says that no justification is needed, he does not refer to a general method of justification that, to avoid a circular reasoning, would not itself require any justification. On the contrary, in agreement with Hume, he refers to the fact that there is no general method of justification for induction and that's ok, because the induction steps do not require justification.  Instead, these steps use patterns of induction that may or may not be applicable depending on the background knowledge. Johnson-Laird wrote:  "[P]hilosophers have worried about which properties of objects warrant inductive inferences. The answer rests on knowledge: we don't infer that all the passengers on a plane are male because the first ten off the plane are men. We know that this observation doesn't rule out the possibility of a woman passenger." The reasoning pattern that was not applied here is enumerative induction.
Popper was interested in the overall learning process in science, to quasi-induction, which he also called the "path of science". However, Popper did not show much interest in these reasoning patterns, which he globally referred to as psychologism. He did not deny the possibility of some kind of psychological explanation for the learning process, especially when psychology is seen as an extension of biology, but he felt that these biological explanations were not within the scope of epistemology. Popper proposed an evolutionary mechanism to explain the success of science, which is much in line with Johnson-Laird's view that "induction is just something that animals, including human beings, do to make life possible", but Popper did not consider it a part of his epistemology. He wrote that his interest was mainly in the logic of science and that epistemology should be concerned with logical aspects only. Instead of asking why science succeeds he considered the pragmatic problem of induction. This problem is not how to justify a theory or what is the global mechanism for the success of science but only what methodology do we use to pick one theory among theories that are already conjectured. His methodological answer to the latter question is that we pick the theory that is the most tested with the available technology: "the one, which in the light of our critical discussion, appears to be the best so far". By his own account, because only a negative approach was supported by logic, Popper adopted a negative methodology. The purpose of his methodology is to prevent "the policy of immunizing our theories against refutation". It also supports some "dogmatic attitude" in defending theories against criticism, because this allows the process to be more complete. This negative view of science was much criticized and not only by Johnson-Laird.
In practice, some steps based on observations can be justified under assumptions, which can be very natural.  For example, Bayesian inductive logic is justified by theorems that make explicit assumptions. These theorems are obtained with deductive logic, not inductive logic. They are sometimes presented as steps of induction, because they refer to laws of probability, even though they do not go beyond deductive logic. This is yet a third notion of induction, which overlap with deductive logic in the following sense that it is supported by it. These deductive steps are not really inductive, but the overall process that includes the creation of assumptions is inductive in the usual sense. In a fallibilism perspective, a perspective that is widely accepted by philosophers, including Popper, every learning step only creates or reinforces an assumption—that is all what science does.

Basic statements and the definition of falsifiability
Popper distinguished between the logic of science and its applied methodology. For example, Newton's law of gravitation is falsifiable—it is falsified by "The brick fell upwards when released".  An explanation for this imaginary state of affairs such as some hidden force other than gravity acting on the brick would make it more intuitive, but is not needed for falsifiability, because it is a logical criterion. The empirical requirement on the potential falsifier, also called the material requirement, is only that it is observable inter-subjectively with existing technologies. The logical part consists of theories, statements and their purely logical relationship together with this material requirement, which is needed for a connection with the methodological part.
The methodological part consists, in Popper's view, of informal rules, which are used to guess theories, accept observation statements as factual, etc. These include statistical tests: Popper is aware that observation statements are accepted with the help of statistical methods and that these involve methodological decisions.  When this distinction is applied to the term "falsifiability", it corresponds to a distinction between two completely different meanings of the term. The same is true for the term "falsifiable". Popper said that he only uses "falsifiability" or "falsifiable" in reference to the logical side and that, when he refers to the methodological side, he speaks instead of "falsification" and its problems.Popper said that methodological problems require proposing methodological rules. For example, one such rule is that, if one refuses to go along with falsifications, then one has retired oneself from the game of science. The logical side does not have such methodological problems, in particular with regard to the falsifiability of a theory, because basic statements are not required to be possible. Methodological rules are only needed in the context of actual falsifications.
So observations have two purposes in Popper's view. On the methodological side, observations can be used to show that a law is false, which Popper calls falsification. On the logical side, observations, which are purely logical constructions, do not show a law to be false, but contradict a law to show its falsifiability. Unlike falsifications and free from the problems of falsification, these contradictions establish the value of the law, which may eventually be corroborated. He wrote that an entire literature exists because this distinction was not observed.

Basic statements
In Popper's view of science, statements of observation can be analyzed within a logical structure independently of any factual observations. The set of all purely logical observations that are considered constitutes the empirical basis. Popper calls them the basic statements or test statements. They are the statements that can be used to show the falsifiability of a theory. Popper says that basic statements do not have to be possible in practice. It is sufficient that they are accepted by convention as belonging to the empirical language, a language that allows intersubjective verifiability: "they must be testable by intersubjective observation (the material requirement)". See the examples in section § Examples of demarcation and applications.
In more than twelve pages of The Logic of Scientific Discovery, Popper discusses informally which statements among those that are considered in the logical structure are basic statements. A logical structure uses universal classes to define laws. For example, in the law "all swans are white" the concept of swans is a universal class. It corresponds to a set of properties that every swan must have. It is not restricted to the swans that exist, existed or will exist. Informally, a basic statement is simply a statement that concerns only a finite number of specific instances in universal classes. In particular, an existential statement such as "there exists a black swan" is not a basic statement, because it is not specific about the instance. On the other hand, "this swan here is black" is a basic statement. Popper says that it is a singular existential statement or simply a singular statement. So, basic statements are singular (existential) statements.

The definition of falsifiability
Thornton says that basic statements are statements that correspond to particular "observation-reports". He then gives Popper's definition of falsifiability:

"A theory is scientific if and only if it divides the class of basic statements into the following two non-empty sub-classes: (a) the class of all those basic statements with which it is inconsistent, or which it prohibits—this is the class of its potential falsifiers (i.e., those statements which, if true, falsify the whole theory), and (b) the class of those basic statements with which it is consistent, or which it permits (i.e., those statements which, if true, corroborate it, or bear it out)."
As in the case of actual falsifiers, decisions must be taken by scientists to accept a logical structure and its associated empirical basis, but these are usually part of a background knowledge that scientists have in common and, often, no discussion is even necessary. The first decision described by Lakatos is implicit in this agreement, but the other decisions are not needed. This agreement, if one can speak of agreement when there is not even a discussion, exists only in principle. This is where the distinction between the logical and methodological sides of science becomes important. When an actual falsifier is proposed, the technology used is considered in detail and, as described in section § Dogmatic falsificationism, an actual agreement is needed. This may require using a deeper empirical basis, hidden within the current empirical basis, to make sure that the properties or values used in the falsifier were obtained correctly (Andersson 2016 gives some examples).
Popper says that despite the fact that the empirical basis can be shaky, more comparable to a swamp than to solid ground, the definition that is given above is simply the formalization of a natural requirement on scientific theories, without which the whole logical process of science would not be possible.

Initial condition and prediction in falsifiers of laws
In his analysis of the scientific nature of universal laws, Popper arrived at the conclusion that laws must "allow us to deduce, roughly speaking, more empirical singular statements than we can deduce from the initial conditions alone."  A singular statement that has one part only cannot contradict a universal law. A falsifier of a law has always two parts: the initial condition and the singular statement that contradicts the prediction.
However, there is no need to require that falsifiers have two parts in the definition itself.  This removes the requirement that a falsifiable statement must make prediction. In this way, the definition is more general and allows the basic statements themselves to be falsifiable.  Criteria that require that a law must be predictive, just as is required by falsifiability (when applied to laws), Popper wrote, "have been put forward as criteria of the meaningfulness of sentences (rather than as criteria of demarcation applicable to theoretical systems) again and again after the publication of my book, even by critics who pooh-poohed my criterion of falsifiability."

Falsifiability in model theory
Scientists such as the Nobel laureate Herbert A. Simon have studied the semantic aspects of the logical side of falsifiability. These studies were done in the perspective that a logic is a relation between formal sentences in languages and a collection of mathematical structures. The relation, usually denoted 
  
    
      
        
          
            A
          
        
        ⊨
        ϕ
      
    
    {\displaystyle {\mathfrak {A}}\models \phi }
  , says the formal sentence 
  
    
      
        ϕ
      
    
    {\displaystyle \phi }
   is true when interpreted in the structure 
  
    
      
        
          
            A
          
        
      
    
    {\displaystyle {\mathfrak {A}}}
  —it provides the semantic of the languages. According to Rynasiewicz, in this semantic perspective, falsifiability as defined by Popper means that in some observation structure (in the collection) there exists a set of observations which refutes the theory. An even stronger notion of falsifiability was considered, which requires, not only that there exists one structure with a contradicting set of observations, but also that all structures in the collection that cannot be expanded to a structure that satisfies 
  
    
      
        ϕ
      
    
    {\displaystyle \phi }
   contain such a contradicting set of observations.

Examples of demarcation and applications
Newton's theory
In response to Lakatos who suggested that Newton's theory was as hard to show falsifiable as Freud's psychoanalytic theory, Popper gave the example of an apple that moves from the ground up to a branch and then starts to dance from one branch to another. It is clearly impossible, yet a basic statement that is a valid potential falsifier for Newton's theory, because the position of the apple at different times can be measured.

Einstein's equivalence principle
Another example of a basic statement is "The inert mass of this object is ten times larger than its gravitational mass." This is a basic statement because the inert mass and the gravitational mass can both be measured separately, even though it never happens that they are different. It is, as described by Popper, a valid falsifier for Einstein's equivalence principle.

Evolution
Industrial melanism
In a discussion of the theory of evolution, Popper mentioned industrial melanism as an example of a falsifiable law.  A corresponding basic statement that acts as a potential falsifier is "In this industrial area, the relative fitness of the white-bodied peppered moth is high." Here "fitness" means "reproductive success over the next generation". It is a basic statement, because it is possible to separately determine the kind of environment, industrial vs natural, and the relative fitness of the white-bodied form (relative to the black-bodied form) in an area, even though it never happens that the white-bodied form has a high relative fitness in an industrial area.

Precambrian rabbit
A famous example of a basic statement from J. B. S. Haldane is "[These are] fossil rabbits in the Precambrian era." This is a basic statement because it is possible to find a fossil rabbit and to determine that the date of a fossil is in the Precambrian era, even though it never happens that the date of a rabbit fossil is in the Precambrian era. Despite opinions to the contrary, sometimes wrongly attributed to Popper, this shows the scientific character of paleontology or the history of the evolution of life on Earth, because it contradicts the hypothesis in paleontology that all mammals existed in a much more recent era. Richard Dawkins adds that any other modern animal, such as a hippo, would suffice.

Simple examples of unfalsifiable statements
A simple example of a non-basic statement is "This angel does not have large wings." It is not a basic statement, because though the absence of large wings can be observed, no technology (independent of the presence of wings) exists to identify angels. Even if it is accepted that angels exist, the sentence "All angels have large wings" is not falsifiable.
Another example from Popper of a non-basic statement is "This human action is altruistic." It is not a basic statement, because no accepted technology allows us to determine whether or not an action is motivated by self-interest. Because no basic statement falsifies it, the statement that "All human actions are egotistic, motivated by self-interest" is thus not falsifiable.

Omphalos hypothesis
Some adherents of young-Earth creationism make an argument (called the Omphalos hypothesis after the Greek word for navel) that the world was created with the appearance of age; e.g., the sudden appearance of a mature chicken capable of laying eggs. This ad hoc hypothesis introduced into young-Earth creationism is unfalsifiable because it says that the time of creation (of a species) measured by the accepted technology is illusory and no accepted technology is proposed to measure the claimed "actual" time of creation.  Moreover, if the ad hoc hypothesis says that the world was created as we observe it today without stating further laws, by definition it cannot be contradicted by observations and thus is not falsifiable. This is discussed by Dienes in the case of a variation on the Omphalos hypothesis, which, in addition, specifies that God made the creation in this way to test our faith.

Useful metaphysical statements
Grover Maxwell discussed statements such as "All men are mortal." This is not falsifiable, because it does not matter how old a man is, maybe he will die next year.  Maxwell said that this statement is nevertheless useful, because it is often corroborated. He coined the term "corroboration without demarcation". Popper's view is that it is indeed useful, because Popper considers that metaphysical statements can be useful, but also because it is indirectly corroborated by the corroboration of the falsifiable law "All men die before the age of 150." For Popper, if no such falsifiable law exists, then the metaphysical law is less useful, because it is not indirectly corroborated. This kind of non-falsifiable statements in science was noticed by Carnap as early as 1937.
Maxwell also used the example "All solids have a melting point." This is not falsifiable, because maybe the melting point will be reached at a higher temperature. The law is falsifiable and more useful if we specify an upper bound on melting points or a way to calculate this upper bound.Another example from Maxwell is "All beta decays are accompanied with a neutrino emission from the same nucleus." This is also not falsifiable, because maybe the neutrino can be detected in a different manner. The law is falsifiable and much more useful from a scientific point of view, if the method to detect the neutrino is specified. Maxwell said that most scientific laws are metaphysical statements of this kind, which, Popper said, need to be made more precise before they can be indirectly corroborated. In other words, specific technologies must be provided to make the statements inter-subjectively-verifiable, i.e., so that scientists know what the falsification or its failure actually means.
In his critique of the falsifiability criterion, Maxwell considered the requirement for decisions in the falsification of, both, the emission of neutrinos (see § Dogmatic falsificationism) and the existence of the melting point. For example, he pointed out that had no neutrino been detected, it could have been because some conservation law is false. Popper did not argue against the problems of falsification per se. He always acknowledged these problems. Popper's response was at the logical level. For example, he pointed out that, if a specific way is given to trap the neutrino, then, at the level of the language, the statement is falsifiable, because "no neutrino was detected after using this specific way" formally contradicts it (and it is inter-subjectively-verifiable—people can repeat the experiment).

Natural selection
In the 5th and 6th editions of On the Origin of Species, following a suggestion of Alfred Russel Wallace, Darwin used "Survival of the fittest", an expression first coined by Herbert Spencer, as a synonym for "Natural Selection". Popper and others said that, if one uses the most widely accepted definition of "fitness" in modern biology (see subsection § Evolution), namely reproductive success itself, the expression "survival of the fittest" is a tautology.Darwinist Ronald Fisher worked out mathematical theorems to help answer questions regarding natural selection. But, for Popper and others, there is no (falsifiable) law of Natural Selection in this, because these tools only apply to some rare traits. Instead, for Popper, the work of Fisher and others on Natural Selection is part of an important and successful metaphysical research program.

Mathematics
Popper said that not all unfalsifiable statements are useless in science. Mathematical statements are good examples. Like all formal sciences, mathematics is not concerned with the validity of theories based on observations in the empirical world, but rather, mathematics is occupied with the theoretical, abstract study of such topics as quantity, structure, space and change. Methods of the mathematical sciences are, however, applied in constructing and testing scientific models dealing with observable reality. Albert Einstein wrote, "One reason why mathematics enjoys special esteem, above all other sciences, is that its laws are absolutely certain and indisputable, while those of other sciences are to some extent debatable and in constant danger of being overthrown by newly discovered facts."

Historicism
Popper made a clear distinction between the original theory of Marx and what came to be known as Marxism later on. For Popper, the original theory of Marx contained genuine scientific laws. Though they could not make preordained predictions, these laws constrained how changes can occur in society. One of them was that changes in society cannot "be achieved by the use of legal or political means". In Popper's view, this was both testable and subsequently falsified. "Yet instead of accepting the refutations", Popper wrote, "the followers of Marx re-interpreted both the theory and the evidence in order to make them agree. ... They thus gave a 'conventionalist twist' to the theory; and by this stratagem they destroyed its much advertised claim to scientific status." Popper's attacks were not directed toward Marxism, or Marx's theories, which were falsifiable, but toward Marxists who he considered to have ignored the falsifications which had happened. Popper more fundamentally criticized 'historicism' in the sense of any preordained prediction of history, given what he saw as our right, ability and responsibility to control our own destiny.

Use in courts of law
Falsifiability has been used in the McLean v. Arkansas case (in 1982), the Daubert case (in 1993) and other cases. A survey of 303 federal judges conducted in 1998 found that "[P]roblems with the nonfalsifiable nature of an expert's underlying theory and difficulties with an unknown or too-large error rate were cited in less than 2% of cases."

McLean v. Arkansas case
In the ruling of the McLean v. Arkansas case, Judge William Overton used falsifiability as one of the criteria to determine that "creation science" was not scientific and should not be taught in Arkansas public schools as such (it can be taught as religion). In his testimony, philosopher Michael Ruse defined the characteristics which constitute science as (see Pennock 2000, p. 5, and Ruse 2010):

It is guided by natural law;
It has to be explanatory by reference to natural law;
It is testable against the empirical world;
Its conclusions are tentative, i.e., are not necessarily the final word; and
It is falsifiable.
In his conclusion related to this criterion Judge Overton stated that While anybody is free to approach a scientific inquiry in any fashion they choose, they cannot properly describe the methodology as scientific, if they start with the conclusion and refuse to change it regardless of the evidence developed during the course of the investigation.

Daubert standard
In several cases of the United States Supreme Court, the court described scientific methodology using the five Daubert factors, which include falsifiability. The Daubert result cited Popper and other philosophers of science: Ordinarily, a key question to be answered in determining whether a theory or technique is scientific knowledge that will assist the trier of fact will be whether it can be (and has been) tested. Scientific methodology today is based on generating hypotheses and testing them to see if they can be falsified; indeed, this methodology is what distinguishes science from other fields of human inquiry. Green 645. See also C. Hempel, Philosophy of Natural Science 49 (1966) ([T]he statements constituting a scientific explanation must be capable of empirical test); K. Popper, Conjectures and Refutations: The Growth of Scientific Knowledge 37 (5th ed. 1989) ([T]he criterion of the scientific status of a theory is its falsifiability, or refutability, or testability) (emphasis deleted).
David H. Kaye said that references to the Daubert majority opinion confused falsifiability and falsification and that "inquiring into the existence of meaningful attempts at falsification is an appropriate and crucial consideration in admissibility determinations."

Connections between statistical theories and falsifiability
Considering the specific detection procedure that was used in the neutrino experiment, without mentioning its probabilistic aspect, Popper wrote "it provided a test of the much more significant falsifiable theory that such emitted neutrinos could be trapped in a certain way". In this manner, in his discussion of the neutrino experiment, Popper did not raise at all the probabilistic aspect of the experiment. Together with Maxwell, who raised the problems of falsification in the experiment, he was aware that some convention must be adopted to fix what it means to detect or not a neutrino in this probabilistic context. This is the third kind of decisions mentioned by Lakatos. For Popper and most philosophers, observations are theory impregnated. In this example, the theory that impregnates observations (and justifies that we conventionally accept the potential falsifier "no neutrino was detected") is statistical. In statistical language, the potential falsifier that can be statistically accepted (not rejected to say it more correctly) is typically the null hypothesis, as understood even in popular accounts on falsifiability.Different ways are used by statisticians to draw conclusions about hypotheses on the basis of available evidence. Fisher, Neyman and Pearson proposed approaches that require no prior probabilities on the hypotheses that are being studied.  In contrast, Bayesian inference emphasizes the importance of prior probabilities. But, as far as falsification as a yes/no procedure in Popper's methodology is concerned, any approach that provides a way to accept or not a potential falsifier can be used, including approaches that use Bayes' theorem and estimations of prior probabilities that are made using critical discussions and reasonable assumptions taken from the background knowledge. There is no general rule that considers as falsified an hypothesis with small Bayesian revised probability, because as pointed out by Mayo and argued before by Popper, the individual outcomes described in detail will easily have very small probabilities under available evidence without being genuine anomalies. Nevertheless, Mayo adds, "they can indirectly falsify hypotheses by adding a methodological falsification rule". In general, Bayesian statistic can play a role in critical rationalism in the context of inductive logic, which is said to be inductive because implications are generalized to conditional probabilities.  According to Popper and other philosophers such as Colin Howson, Hume's argument precludes inductive logic, but only when the logic makes no use "of additional assumptions: in particular, about what is to be assigned positive prior probability". Inductive logic itself is not precluded, especially not when it is a deductively valid application of Bayes' theorem that is used to evaluate the probabilities of the hypotheses using the observed data and what is assumed about the priors. Gelman and Shalizi mentioned that Bayes' statisticians do not have to disagree with the non-inductivists.Because statisticians often associate statistical inference with induction, Popper's philosophy is often said to have a hidden form of induction.  For example, Mayo wrote "The falsifying hypotheses ... necessitate an evidence-transcending (inductive) statistical inference. This is hugely problematic for Popper".  Yet, also according to Mayo, Popper [as a non-inductivist] acknowledged the useful role of statistical inference in the falsification problems:  she mentioned that Popper wrote her (in the context of falsification based on evidence) "I regret not studying statistics" and that her thought was then "not as much as I do".

Lakatos's falsificationism
Imre Lakatos divided the problems of falsification in two categories. The first category corresponds to decisions that must be agreed upon by scientists before they can falsify a theory. The other category emerges when one tries to use falsifications and corroborations to explain progress in science.  Lakatos described four kind of falsificationisms in view of how they address these problems. Dogmatic falsificationism ignores both types of problems. Methodological falsificationism addresses the first type of problems by accepting that decisions must be taken by scientists.  Naive methodological falsificationism or naive falsificationism does not do anything to address the second type of problems. Lakatos used dogmatic and naive falsificationism to explain how Popper's philosophy changed over time and viewed sophisticated falsificationism as his own improvement on Popper's philosophy, but also said that Popper some times appears as a sophisticated falsificationist. Popper responded that Lakatos misrepresented his intellectual history with these terminological distinctions.

Dogmatic falsificationism
A dogmatic falsificationist ignores that every observation is theory-impregnated. Being theory-impregnated means that it goes beyond direct experience. For example, the statement "Here is a glass of water" goes beyond experience, because the concepts of glass and water "denote physical bodies which exhibit a certain law-like behaviour" (Popper). This leads to the critique that it is unclear which theory is falsified. Is it the one that is being studied or the one behind the observation? This is sometimes called the 'Duhem–Quine problem'. An example is Galileo's refutation of the theory that celestial bodies are faultless crystal balls. Many considered that it was the optical theory of the telescope that was false, not the theory of celestial bodies. Another example is the theory that neutrinos are emitted in beta decays. Had they not been observed in the Cowan–Reines neutrino experiment, many would have considered that the strength of the beta-inverse reaction used to detect the neutrinos was not sufficiently high. At the time, Grover Maxwell wrote, the possibility that this strength was sufficiently high was a "pious hope".A dogmatic falsificationist ignores the role of auxiliary hypotheses. The assumptions or auxiliary hypotheses of a particular test are all the hypotheses that are assumed to be accurate in order for the test to work as planned. The predicted observation that is contradicted depends on the theory and these auxiliary hypotheses. Again, this leads to the critique that it cannot be told if it is the theory or one of the required auxiliary hypotheses that is false. Lakatos gives the example of the path of a planet. If the path contradicts Newton's law, we will not know if it is Newton's law that is false or the assumption that no other body influenced the path. 

Lakatos says that Popper's solution to these criticisms requires that one relaxes the assumption that an observation can show a theory to be false:  If a theory is falsified [in the usual sense], it is proven false; if it is 'falsified' [in the technical sense], it may still be true. 
Methodological falsificationism replaces the contradicting observation in a falsification with a "contradicting observation" accepted by convention among scientists, a convention that implies four kinds of decisions that have these respective goals: the selection of all basic statements (statements that correspond to logically possible observations), selection of the accepted basic statements among the basic statements, making statistical laws falsifiable and applying the refutation to the specific theory (instead of an auxiliary hypothesis). The experimental falsifiers and falsifications thus depend on decisions made by scientists in view of the currently accepted technology and its associated theory.

Naive falsificationism
According to Lakatos, naive falsificationism is the claim that methodological falsifications can by themselves explain how scientific knowledge progresses. Very often a theory is still useful and used even after it is found in contradiction with some observations. Also, when scientists deal with two or more competing theories which are both corroborated, considering only falsifications, it is not clear why one theory is chosen above the other, even when one is corroborated more often than the other. In fact, a stronger version of the Quine-Duhem thesis says that it is not always possible to rationally pick one theory over the other using falsifications.  Considering only falsifications, it is not clear why often a corroborating experiment is seen as a sign of progress. Popper's critical rationalism uses both falsifications and corroborations to explain progress in science. How corroborations and falsifications can explain progress in science was a subject of disagreement between many philosophers, especially between Lakatos and Popper.Popper distinguished between the creative and informal process from which theories and accepted basic statements emerge and the logical and formal process where theories are falsified or corroborated. The main issue is whether the decision to select a theory among competing theories in the light of falsifications and corroborations could be justified using some kind of formal logic. It is a delicate question, because this logic would be inductive: it justifies a universal law in view of instances. Also, falsifications, because they are based on methodological decisions, are useless in a strict justification perspective. The answer of Lakatos and many others to that question is that it should. In contradistinction, for Popper, the creative and informal part is guided by methodological rules, which naturally say to favour theories that are corroborated over those that are falsified, but this methodology can hardly be made rigorous.Popper's way to analyze progress in science was through the concept of verisimilitude, a way to define how close a theory is to the truth, which he did not consider very significant, except (as an attempt) to describe a concept already clear in practice. Later, it was shown that the specific definition proposed by Popper cannot distinguish between two theories that are false, which is the case for all theories in the history of science. Today, there is still on going research on the general concept of verisimilitude.

From the problem of induction to falsificationism
Hume explained induction with a theory of the mind that was in part inspired by Newton's theory of gravitation.  Popper rejected Hume's explanation of induction and proposed his own mechanism: science progresses by trial and error within an evolutionary epistemology. Hume believed that his psychological induction process follows laws of nature, but, for him, this does not imply the existence of a method of justification based on logical rules.  In fact, he argued that any induction mechanism, including the mechanism described by his theory, could not be justified logically.  Similarly, Popper adopted an evolutionary epistemology, which implies that some laws explain progress in science, but yet insists that the process of trial and error is hardly rigorous and that there is always an element of irrationality in the creative process of science. The absence of a method of justification is a built-in aspect of Popper's trial and error explanation.
As rational as they can be, these explanations that refer to laws, but cannot be turned into methods of justification (and thus do not contradict Hume's argument or its premises), were not sufficient for some philosophers. In particular, Russell once expressed the view that if Hume's problem cannot be solved, “there is no intellectual difference between sanity and insanity” and actually proposed a method of justification. He rejected Hume's premise that there is a need to justify any principle that is itself used to justify induction.  It might seem that this premise is hard to reject, but to avoid circular reasoning we do reject it in the case of deductive logic. It makes sense to also reject this premise in the case of principles to justify induction.  Lakatos's proposal of sophisticated falsificationism was very natural in that context.
Therefore, Lakatos urged Popper to find an inductive principle behind the trial and error learning process and sophisticated falsificationism was his own approach to address this challenge.  Kuhn, Feyerabend, Musgrave and others mentioned and Lakatos himself acknowledged that, as a method of justification, this attempt failed, because there was no normative methodology to justify—Lakatos's methodology was anarchy in disguise.

Falsificationism in Popper's philosophy
Popper's philosophy is sometimes said to fail to recognize the Quine-Duhem thesis, which would make it a form of dogmatic falsificationism. For example, Watkins wrote "apparently forgetting that he had once said 'Duhem is right [...]', Popper set out to devise potential falsifiers just for Newton's fundamental assumptions".  But, Popper's philosophy is not always qualified of falsificationism in the pejorative manner associated with dogmatic or naive falsificationism. The problems of falsification are acknowledged by the falsificationists. For example, Chalmers points out that falsificationists freely admit that observation is theory impregnated. Thornton, referring to Popper's methodology, says that the predictions inferred from conjectures are not directly compared with the facts simply because all observation-statements are theory-laden.  For the critical rationalists, the problems of falsification are not an issue, because they do not try to make experimental falsifications logical or to logically justify them, nor to use them to logically explain progress in science. Instead, their faith rests on critical discussions around these experimental falsifications. Lakatos made a distinction between a "falsification" (with quotation marks) in Popper's philosophy and a falsification (without quotation marks) that can be used in a systematic methodology where rejections are justified. He knew that Popper's philosophy is not and has never been about this kind of justification, but he felt that it should have been. Sometimes, Popper and other falsificationists say that when a theory is falsified it is rejected, which appears as dogmatic falsificationism, but the general context is always critical rationalism in which all decisions are open to critical discussions and can be revised.

Controversies
Methodless creativity versus inductive methodology
As described in section § Naive falsificationism, Lakatos and Popper agreed that universal laws cannot be logically deduced (except from laws that say even more). But unlike Popper, Lakatos felt that if the explanation for new laws cannot be deductive, it must be inductive. He urged Popper explicitly to adopt some inductive principle and sets himself the task to find an inductive methodology. However, the methodology that he found did not offer any exact inductive rules. In a response to Kuhn, Feyerabend and Musgrave, Lakatos acknowledged that the methodology depends on the good judgment of the scientists.  Feyerabend wrote in "Against Method" that Lakatos's methodology of scientific research programmes is epistemological anarchism in disguise and Musgrave made a similar comment.  In more recent work, Feyerabend says that Lakatos uses rules, but whether or not to follow any of these rules is left to the judgment of the scientists. This is also discussed elsewhere.Popper also offered a methodology with rules, but these rules are also not-inductive rules, because they are not by themselves used to accept laws or establish their validity. They do that through the creativity or "good judgment" of the scientists only.  For Popper, the required non deductive component of science never had to be an inductive methodology. He always viewed this component as a creative process beyond the explanatory reach of any rational methodology, but yet used to decide which theories should be studied and applied, find good problems and guess useful conjectures. Quoting Einstein to support his view, Popper said that this renders obsolete the need for an inductive methodology or logical path to the laws. For Popper, no inductive methodology was ever proposed to satisfactorily explain science.

Ahistorical versus historiographical
Section § Methodless creativity versus inductive methodology says that both Lakatos's and Popper's methodology are not inductive. Yet Lakatos's methodology extended importantly Popper's methodology: it added a historiographical component to it. This allowed Lakatos to find corroborations for his methodology in the history of science. The basic units in his methodology, which can be abandoned or pursued, are research programmes. Research programmes can be degenerative or progressive and only degenerative research programmes must be abandoned at some point.  For Lakatos, this is mostly corroborated by facts in history.
In contradistinction, Popper did not propose his methodology as a tool to reconstruct the history of science. Yet, some times, he did refer to history to corroborate his methodology. For example, he remarked that theories that were considered great successes were also the most likely to be falsified. Zahar's view was that, with regard to corroborations found in the history of science, there was only a difference of emphasis between Popper and Lakatos.
As an anecdotal example, in one of his articles Lakatos challenged Popper to show that his theory was falsifiable: he asked "Under what conditions would you give up your demarcation criterion?". Popper replied "I shall give up my theory if Professor Lakatos succeeds in showing that Newton's theory is no more falsifiable by 'observable states of affairs' than is Freud's."

Normal science versus revolutionary science
Thomas Kuhn analyzed what he calls periods of normal science as well as revolutions from one period of normal science to another, whereas Popper's view is that only revolutions are relevant. For Popper, the role of science, mathematics and metaphysics, actually the role of any knowledge, is to solve puzzles. In the same line of thought, Kuhn observes that in periods of normal science the scientific theories, which represent some paradigm, are used to routinely solve puzzles and the validity of the paradigm is hardly in question. It is only when important new puzzles emerge that cannot be solved by accepted theories that a revolution might occur. This can be seen as a viewpoint on the distinction made by Popper between the informal and formal process in science (see section § Naive falsificationism). In the big picture presented by Kuhn, the routinely solved puzzles are corroborations. Falsifications or otherwise unexplained observations are unsolved puzzles. All of these are used in the informal process that generates a new kind of theory. Kuhn says that Popper emphasizes formal or logical falsifications and fails to explain how the social and informal process works.

Unfalsifiability versus falsity of astrology
Popper often uses astrology as an example of a pseudoscience. He says that it is not falsifiable because both the theory itself and its predictions are too imprecise. Kuhn, as an historian of science, remarked that many predictions made by astrologers in the past were quite precise and they were very often falsified. He also said that astrologers themselves acknowledged these falsifications.

Epistemological anarchism vs the scientific method
Paul Feyerabend rejected any prescriptive methodology at all. He rejected Lakatos's argument for ad hoc hypothesis, arguing that science would not have progressed without making use of any and all available methods to support new theories. He rejected any reliance on a scientific method, along with any special authority for science that might derive from such a method. He said that if one is keen to have a universally valid methodological rule, epistemological anarchism or anything goes would be the only candidate. For Feyerabend, any special status that science might have, derives from the social and physical value of the results of science rather than its method.

Sokal and Bricmont
In their book Fashionable Nonsense (from 1997, published in the UK as Intellectual Impostures) the physicists Alan Sokal and Jean Bricmont criticised falsifiability. They include this critique in the "Intermezzo" chapter, where they expose their own views on truth in contrast to the extreme epistemological relativism of postmodernism. Even though Popper is clearly not a relativist, Sokal and Bricmont discuss falsifiability because they see postmodernist epistemological relativism as a reaction to Popper's description of falsifiability, and more generally, to his theory of science.

See also
Notes
Abbreviated references
References
Further reading
External links
 The dictionary definition of falsifiability at Wiktionary