In mathematics, the prime number theorem (PNT) describes the asymptotic distribution of the prime numbers among the positive integers. It formalizes the intuitive idea that primes become less common as they become larger by precisely quantifying the rate at which this occurs.  The theorem was proved independently by Jacques Hadamard and Charles Jean de la Vallée Poussin in 1896 using ideas introduced by Bernhard Riemann (in particular, the Riemann zeta function).
The first such distribution found is π(N) ~ N/log(N), where π(N) is the prime-counting function (the number of primes less than or equal to N) and log(N) is the natural logarithm of N. This means that for large enough N, the probability that a random integer not greater than N is prime is very close to 1 / log(N). Consequently, a random integer with at most 2n digits (for large enough n) is about half as likely to be prime as a random integer with at most n digits. For example, among the positive integers of at most 1000 digits, about one in 2300 is prime (log(101000) ≈ 2302.6), whereas among positive integers of at most 2000 digits, about one in 4600 is prime (log(102000) ≈ 4605.2). In other words, the average gap between consecutive prime numbers among the first N integers is roughly log(N).

Statement
Let π(x) be the prime-counting function defined to be the number of primes less than or equal to x, for any real number x. For example, π(10) = 4 because there are four prime numbers (2, 3, 5 and 7) less than or equal to 10. The prime number theorem then states that x / log x is a good approximation to π(x) (where log here means the natural logarithm), in the sense that the limit of the quotient of the two functions π(x) and x / log x as x increases without bound is 1:

  
    
      
        
          lim
          
            x
            →
            ∞
          
        
        
          
            
              
              π
              (
              x
              )
              
            
            
              
              
                [
                
                  
                    x
                    
                      log
                      ⁡
                      (
                      x
                      )
                    
                  
                
                ]
              
              
            
          
        
        =
        1
        ,
      
    
    {\displaystyle \lim _{x\to \infty }{\frac {\;\pi (x)\;}{\;\left[{\frac {x}{\log(x)}}\right]\;}}=1,}
  known as the asymptotic law of distribution of prime numbers. Using asymptotic notation this result can be restated as

  
    
      
        π
        (
        x
        )
        ∼
        
          
            x
            
              log
              ⁡
              x
            
          
        
        .
      
    
    {\displaystyle \pi (x)\sim {\frac {x}{\log x}}.}
  This notation (and the theorem) does not say anything about the limit of the difference of the two functions as x increases without bound. Instead, the theorem states that x / log x approximates π(x) in the sense that the relative error of this approximation approaches 0 as x increases without bound.
The prime number theorem is equivalent to the statement that the nth prime number pn satisfies

  
    
      
        
          p
          
            n
          
        
        ∼
        n
        log
        ⁡
        (
        n
        )
        ,
      
    
    {\displaystyle p_{n}\sim n\log(n),}
  the asymptotic notation meaning, again, that the relative error of this approximation approaches 0 as n increases without bound. For example, the 2×1017th prime number is 8512677386048191063, and (2×1017)log(2×1017) rounds to 7967418752291744388, a relative error of about 6.4%.
On the other hand, the following asymptotic relations are logically equivalent:

  
    
      
        
          
            
              
                
                  lim
                  
                    x
                    →
                    ∞
                  
                
                
                  
                    
                      π
                      (
                      x
                      )
                      log
                      ⁡
                      x
                    
                    x
                  
                
              
              
                
                =
                1
                ,
              
            
            
              
                
                  lim
                  
                    x
                    →
                    ∞
                  
                
                
                  
                    
                      π
                      (
                      x
                      )
                      log
                      ⁡
                      π
                      (
                      x
                      )
                    
                    x
                  
                
              
              
                
                =
                1.
              
            
          
        
      
    
    {\displaystyle {\begin{aligned}\lim _{x\rightarrow \infty }{\frac {\pi (x)\log x}{x}}&=1,\\\lim _{x\rightarrow \infty }{\frac {\pi (x)\log \pi (x)}{x}}&=1.\end{aligned}}}
  As outlined below, the prime number theorem is also equivalent to

  
    
      
        
          lim
          
            x
            →
            ∞
          
        
        
          
            
              ϑ
              (
              x
              )
            
            x
          
        
        =
        
          lim
          
            x
            →
            ∞
          
        
        
          
            
              ψ
              (
              x
              )
            
            x
          
        
        =
        1
        ,
      
    
    {\displaystyle \lim _{x\to \infty }{\frac {\vartheta (x)}{x}}=\lim _{x\to \infty }{\frac {\psi (x)}{x}}=1,}
  where ϑ and ψ are the first and the second Chebyshev functions respectively, and to

  
    
      
        
          lim
          
            x
            →
            ∞
          
        
        
          
            
              M
              (
              x
              )
            
            x
          
        
        =
        0
        ,
      
    
    {\displaystyle \lim _{x\to \infty }{\frac {M(x)}{x}}=0,}
  where 
  
    
      
        M
        (
        x
        )
        =
        
          ∑
          
            n
            ≤
            x
          
        
        μ
        (
        n
        )
      
    
    {\displaystyle M(x)=\sum _{n\leq x}\mu (n)}
   is the Mertens function.

History of the proof of the asymptotic law of prime numbers
Based on the tables by Anton Felkel and Jurij Vega, Adrien-Marie Legendre conjectured in 1797 or 1798 that π(a) is approximated by the function a / (A log a + B), where A and B are unspecified constants. In the second edition of his book on number theory (1808) he then made a more precise conjecture, with A = 1 and B = −1.08366. Carl Friedrich Gauss considered the same question at age 15 or 16 "in the year 1792 or 1793", according to his own recollection in 1849. In 1838 Peter Gustav Lejeune Dirichlet came up with his own approximating function, the logarithmic integral li(x) (under the slightly different form of a series, which he communicated to Gauss). Both Legendre's and Dirichlet's formulas imply the same conjectured asymptotic equivalence of π(x) and x / log(x) stated above, although it turned out that Dirichlet's approximation is considerably better if one considers the differences instead of quotients.
In two papers from 1848 and 1850, the Russian mathematician Pafnuty Chebyshev attempted to prove the asymptotic law of distribution of prime numbers. His work is notable for the use of the zeta function ζ(s), for real values of the argument "s", as in works of Leonhard Euler, as early as 1737. Chebyshev's papers predated Riemann's celebrated memoir of 1859, and he succeeded in proving a slightly weaker form of the asymptotic law, namely, that if the limit as x goes to infinity of π(x) / (x / log(x))  exists at all, then it is necessarily equal to one. He was able to prove unconditionally that this ratio is bounded above and below by two explicitly given constants near 1, for all sufficiently large x. Although Chebyshev's paper did not prove the Prime Number Theorem, his estimates for π(x) were strong enough for him to prove Bertrand's postulate that there exists a prime number between n and 2n for any integer n ≥ 2.
An important paper concerning the distribution of prime numbers was Riemann's 1859 memoir "On the Number of Primes Less Than a Given Magnitude", the only paper he ever wrote on the subject. Riemann introduced new ideas into the subject, chiefly that the distribution of prime numbers is intimately connected with the zeros of the analytically extended Riemann zeta function of a complex variable. In particular, it is in this paper that the idea to apply methods of complex analysis to the study of the real function π(x) originates. Extending Riemann's ideas, two proofs of the asymptotic law of the distribution of prime numbers were found independently by Jacques Hadamard and Charles Jean de la Vallée Poussin and appeared in the same year (1896). Both proofs used methods from complex analysis, establishing as a main step of the proof that the Riemann zeta function ζ(s) is nonzero for all complex values of the variable s that have the form s = 1 + it with t > 0.During the 20th century, the theorem of Hadamard and de la Vallée Poussin also became known as the Prime Number Theorem. Several different proofs of it were found, including the "elementary" proofs of Atle Selberg and Paul Erdős (1949). Hadamard's and de la Vallée Poussin's original proofs are long and elaborate; later proofs introduced various simplifications through the use of Tauberian theorems but remained difficult to digest. A short proof was discovered in 1980 by the American mathematician Donald J. Newman. Newman's proof is arguably the simplest known proof of the theorem, although it is non-elementary in the sense that it uses Cauchy's integral theorem from complex analysis.

Proof sketch
Here is a sketch of the proof referred to in one of Terence Tao's lectures. Like most proofs of the PNT, it starts out by reformulating the problem in terms of a less intuitive, but better-behaved, prime-counting function. The idea is to count the primes (or a related set such as the set of prime powers) with weights to arrive at a function with smoother asymptotic behavior. The most common such generalized counting function is the Chebyshev function ψ(x), defined by

  
    
      
        ψ
        (
        x
        )
        =
        
        
        
        
        
          ∑
          
            
              
                
                  p
                  
                     is prime
                  
                
                
                  
                    p
                    
                      k
                    
                  
                  ≤
                  x
                  ,
                
              
            
          
        
        
        
        
        
        log
        ⁡
        p
        
        .
      
    
    {\displaystyle \psi (x)=\!\!\!\!\sum _{\stackrel {p^{k}\leq x,}{p{\text{ is prime}}}}\!\!\!\!\log p\;.}
  This is sometimes written as

  
    
      
        ψ
        (
        x
        )
        =
        
          ∑
          
            n
            ≤
            x
          
        
        Λ
        (
        n
        )
        
        ,
      
    
    {\displaystyle \psi (x)=\sum _{n\leq x}\Lambda (n)\;,}
  where Λ(n) is the von Mangoldt function, namely

  
    
      
        Λ
        (
        n
        )
        =
        
          
            {
            
              
                
                  log
                  ⁡
                  p
                
                
                  
                     if 
                  
                  n
                  =
                  
                    p
                    
                      k
                    
                  
                  
                     for some prime 
                  
                  p
                  
                     and integer 
                  
                  k
                  ≥
                  1
                  ,
                
              
              
                
                  0
                
                
                  
                    otherwise.
                  
                
              
            
            
          
        
      
    
    {\displaystyle \Lambda (n)={\begin{cases}\log p&{\text{ if }}n=p^{k}{\text{ for some prime }}p{\text{ and integer }}k\geq 1,\\0&{\text{otherwise.}}\end{cases}}}
  It is now relatively easy to check that the PNT is equivalent to the claim that

  
    
      
        
          lim
          
            x
            →
            ∞
          
        
        
          
            
              ψ
              (
              x
              )
            
            x
          
        
        =
        1
        
        .
      
    
    {\displaystyle \lim _{x\to \infty }{\frac {\psi (x)}{x}}=1\;.}
  Indeed, this follows from the easy estimates

  
    
      
        ψ
        (
        x
        )
        =
        
          ∑
          
            
              
                
                  p
                  
                     is prime
                  
                
                
                  p
                  ≤
                  x
                
              
            
          
        
        log
        ⁡
        p
        
          ⌊
          
            
              
                log
                ⁡
                x
              
              
                log
                ⁡
                p
              
            
          
          ⌋
        
        ≤
        
          ∑
          
            
              
                
                  p
                  
                     is prime
                  
                
                
                  p
                  ≤
                  x
                
              
            
          
        
        log
        ⁡
        x
        =
        π
        (
        x
        )
        log
        ⁡
        x
      
    
    {\displaystyle \psi (x)=\sum _{\stackrel {p\leq x}{p{\text{ is prime}}}}\log p\left\lfloor {\frac {\log x}{\log p}}\right\rfloor \leq \sum _{\stackrel {p\leq x}{p{\text{ is prime}}}}\log x=\pi (x)\log x}
  and (using big O notation) for any ε > 0,

  
    
      
        ψ
        (
        x
        )
        ≥
        
        
        
        
        
          ∑
          
            
              
                
                  p
                  
                     is prime
                  
                
                
                  
                    x
                    
                      1
                      −
                      ε
                    
                  
                  ≤
                  p
                  ≤
                  x
                
              
            
          
        
        
        
        
        
        log
        ⁡
        p
        ≥
        
        
        
        
        
          ∑
          
            
              
                
                  p
                  
                     is prime
                  
                
                
                  
                    x
                    
                      1
                      −
                      ε
                    
                  
                  ≤
                  p
                  ≤
                  x
                
              
            
          
        
        
        
        
        
        (
        1
        −
        ε
        )
        log
        ⁡
        x
        =
        (
        1
        −
        ε
        )
        
          (
          
            π
            (
            x
            )
            +
            O
            
              (
              
                x
                
                  1
                  −
                  ε
                
              
              )
            
          
          )
        
        log
        ⁡
        x
        
        .
      
    
    {\displaystyle \psi (x)\geq \!\!\!\!\sum _{\stackrel {x^{1-\varepsilon }\leq p\leq x}{p{\text{ is prime}}}}\!\!\!\!\log p\geq \!\!\!\!\sum _{\stackrel {x^{1-\varepsilon }\leq p\leq x}{p{\text{ is prime}}}}\!\!\!\!(1-\varepsilon )\log x=(1-\varepsilon )\left(\pi (x)+O\left(x^{1-\varepsilon }\right)\right)\log x\;.}
  The next step is to find a useful representation for ψ(x). Let ζ(s) be the Riemann zeta function. It can be shown that ζ(s) is related to the von Mangoldt function Λ(n), and hence to ψ(x), via the relation

  
    
      
        −
        
          
            
              
                ζ
                ′
              
              (
              s
              )
            
            
              ζ
              (
              s
              )
            
          
        
        =
        
          ∑
          
            n
            =
            1
          
          
            ∞
          
        
        Λ
        (
        n
        )
        
        
          n
          
            −
            s
          
        
        
        .
      
    
    {\displaystyle -{\frac {\zeta '(s)}{\zeta (s)}}=\sum _{n=1}^{\infty }\Lambda (n)\,n^{-s}\;.}
  A delicate analysis of this equation and related properties of the zeta function, using the Mellin transform and Perron's formula, shows that for non-integer x the equation

  
    
      
        ψ
        (
        x
        )
        =
        x
        
        −
        
        log
        ⁡
        (
        2
        π
        )
        
        −
        
          ∑
          
            ρ
            :
            
            ζ
            (
            ρ
            )
            =
            0
          
        
        
          
            
              x
              
                ρ
              
            
            ρ
          
        
      
    
    {\displaystyle \psi (x)=x\;-\;\log(2\pi )\;-\sum \limits _{\rho :\,\zeta (\rho )=0}{\frac {x^{\rho }}{\rho }}}
  holds, where the sum is over all zeros (trivial and nontrivial) of the zeta function. This striking formula is one of the so-called explicit formulas of number theory, and is already suggestive of the result we wish to prove, since the term x (claimed to be the correct asymptotic order of ψ(x)) appears on the right-hand side, followed by (presumably) lower-order asymptotic terms.
The next step in the proof involves a study of the zeros of the zeta function. The trivial zeros −2, −4, −6, −8, ... can be handled separately:

  
    
      
        
          ∑
          
            n
            =
            1
          
          
            ∞
          
        
        
          
            1
            
              2
              n
              
              
                x
                
                  2
                  n
                
              
            
          
        
        =
        −
        
          
            1
            2
          
        
        log
        ⁡
        
          (
          
            1
            −
            
              
                1
                
                  x
                  
                    2
                  
                
              
            
          
          )
        
        ,
      
    
    {\displaystyle \sum _{n=1}^{\infty }{\frac {1}{2n\,x^{2n}}}=-{\frac {1}{2}}\log \left(1-{\frac {1}{x^{2}}}\right),}
  which vanishes for large x. The nontrivial zeros, namely those on the critical strip 0 ≤ Re(s) ≤ 1, can potentially be of an asymptotic order comparable to the main term x if Re(ρ) = 1, so we need to show that all zeros have real part strictly less than 1.

Non-vanishing on Re(s) = 1
To do this, we take for granted that ζ(s) is meromorphic in the half-plane Re(s) > 0, and is analytic there except for a simple pole at s = 1, and that there is a product formula

  
    
      
        ζ
        (
        s
        )
        =
        
          ∏
          
            p
          
        
        
          
            1
            
              1
              −
              
                p
                
                  −
                  s
                
              
            
          
        
      
    
    {\displaystyle \zeta (s)=\prod _{p}{\frac {1}{1-p^{-s}}}}
  for Re(s) > 1. This product formula follows from the existence of unique prime factorization of integers, and shows that ζ(s) is never zero in this region, so that its logarithm is defined there and

  
    
      
        log
        ⁡
        ζ
        (
        s
        )
        =
        −
        
          ∑
          
            p
          
        
        log
        ⁡
        
          (
          
            1
            −
            
              p
              
                −
                s
              
            
          
          )
        
        =
        
          ∑
          
            p
            ,
            n
          
        
        
          
            
              p
              
                −
                n
                s
              
            
            n
          
        
        
        .
      
    
    {\displaystyle \log \zeta (s)=-\sum _{p}\log \left(1-p^{-s}\right)=\sum _{p,n}{\frac {p^{-ns}}{n}}\;.}
  Write s = x + iy ; then

  
    
      
        
          
            |
          
        
        ζ
        (
        x
        +
        i
        y
        )
        
          
            |
          
        
        =
        exp
        ⁡
        
          (
          
            
              ∑
              
                n
                ,
                p
              
            
            
              
                
                  cos
                  ⁡
                  n
                  y
                  log
                  ⁡
                  p
                
                
                  n
                  
                    p
                    
                      n
                      x
                    
                  
                
              
            
          
          )
        
        
        .
      
    
    {\displaystyle {\big |}\zeta (x+iy){\big |}=\exp \left(\sum _{n,p}{\frac {\cos ny\log p}{np^{nx}}}\right)\;.}
  Now observe the identity

  
    
      
        3
        +
        4
        cos
        ⁡
        ϕ
        +
        cos
        ⁡
        2
        ϕ
        =
        2
        (
        1
        +
        cos
        ⁡
        ϕ
        
          )
          
            2
          
        
        ≥
        0
        
        ,
      
    
    {\displaystyle 3+4\cos \phi +\cos 2\phi =2(1+\cos \phi )^{2}\geq 0\;,}
  so that

  
    
      
        
          |
          
            ζ
            (
            x
            
              )
              
                3
              
            
            ζ
            (
            x
            +
            i
            y
            
              )
              
                4
              
            
            ζ
            (
            x
            +
            2
            i
            y
            )
          
          |
        
        =
        exp
        ⁡
        
          (
          
            
              ∑
              
                n
                ,
                p
              
            
            
              
                
                  3
                  +
                  4
                  cos
                  ⁡
                  (
                  n
                  y
                  log
                  ⁡
                  p
                  )
                  +
                  cos
                  ⁡
                  (
                  2
                  n
                  y
                  log
                  ⁡
                  p
                  )
                
                
                  n
                  
                    p
                    
                      n
                      x
                    
                  
                
              
            
          
          )
        
        ≥
        1
      
    
    {\displaystyle \left|\zeta (x)^{3}\zeta (x+iy)^{4}\zeta (x+2iy)\right|=\exp \left(\sum _{n,p}{\frac {3+4\cos(ny\log p)+\cos(2ny\log p)}{np^{nx}}}\right)\geq 1}
  for all x > 1. Suppose now that ζ(1 + iy) = 0. Certainly y is not zero, since ζ(s) has a simple pole at s = 1. Suppose that x > 1 and let x tend to 1 from above. Since 
  
    
      
        ζ
        (
        s
        )
      
    
    {\displaystyle \zeta (s)}
   has a simple pole at s = 1 and ζ(x + 2iy) stays analytic, the left hand side in the previous inequality tends to 0, a contradiction.
Finally, we can conclude that the PNT is heuristically true. To rigorously complete the proof there are still serious technicalities to overcome, due to the fact that the summation over zeta zeros in the explicit formula for ψ(x) does not converge absolutely but only conditionally and in a "principal value" sense. There are several ways around this problem but many of them require rather delicate complex-analytic estimates. Edwards's book provides the details. Another method is to use Ikehara's Tauberian theorem, though this theorem is itself quite hard to prove. D.J. Newman observed that the full strength of Ikehara's theorem is not needed for the prime number theorem, and one can get away with a special case that is much easier to prove.

Newman's proof of the prime number theorem
D. J. Newman gives a quick proof of the prime number theorem (PNT). The proof is "non-elementary" by virtue of relying on complex analysis, but uses only elementary techniques from a first course in the subject: Cauchy's integral formula, Cauchy's integral theorem and estimates of complex integrals. Here is a brief sketch of this proof.  See  for the complete details.
The proof uses the same preliminaries as in the previous section except instead of the function 
  
    
      
        ψ
      
    
    {\textstyle \psi }
  , the  Chebyshev function
  
    
      
        
        ϑ
        (
        x
        )
        =
        
          ∑
          
            p
            ≤
            x
          
        
        log
        ⁡
        p
      
    
    {\textstyle \quad \vartheta (x)=\sum _{p\leq x}\log p}
   is used, which is obtained by dropping some of the terms from the series for 
  
    
      
        ψ
      
    
    {\textstyle \psi }
  .  It is easy to show that the PNT is equivalent to 
  
    
      
        
          lim
          
            x
            →
            ∞
          
        
        ϑ
        (
        x
        )
        
          /
        
        x
        =
        1
      
    
    {\displaystyle \lim _{x\to \infty }\vartheta (x)/x=1}
  .  Likewise instead of 
  
    
      
        −
        
          
            
              
                ζ
                ′
              
              (
              s
              )
            
            
              ζ
              (
              s
              )
            
          
        
      
    
    {\displaystyle -{\frac {\zeta '(s)}{\zeta (s)}}}
   the function 
  
    
      
        Φ
        (
        s
        )
        =
        
          ∑
          
            p
            ≤
            x
          
        
        log
        ⁡
        p
        
        
        
          p
          
            −
            s
          
        
      
    
    {\displaystyle \Phi (s)=\sum _{p\leq x}\log p\,\,p^{-s}}
    is used, which is obtained by dropping some terms in the series for 
  
    
      
        −
        
          
            
              
                ζ
                ′
              
              (
              s
              )
            
            
              ζ
              (
              s
              )
            
          
        
      
    
    {\displaystyle -{\frac {\zeta '(s)}{\zeta (s)}}}
  .  The functions 
  
    
      
        Φ
        (
        s
        )
      
    
    {\displaystyle \Phi (s)}
    and 
  
    
      
        −
        
          ζ
          ′
        
        (
        s
        )
        
          /
        
        ζ
        (
        s
        )
      
    
    {\displaystyle -\zeta '(s)/\zeta (s)}
   differ by a function holomorphic on 
  
    
      
        ℜ
        s
        =
        1
      
    
    {\displaystyle \Re s=1}
  .  Since, as was shown in the previous section,  
  
    
      
        ζ
        (
        s
        )
      
    
    {\displaystyle \zeta (s)}
    has no zeroes on the line 
  
    
      
        ℜ
        s
        =
        1
      
    
    {\displaystyle \Re s=1}
   , 
  
    
      
        Φ
        (
        s
        )
        −
        
          
            1
            
              s
              −
              1
            
          
        
      
    
    {\displaystyle \Phi (s)-{\frac {1}{s-1}}}
   has no singularities on 
  
    
      
        ℜ
        s
        =
        1
      
    
    {\displaystyle \Re s=1}
  .
One further piece of information needed in Newman's proof, and which is the key to the estimates in his simple method, is that 
  
    
      
        ϑ
        (
        x
        )
        
          /
        
        x
      
    
    {\displaystyle \vartheta (x)/x}
    is bounded. This is proved using an ingenious and easy method due to Chebyshev.
Integration by parts  shows how 
  
    
      
        ϑ
        (
        x
        )
      
    
    {\displaystyle \vartheta (x)}
   and  
  
    
      
        Φ
        (
        s
        )
      
    
    {\displaystyle \Phi (s)}
   are related.  For 
  
    
      
        ℜ
        s
        >
        1
      
    
    {\displaystyle \Re s>1}
  , 

  
    
      
        Φ
        (
        s
        )
        =
        
          ∫
          
            1
          
          
            ∞
          
        
        
          x
          
            −
            s
          
        
        d
        ϑ
        (
        x
        )
        =
        s
        
          ∫
          
            1
          
          
            ∞
          
        
        ϑ
        (
        x
        )
        
          x
          
            −
            s
            −
            1
          
        
        
        d
        x
        =
        s
        
          ∫
          
            0
          
          
            ∞
          
        
        ϑ
        (
        
          e
          
            t
          
        
        )
        
          e
          
            −
            s
            t
          
        
        
        d
        t
        .
      
    
    {\displaystyle \Phi (s)=\int _{1}^{\infty }x^{-s}d\vartheta (x)=s\int _{1}^{\infty }\vartheta (x)x^{-s-1}\,dx=s\int _{0}^{\infty }\vartheta (e^{t})e^{-st}\,dt.}
  Newman's method proves the PNT by showing the integral 

  
    
      
        I
        =
        
          ∫
          
            0
          
          
            ∞
          
        
        
          (
          
            
              
                
                  ϑ
                  (
                  
                    e
                    
                      t
                    
                  
                  )
                
                
                  e
                  
                    t
                  
                
              
            
            −
            1
          
          )
        
        
        d
        t
        .
      
    
    {\displaystyle I=\int _{0}^{\infty }\left({\frac {\vartheta (e^{t})}{e^{t}}}-1\right)\,dt.}
  converges, and therefore the integrand goes to zero as 
  
    
      
        t
        →
        ∞
      
    
    {\displaystyle t\to \infty }
  , which is  the PNT. In general, the convergence of the improper integral does not imply that the integrand goes to zero at infinity, since it may oscillate, but since 
  
    
      
        ϑ
      
    
    {\displaystyle \vartheta }
    is increasing, it is easy to show in this case.
To show the convergence of 
  
    
      
        I
      
    
    {\displaystyle I}
  , for 
  
    
      
        ℜ
        z
        >
        0
      
    
    {\displaystyle \Re z>0}
    let 

  
    
      
        
          g
          
            T
          
        
        (
        z
        )
        =
        
          ∫
          
            0
          
          
            T
          
        
        f
        (
        t
        )
        
          e
          
            −
            z
            t
          
        
        
        d
        t
      
    
    {\displaystyle g_{T}(z)=\int _{0}^{T}f(t)e^{-zt}\,dt}
    and  
  
    
      
        g
        (
        z
        )
        =
        
          ∫
          
            0
          
          
            ∞
          
        
        f
        (
        t
        )
        
          e
          
            −
            z
            t
          
        
        
        d
        t
      
    
    {\displaystyle g(z)=\int _{0}^{\infty }f(t)e^{-zt}\,dt}
   where 
  
    
      
        f
        (
        t
        )
        =
        
          
            
              ϑ
              (
              
                e
                
                  t
                
              
              )
            
            
              e
              
                t
              
            
          
        
        −
        1
      
    
    {\displaystyle f(t)={\frac {\vartheta (e^{t})}{e^{t}}}-1}
  then

  
    
      
        
          lim
          
            T
            →
            ∞
          
        
        
          g
          
            T
          
        
        (
        z
        )
        =
        g
        (
        z
        )
        =
        
          
            
              Φ
              (
              s
              )
            
            s
          
        
        −
        
          
            1
            
              s
              −
              1
            
          
        
        
        
        
          where
        
        
        z
        =
        s
        −
        1
      
    
    {\displaystyle \lim _{T\to \infty }g_{T}(z)=g(z)={\frac {\Phi (s)}{s}}-{\frac {1}{s-1}}\quad \quad {\text{where}}\quad z=s-1}
  which is equal to a function holomorphic on the line 
  
    
      
        ℜ
        z
        =
        0
      
    
    {\displaystyle \Re z=0}
   .
The convergence of the integral 
  
    
      
        I
      
    
    {\displaystyle I}
  , and thus the PNT, is proved by showing that 
  
    
      
        
          lim
          
            T
            →
            ∞
          
        
        
          g
          
            T
          
        
        (
        0
        )
        =
        g
        (
        0
        )
      
    
    {\displaystyle \lim _{T\to \infty }g_{T}(0)=g(0)}
  . This involves change of order of limits since it can be written 
  
    
      
        
          lim
          
            T
            →
            ∞
          
        
        
          lim
          
            z
            →
            0
          
        
        
          g
          
            T
          
        
        (
        z
        )
        =
        
          lim
          
            z
            →
            0
          
        
        
          lim
          
            T
            →
            ∞
          
        
        
          g
          
            T
          
        
        (
        z
        )
      
    
    {\textstyle \lim _{T\to \infty }\lim _{z\to 0}g_{T}(z)=\lim _{z\to 0}\lim _{T\to \infty }g_{T}(z)}
   and therefore classified as a Tauberian theorem.
The difference 
  
    
      
        g
        (
        0
        )
        −
        
          g
          
            T
          
        
        (
        0
        )
      
    
    {\displaystyle g(0)-g_{T}(0)}
    is expressed using Cauchy's integral formula and then shown to be small for 
  
    
      
        T
      
    
    {\displaystyle T}
   large by estimating the integrand. Fix 
  
    
      
        R
        >
        0
      
    
    {\displaystyle R>0}
    and 
  
    
      
        δ
        >
        0
      
    
    {\displaystyle \delta >0}
    such that 
  
    
      
        g
        (
        z
        )
      
    
    {\displaystyle g(z)}
    is holomorphic in the region  where 
  
    
      
        
          |
        
        z
        
          |
        
        ≤
        R
        
           and 
        
        ℜ
        z
        ≥
        −
        δ
      
    
    {\displaystyle |z|\leq R{\text{ and }}\Re z\geq -\delta }
  ,  and let 
  
    
      
        C
      
    
    {\displaystyle C}
    be the boundary of this region.  Since 0 is in the interior of the region, Cauchy's integral formula gives 

  
    
      
        g
        (
        0
        )
        −
        
          g
          
            T
          
        
        (
        0
        )
        =
        
          
            1
            
              2
              π
              i
            
          
        
        
          ∫
          
            C
          
        
        
          (
          
            g
            (
            z
            )
            −
            
              g
              
                T
              
            
            (
            z
            )
          
          )
        
        
          
            
              d
              z
            
            z
          
        
        =
        
          
            1
            
              2
              π
              i
            
          
        
        
          ∫
          
            C
          
        
        
          (
          
            g
            (
            z
            )
            −
            
              g
              
                T
              
            
            (
            z
            )
          
          )
        
        F
        (
        z
        )
        
          
            
              d
              z
            
            z
          
        
      
    
    {\displaystyle g(0)-g_{T}(0)={\frac {1}{2\pi i}}\int _{C}\left(g(z)-g_{T}(z)\right){\frac {dz}{z}}={\frac {1}{2\pi i}}\int _{C}\left(g(z)-g_{T}(z)\right)F(z){\frac {dz}{z}}}
  where 
  
    
      
        F
        (
        z
        )
        =
        
          e
          
            z
            T
          
        
        
          (
          
            1
            +
            
              
                
                  z
                  
                    2
                  
                
                
                  R
                  
                    2
                  
                
              
            
          
          )
        
      
    
    {\displaystyle F(z)=e^{zT}\left(1+{\frac {z^{2}}{R^{2}}}\right)}
   is the factor introduced by Newman, which does not change the integral since 
  
    
      
        F
      
    
    {\displaystyle F}
    is entire and 
  
    
      
        F
        (
        0
        )
        =
        1
      
    
    {\displaystyle F(0)=1}
  .
To estimate the integral, break the contour 
  
    
      
        C
      
    
    {\displaystyle C}
   into two parts, 
  
    
      
        C
        =
        
          C
          
            +
          
        
        +
        
          C
          
            −
          
        
      
    
    {\displaystyle C=C_{+}+C_{-}}
   where  
  
    
      
        
          C
          
            +
          
        
        =
        C
        ∩
        
          {
          
            z
            
            |
            
            ℜ
            z
            >
            0
          
          }
        
      
    
    {\displaystyle C_{+}=C\cap \left\{z\,\vert \,\Re z>0\right\}}
    and 
  
    
      
        
          C
          
            −
          
        
        ∩
        
          {
          
            ℜ
            z
            ≤
            0
          
          }
        
      
    
    {\displaystyle C_{-}\cap \left\{\Re z\leq 0\right\}}
  .  Then 
  
    
      
        g
        (
        0
        )
        −
        
          g
          
            T
          
        
        (
        0
        )
        =
        
          ∫
          
            
              C
              
                +
              
            
          
        
        
          ∫
          
            T
          
          
            ∞
          
        
        H
        (
        t
        ,
        z
        )
        d
        t
        d
        z
        −
        
          ∫
          
            
              C
              
                −
              
            
          
        
        
          ∫
          
            0
          
          
            T
          
        
        H
        (
        t
        ,
        z
        )
        d
        t
        d
        z
        +
        
          ∫
          
            
              C
              
                −
              
            
          
        
        g
        (
        z
        )
        F
        (
        z
        )
        
          
            
              d
              z
            
            
              2
              π
              i
              z
            
          
        
      
    
    {\displaystyle g(0)-g_{T}(0)=\int _{C_{+}}\int _{T}^{\infty }H(t,z)dtdz-\int _{C_{-}}\int _{0}^{T}H(t,z)dtdz+\int _{C_{-}}g(z)F(z){\frac {dz}{2\pi iz}}}
  where 
  
    
      
        H
        (
        t
        ,
        z
        )
        =
        f
        (
        t
        )
        
          e
          
            −
            t
            z
          
        
        F
        (
        z
        )
        
          /
        
        2
        π
        i
      
    
    {\displaystyle H(t,z)=f(t)e^{-tz}F(z)/2\pi i}
  .  Since 
  
    
      
        ϑ
        (
        x
        )
        
          /
        
        x
      
    
    {\displaystyle \vartheta (x)/x}
  , and hence  
  
    
      
        f
        (
        t
        )
      
    
    {\displaystyle f(t)}
  , is bounded, let 
  
    
      
        B
      
    
    {\displaystyle B}
    be an upper bound for the absolute value of 
  
    
      
        f
        (
        t
        )
      
    
    {\displaystyle f(t)}
  . This bound together with the estimate  
  
    
      
        
          |
        
        F
        
          |
        
        ≤
        2
        exp
        ⁡
        (
        T
        ℜ
        z
        )
        
          |
        
        ℜ
        z
        
          |
        
        
          /
        
        R
      
    
    {\displaystyle |F|\leq 2\exp(T\Re z)|\Re z|/R}
   for 
  
    
      
        
          |
        
        z
        
          |
        
        =
        R
      
    
    {\displaystyle |z|=R}
   gives that the first integral in absolute value is 
  
    
      
        ≤
        B
        
          /
        
        R
      
    
    {\displaystyle \leq B/R}
  .  The integrand over 
  
    
      
        
          C
          
            −
          
        
      
    
    {\displaystyle C_{-}}
   in the second integral is entire, so by Cauchy's integral theorem, the contour 
  
    
      
        
          C
          
            −
          
        
      
    
    {\displaystyle C_{-}}
    can be modified to a semicircle of radius 
  
    
      
        R
      
    
    {\displaystyle R}
    in the left half-plane without changing the integral, and the same argument as for the first integral gives the absolute value of the second integral is 
  
    
      
        ≤
        B
        
          /
        
        R
      
    
    {\displaystyle \leq B/R}
  .  Finally, letting 
  
    
      
        T
        →
        ∞
      
    
    {\displaystyle T\to \infty }
   , the third integral goes to zero since 
  
    
      
        
          e
          
            z
            T
          
        
      
    
    {\displaystyle e^{zT}}
    and hence 
  
    
      
        F
      
    
    {\displaystyle F}
   goes to zero on the contour. Combining the two estimates and the limit get

  
    
      
        
          lim sup
          
            T
            →
            ∞
          
        
        
          |
        
        g
        (
        0
        )
        −
        
          g
          
            T
          
        
        (
        0
        )
        
          |
        
        ≤
        
          
            
              2
              B
            
            R
          
        
        .
      
    
    {\displaystyle \limsup _{T\to \infty }|g(0)-g_{T}(0)|\leq {\frac {2B}{R}}.}
  This holds for any 
  
    
      
        R
      
    
    {\displaystyle R}
    so 
  
    
      
        
          lim
          
            T
            →
            ∞
          
        
        
          g
          
            T
          
        
        (
        0
        )
        =
        g
        (
        0
        )
      
    
    {\displaystyle \lim _{T\to \infty }g_{T}(0)=g(0)}
  , and the PNT follows.

Prime-counting function in terms of the logarithmic integral
In a handwritten note on a reprint of his 1838 paper "Sur l'usage des séries infinies dans la théorie des nombres", which he mailed to Gauss, Dirichlet conjectured (under a slightly different form appealing to a series rather than an integral) that an even better approximation to π(x) is given by the offset logarithmic integral function Li(x), defined by

  
    
      
        Li
        ⁡
        (
        x
        )
        =
        
          ∫
          
            2
          
          
            x
          
        
        
          
            
              d
              t
            
            
              log
              ⁡
              t
            
          
        
        =
        li
        ⁡
        (
        x
        )
        −
        li
        ⁡
        (
        2
        )
        .
      
    
    {\displaystyle \operatorname {Li} (x)=\int _{2}^{x}{\frac {dt}{\log t}}=\operatorname {li} (x)-\operatorname {li} (2).}
  Indeed, this integral is strongly suggestive of the notion that the "density" of primes around t should be 1 / log t. This function is related to the logarithm by the asymptotic expansion

  
    
      
        Li
        ⁡
        (
        x
        )
        ∼
        
          
            x
            
              log
              ⁡
              x
            
          
        
        
          ∑
          
            k
            =
            0
          
          
            ∞
          
        
        
          
            
              k
              !
            
            
              (
              log
              ⁡
              x
              
                )
                
                  k
                
              
            
          
        
        =
        
          
            x
            
              log
              ⁡
              x
            
          
        
        +
        
          
            x
            
              (
              log
              ⁡
              x
              
                )
                
                  2
                
              
            
          
        
        +
        
          
            
              2
              x
            
            
              (
              log
              ⁡
              x
              
                )
                
                  3
                
              
            
          
        
        +
        ⋯
      
    
    {\displaystyle \operatorname {Li} (x)\sim {\frac {x}{\log x}}\sum _{k=0}^{\infty }{\frac {k!}{(\log x)^{k}}}={\frac {x}{\log x}}+{\frac {x}{(\log x)^{2}}}+{\frac {2x}{(\log x)^{3}}}+\cdots }
  So, the prime number theorem can also be written as π(x) ~ Li(x). In fact, in another paper in 1899 de la Vallée Poussin proved that

  
    
      
        π
        (
        x
        )
        =
        Li
        ⁡
        (
        x
        )
        +
        O
        
          (
          
            x
            
              e
              
                −
                a
                
                  
                    log
                    ⁡
                    x
                  
                
              
            
          
          )
        
        
        
          as 
        
        x
        →
        ∞
      
    
    {\displaystyle \pi (x)=\operatorname {Li} (x)+O\left(xe^{-a{\sqrt {\log x}}}\right)\quad {\text{as }}x\to \infty }
  for some positive constant a, where O(...) is the big O notation. This has been improved to

  
    
      
        π
        (
        x
        )
        =
        li
        ⁡
        (
        x
        )
        +
        O
        
          (
          
            x
            exp
            ⁡
            
              (
              
                −
                
                  
                    
                      A
                      (
                      log
                      ⁡
                      x
                      
                        )
                        
                          
                            3
                            5
                          
                        
                      
                    
                    
                      (
                      log
                      ⁡
                      log
                      ⁡
                      x
                      
                        )
                        
                          
                            1
                            5
                          
                        
                      
                    
                  
                
              
              )
            
          
          )
        
      
    
    {\displaystyle \pi (x)=\operatorname {li} (x)+O\left(x\exp \left(-{\frac {A(\log x)^{\frac {3}{5}}}{(\log \log x)^{\frac {1}{5}}}}\right)\right)}
   where 
  
    
      
        A
        =
        0.2098
      
    
    {\displaystyle A=0.2098}
  .In 2016, Trudgian proved an explicit upper bound for the difference between 
  
    
      
        π
        (
        x
        )
      
    
    {\displaystyle \pi (x)}
   and 
  
    
      
        li
        ⁡
        (
        x
        )
      
    
    {\displaystyle \operatorname {li} (x)}
  :

  
    
      
        
          
            |
          
        
        π
        (
        x
        )
        −
        li
        ⁡
        (
        x
        )
        
          
            |
          
        
        ≤
        0.2795
        
          
            x
            
              (
              log
              ⁡
              x
              
                )
                
                  3
                  
                    /
                  
                  4
                
              
            
          
        
        exp
        ⁡
        
          (
          
            −
            
              
                
                  
                    log
                    ⁡
                    x
                  
                  6.455
                
              
            
          
          )
        
      
    
    {\displaystyle {\big |}\pi (x)-\operatorname {li} (x){\big |}\leq 0.2795{\frac {x}{(\log x)^{3/4}}}\exp \left(-{\sqrt {\frac {\log x}{6.455}}}\right)}
  for 
  
    
      
        x
        ≥
        229
      
    
    {\displaystyle x\geq 229}
  .The connection between the Riemann zeta function and π(x) is one reason the Riemann hypothesis has considerable importance in number theory: if established, it would yield a far better estimate of the error involved in the prime number theorem than is available today. More specifically, Helge von Koch showed in 1901 that if the Riemann hypothesis is true, the error term in the above relation can be improved to

  
    
      
        π
        (
        x
        )
        =
        Li
        ⁡
        (
        x
        )
        +
        O
        
          (
          
            
              
                x
              
            
            log
            ⁡
            x
          
          )
        
      
    
    {\displaystyle \pi (x)=\operatorname {Li} (x)+O\left({\sqrt {x}}\log x\right)}
  (this last estimate is in fact equivalent to the Riemann hypothesis). The constant involved in the big O notation was estimated in 1976 by Lowell Schoenfeld: assuming the Riemann hypothesis,

  
    
      
        
          
            |
          
        
        π
        (
        x
        )
        −
        li
        ⁡
        (
        x
        )
        
          
            |
          
        
        <
        
          
            
              
                
                  x
                
              
              log
              ⁡
              x
            
            
              8
              π
            
          
        
      
    
    {\displaystyle {\big |}\pi (x)-\operatorname {li} (x){\big |}<{\frac {{\sqrt {x}}\log x}{8\pi }}}
  for all x ≥ 2657. He also derived a similar bound for the Chebyshev prime-counting function ψ:

  
    
      
        
          
            |
          
        
        ψ
        (
        x
        )
        −
        x
        
          
            |
          
        
        <
        
          
            
              
                
                  x
                
              
              (
              log
              ⁡
              x
              
                )
                
                  2
                
              
            
            
              8
              π
            
          
        
      
    
    {\displaystyle {\big |}\psi (x)-x{\big |}<{\frac {{\sqrt {x}}(\log x)^{2}}{8\pi }}}
  for all x ≥ 73.2 . This latter bound has been shown to express a variance to mean power law (when regarded as a random function over the integers) and 1/ f  noise and to also correspond to the Tweedie compound Poisson distribution. (The Tweedie distributions represent a family of scale invariant distributions that serve as foci of convergence for a generalization of the central limit theorem.)
The logarithmic integral li(x) is larger than π(x) for "small" values of x. This is because it is (in some sense) counting not primes, but prime powers, where a power pn of a prime p is counted as 1/ n  of a prime. This suggests that li(x) should usually be larger than π(x) by roughly 
  
    
      
         
        
          
            
              1
              2
            
          
        
        li
        ⁡
        (
        
          
            x
          
        
        )
         
        ,
      
    
    {\displaystyle \ {\tfrac {1}{2}}\operatorname {li} ({\sqrt {x}})\ ,}
   and in particular should always be larger than π(x). However, in 1914, J. E. Littlewood proved that 
  
    
      
         
        π
        (
        x
        )
        −
        li
        ⁡
        (
        x
        )
         
      
    
    {\displaystyle \ \pi (x)-\operatorname {li} (x)\ }
   changes sign infinitely often. The first value of x where π(x) exceeds li(x) is probably around x ~ 10316 ; see the article on Skewes' number for more details. (On the other hand, the offset logarithmic integral Li(x) is smaller than π(x) already for x = 2; indeed, Li(2) = 0, while π(2) = 1.)

Elementary proofs
In the first half of the twentieth century, some mathematicians (notably G. H. Hardy) believed that there exists a hierarchy of proof methods in mathematics depending on what sorts of numbers (integers, reals, complex) a proof requires, and that the prime number theorem (PNT) is a "deep" theorem by virtue of requiring complex analysis. This belief was somewhat shaken by a proof of the PNT based on Wiener's tauberian theorem, though this could be set aside if Wiener's theorem were deemed to have a "depth" equivalent to that of complex variable methods.
In March 1948, Atle Selberg established, by "elementary" means, the asymptotic formula

  
    
      
        ϑ
        (
        x
        )
        log
        ⁡
        (
        x
        )
        +
        
          ∑
          
            p
            ≤
            x
          
        
        
          log
          ⁡
          (
          p
          )
        
         
        ϑ
        
          (
          
            
              x
              p
            
          
          )
        
        =
        2
        x
        log
        ⁡
        (
        x
        )
        +
        O
        (
        x
        )
      
    
    {\displaystyle \vartheta (x)\log(x)+\sum \limits _{p\leq x}{\log(p)}\ \vartheta \left({\frac {x}{p}}\right)=2x\log(x)+O(x)}
  where

  
    
      
        ϑ
        (
        x
        )
        =
        
          ∑
          
            p
            ≤
            x
          
        
        
          log
          ⁡
          (
          p
          )
        
      
    
    {\displaystyle \vartheta (x)=\sum \limits _{p\leq x}{\log(p)}}
  for primes p. By July of that year, Selberg and Paul Erdős had each obtained elementary proofs of the PNT, both using Selberg's asymptotic formula as a starting point. These proofs effectively laid to rest the notion that the PNT was "deep" in that sense, and showed that technically "elementary" methods were more powerful than had been believed to be the case. On the history of the elementary proofs of the PNT, including the Erdős–Selberg priority dispute, see an article by Dorian Goldfeld.There is some debate about the significance of Erdős and Selberg's result. There is no rigorous and widely accepted definition of the notion of elementary proof in number theory, so it is not clear exactly in what sense their proof is "elementary". Although it does not use complex analysis, it is in fact much more technical than the standard proof of PNT. One possible definition of an "elementary" proof is "one that can be carried out in first-order Peano arithmetic." There are number-theoretic statements (for example, the Paris–Harrington theorem) provable using second order but not first-order methods, but such theorems are rare to date. Erdős and Selberg's proof can certainly be formalized in Peano arithmetic, and in 1994, Charalambos Cornaros and Costas Dimitracopoulos proved that their proof can be formalized in a very weak fragment of PA, namely IΔ0 + exp. However, this does not address the question of whether or not the standard proof of PNT can be formalized in PA.

Computer verifications
In 2005, Avigad et al. employed the Isabelle theorem prover to devise a computer-verified variant of the Erdős–Selberg proof of the PNT. This was the first machine-verified proof of the PNT. Avigad chose to formalize the Erdős–Selberg proof rather than an analytic one because while Isabelle's library at the time could implement the notions of limit, derivative, and transcendental function, it had almost no theory of integration to speak of.: 19 In 2009, John Harrison employed HOL Light to formalize a proof employing complex analysis. By developing the necessary analytic machinery, including the Cauchy integral formula, Harrison was able to formalize "a direct, modern and elegant proof instead of the more involved 'elementary' Erdős–Selberg argument".

Prime number theorem for arithmetic progressions
Let πd,a(x) denote the number of primes in the arithmetic progression a, a + d, a + 2d, a + 3d, ... that are less than x. Dirichlet and Legendre conjectured, and de la Vallée Poussin proved, that if a and d are coprime, then

  
    
      
        
          π
          
            d
            ,
            a
          
        
        (
        x
        )
        ∼
        
          
            
              Li
              ⁡
              (
              x
              )
            
            
              φ
              (
              d
              )
            
          
        
         
        ,
      
    
    {\displaystyle \pi _{d,a}(x)\sim {\frac {\operatorname {Li} (x)}{\varphi (d)}}\ ,}
  where φ is Euler's totient function. In other words, the primes are distributed evenly among the residue classes [a] modulo d with gcd(a, d) = 1 . This is stronger than Dirichlet's theorem on arithmetic progressions (which only states that there is an infinity of primes in each class) and can be proved using similar methods used by Newman for his proof of the prime number theorem.The Siegel–Walfisz theorem gives a good estimate for the distribution of primes in residue classes.
Bennett et al. 
proved the following estimate that has explicit constants A and B (Theorem 1.3):
Let d 
  
    
      
        ≥
        3
      
    
    {\displaystyle \geq 3}
   be an integer and let a be an integer that is coprime to d. Then there are positive constants A and B such that

  
    
      
        
          |
          
            
              π
              
                d
                ,
                a
              
            
            (
            x
            )
            −
            
              
                
                   
                  Li
                  ⁡
                  (
                  x
                  )
                   
                
                
                   
                  φ
                  (
                  d
                  )
                   
                
              
            
          
          |
        
        <
        
          
            
              A
               
              x
            
            
               
              (
              log
              ⁡
              x
              
                )
                
                  2
                
              
               
            
          
        
        
        
           for all 
        
        
        x
        ≥
        B
         
        ,
      
    
    {\displaystyle \left|\pi _{d,a}(x)-{\frac {\ \operatorname {Li} (x)\ }{\ \varphi (d)\ }}\right|<{\frac {A\ x}{\ (\log x)^{2}\ }}\quad {\text{ for all }}\quad x\geq B\ ,}
  where

  
    
      
        A
        =
        
          
            1
            
               
              840
               
            
          
        
        
        
           if 
        
        
        3
        ≤
        d
        ≤
        
          10
          
            4
          
        
        
        
           and 
        
        
        A
        =
        
          
            1
            
               
              160
               
            
          
        
        
        
           if 
        
        
        d
        >
        
          10
          
            4
          
        
         
        ,
      
    
    {\displaystyle A={\frac {1}{\ 840\ }}\quad {\text{ if }}\quad 3\leq d\leq 10^{4}\quad {\text{ and }}\quad A={\frac {1}{\ 160\ }}\quad {\text{ if }}\quad d>10^{4}~,}
  and

  
    
      
        B
        =
        8
        ⋅
        
          10
          
            9
          
        
        
        
           if 
        
        
        3
        ≤
        d
        ≤
        
          10
          
            5
          
        
        
        
           and 
        
        
        B
        =
        exp
        ⁡
        (
         
        0.03
         
        
          
            d
             
          
        
         
        (
        log
        ⁡
        
          d
        
        
          )
          
            3
          
        
         
        )
        
        
           if 
        
        
        d
        >
        
          10
          
            5
          
        
         
        .
      
    
    {\displaystyle B=8\cdot 10^{9}\quad {\text{ if }}\quad 3\leq d\leq 10^{5}\quad {\text{ and }}\quad B=\exp(\ 0.03\ {\sqrt {d\ }}\ (\log {d})^{3}\ )\quad {\text{ if }}\quad d>10^{5}\ .}

Prime number race
Although we have in particular

  
    
      
        
          π
          
            4
            ,
            1
          
        
        (
        x
        )
        ∼
        
          π
          
            4
            ,
            3
          
        
        (
        x
        )
         
        ,
      
    
    {\displaystyle \pi _{4,1}(x)\sim \pi _{4,3}(x)\ ,}
  empirically the primes congruent to 3 are more numerous and are nearly always ahead in this "prime number race"; the first reversal occurs at x = 26861.: 1–2  However Littlewood showed in 1914: 2  that there are infinitely many sign changes for the function

  
    
      
        
          π
          
            4
            ,
            1
          
        
        (
        x
        )
        −
        
          π
          
            4
            ,
            3
          
        
        (
        x
        )
         
        ,
      
    
    {\displaystyle \pi _{4,1}(x)-\pi _{4,3}(x)~,}
  so the lead in the race switches back and forth infinitely many times. The phenomenon that π4,3(x) is ahead most of the time is called Chebyshev's bias. The prime number race generalizes to other moduli and is the subject of much research; Pál Turán asked whether it is always the case that π(x;a,c) and π(x;b,c) change places when a and b are coprime to c. Granville and Martin give a thorough exposition and survey.

Non-asymptotic bounds on the prime-counting function
The prime number theorem is an asymptotic result. It gives an ineffective bound on π(x) as a direct consequence of the definition of the limit: for all ε > 0, there is an S such that for all x > S,

  
    
      
        (
        1
        −
        ε
        )
        
          
            x
            
              log
              ⁡
              x
            
          
        
        
        <
        
        π
        (
        x
        )
        
        <
        
        (
        1
        +
        ε
        )
        
          
            x
            
              log
              ⁡
              x
            
          
        
        
        .
      
    
    {\displaystyle (1-\varepsilon ){\frac {x}{\log x}}\;<\;\pi (x)\;<\;(1+\varepsilon ){\frac {x}{\log x}}\;.}
  However, better bounds on π(x) are known, for instance Pierre Dusart's

  
    
      
        
          
            x
            
              log
              ⁡
              x
            
          
        
        
          (
          
            1
            +
            
              
                1
                
                  log
                  ⁡
                  x
                
              
            
          
          )
        
        
        <
        
        π
        (
        x
        )
        
        <
        
        
          
            x
            
              log
              ⁡
              x
            
          
        
        
          (
          
            1
            +
            
              
                1
                
                  log
                  ⁡
                  x
                
              
            
            +
            
              
                2.51
                
                  (
                  log
                  ⁡
                  x
                  
                    )
                    
                      2
                    
                  
                
              
            
          
          )
        
        
        .
      
    
    {\displaystyle {\frac {x}{\log x}}\left(1+{\frac {1}{\log x}}\right)\;<\;\pi (x)\;<\;{\frac {x}{\log x}}\left(1+{\frac {1}{\log x}}+{\frac {2.51}{(\log x)^{2}}}\right)\;.}
  The first inequality holds for all x ≥ 599 and the second one for x ≥ 355991.A weaker but sometimes useful bound for x ≥ 55 is

  
    
      
        
          
            x
            
              log
              ⁡
              x
              +
              2
            
          
        
        
        <
        
        π
        (
        x
        )
        
        <
        
        
          
            x
            
              log
              ⁡
              x
              −
              4
            
          
        
        
        .
      
    
    {\displaystyle {\frac {x}{\log x+2}}\;<\;\pi (x)\;<\;{\frac {x}{\log x-4}}\;.}
  In Pierre Dusart's thesis there are stronger versions of this type of inequality that are valid for larger x. Later in 2010, Dusart proved:

  
    
      
        
          
            
              
                
                  
                    x
                    
                      log
                      ⁡
                      x
                      −
                      1
                    
                  
                
                
              
              
                
                <
                
                π
                (
                x
                )
              
              
              
                
                   for 
                
                x
                ≥
                5393
                
                ,
                
                   and 
                
              
            
            
              
                π
                (
                x
                )
                
              
              
                
                <
                
                
                  
                    x
                    
                      log
                      ⁡
                      x
                      −
                      1.1
                    
                  
                
              
              
              
                
                   for 
                
                x
                ≥
                60184
                
                .
              
            
          
        
      
    
    {\displaystyle {\begin{aligned}{\frac {x}{\log x-1}}\;&<\;\pi (x)&&{\text{  for }}x\geq 5393\;,{\text{   and }}\\\pi (x)\;&<\;{\frac {x}{\log x-1.1}}&&{\text{  for }}x\geq 60184\;.\end{aligned}}}
  The proof by de la Vallée Poussin implies the following: For every ε > 0, there is an S such that for all x > S,

  
    
      
        
          
            x
            
              log
              ⁡
              x
              −
              (
              1
              −
              ε
              )
            
          
        
        
        <
        
        π
        (
        x
        )
        
        <
        
        
          
            x
            
              log
              ⁡
              x
              −
              (
              1
              +
              ε
              )
            
          
        
        
        .
      
    
    {\displaystyle {\frac {x}{\log x-(1-\varepsilon )}}\;<\;\pi (x)\;<\;{\frac {x}{\log x-(1+\varepsilon )}}\;.}

Approximations for the nth prime number
As a consequence of the prime number theorem, one gets an asymptotic expression for the nth prime number, denoted by pn:

  
    
      
        
          p
          
            n
          
        
        ∼
        n
        log
        ⁡
        n
        .
      
    
    {\displaystyle p_{n}\sim n\log n.}
  A better approximation is

  
    
      
        
          
            
              p
              
                n
              
            
            n
          
        
        =
        log
        ⁡
        n
        +
        log
        ⁡
        log
        ⁡
        n
        −
        1
        +
        
          
            
              log
              ⁡
              log
              ⁡
              n
              −
              2
            
            
              log
              ⁡
              n
            
          
        
        −
        
          
            
              (
              log
              ⁡
              log
              ⁡
              n
              
                )
                
                  2
                
              
              −
              6
              log
              ⁡
              log
              ⁡
              n
              +
              11
            
            
              2
              (
              log
              ⁡
              n
              
                )
                
                  2
                
              
            
          
        
        +
        o
        
          (
          
            
              1
              
                (
                log
                ⁡
                n
                
                  )
                  
                    2
                  
                
              
            
          
          )
        
        .
      
    
    {\displaystyle {\frac {p_{n}}{n}}=\log n+\log \log n-1+{\frac {\log \log n-2}{\log n}}-{\frac {(\log \log n)^{2}-6\log \log n+11}{2(\log n)^{2}}}+o\left({\frac {1}{(\log n)^{2}}}\right).}
  Again considering the 2×1017th prime number 8512677386048191063, this gives an estimate of 8512681315554715386; the first 5 digits match and relative error is about 0.00005%.
Rosser's theorem states that 

  
    
      
        
          p
          
            n
          
        
        >
        n
        log
        ⁡
        n
        .
      
    
    {\displaystyle p_{n}>n\log n.}
  This can be improved by the following pair of bounds:

  
    
      
        log
        ⁡
        n
        +
        log
        ⁡
        log
        ⁡
        n
        −
        1
        <
        
          
            
              p
              
                n
              
            
            n
          
        
        <
        log
        ⁡
        n
        +
        log
        ⁡
        log
        ⁡
        n
        
        
          for 
        
        n
        ≥
        6.
      
    
    {\displaystyle \log n+\log \log n-1<{\frac {p_{n}}{n}}<\log n+\log \log n\quad {\text{for }}n\geq 6.}

Table of π(x), x / log x, and li(x)
The table compares exact values of π(x) to the two approximations x / log x and li(x). The last column, x / π(x), is the average prime gap below x.

The value for π(1024) was originally computed assuming the Riemann hypothesis; it has since been verified unconditionally.

Analogue for irreducible polynomials over a finite field
There is an analogue of the prime number theorem that describes the "distribution" of irreducible polynomials over a finite field; the form it takes is strikingly similar to the case of the classical prime number theorem.
To state it precisely, let F = GF(q) be the finite field with q elements, for some fixed q, and let Nn be the number of monic irreducible polynomials over F whose degree is equal to n. That is, we are looking at polynomials with coefficients chosen from F, which cannot be written as products of polynomials of smaller degree. In this setting, these polynomials play the role of the prime numbers, since all other monic polynomials are built up of products of them. One can then prove that

  
    
      
        
          N
          
            n
          
        
        ∼
        
          
            
              q
              
                n
              
            
            n
          
        
        .
      
    
    {\displaystyle N_{n}\sim {\frac {q^{n}}{n}}.}
  If we make the substitution x = qn, then the right hand side is just

  
    
      
        
          
            x
            
              
                log
                
                  q
                
              
              ⁡
              x
            
          
        
        ,
      
    
    {\displaystyle {\frac {x}{\log _{q}x}},}
  which makes the analogy clearer. Since there are precisely qn monic polynomials of degree n (including the reducible ones), this can be rephrased as follows: if a monic polynomial of degree n is selected randomly, then the probability of it being irreducible is about 1/n.
One can even prove an analogue of the Riemann hypothesis, namely that

  
    
      
        
          N
          
            n
          
        
        =
        
          
            
              q
              
                n
              
            
            n
          
        
        +
        O
        
          (
          
            
              
                q
                
                  
                    n
                    2
                  
                
              
              n
            
          
          )
        
        .
      
    
    {\displaystyle N_{n}={\frac {q^{n}}{n}}+O\left({\frac {q^{\frac {n}{2}}}{n}}\right).}
  The proofs of these statements are far simpler than in the classical case. It involves a short, combinatorial argument, summarised as follows: every element of the degree n extension of F is a root of some irreducible polynomial whose degree d divides n; by counting these roots in two different ways one establishes that

  
    
      
        
          q
          
            n
          
        
        =
        
          ∑
          
            d
            ∣
            n
          
        
        d
        
          N
          
            d
          
        
        ,
      
    
    {\displaystyle q^{n}=\sum _{d\mid n}dN_{d},}
  where the sum is over all divisors d of n. Möbius inversion then yields

  
    
      
        
          N
          
            n
          
        
        =
        
          
            1
            n
          
        
        
          ∑
          
            d
            ∣
            n
          
        
        μ
        
          (
          
            
              n
              d
            
          
          )
        
        
          q
          
            d
          
        
        ,
      
    
    {\displaystyle N_{n}={\frac {1}{n}}\sum _{d\mid n}\mu \left({\frac {n}{d}}\right)q^{d},}
  where μ(k) is the Möbius function. (This formula was known to Gauss.) The main term occurs for d = n, and it is not difficult to bound the remaining terms. The "Riemann hypothesis" statement depends on the fact that the largest proper divisor of n can be no larger than n/2.

See also
Abstract analytic number theory for information about generalizations of the theorem.
Landau prime ideal theorem for a generalization to prime ideals in algebraic number fields.
Riemann hypothesis

Citations
References
Granville, Andrew (1995). "Harald Cramér and the distribution of prime numbers" (PDF). Scandinavian Actuarial Journal. 1: 12–28. CiteSeerX 10.1.1.129.6847. doi:10.1080/03461238.1995.10413946.
Hardy, G.H.; Littlewood, J.E. (1916). "Contributions to the theory of the Riemann zeta-function and the theory of the distribution of primes". Acta Mathematica. 41: 119–196. doi:10.1007/BF02422942. S2CID 53405990.
Hardy, G. H.; Wright, E. M. (2008) [1st ed. 1938], An Introduction to the Theory of Numbers, Revised by D. R. Heath-Brown and J. H. Silverman, with a foreword by Andrew Wiles (6th ed.), Oxford: Oxford University Press, ISBN 978-0-19-921985-8
Narkiewicz, Władysław (2000), The Development of Prime Number Theory: From Euclid to Hardy and Littlewood, Springer Monographs in Mathematics, Springer-Verlag, doi:10.1007/978-3-662-13157-2, ISBN 978-3-540-66289-1, ISSN 1439-7382

External links
"Distribution of prime numbers", Encyclopedia of Mathematics, EMS Press, 2001 [1994]
Table of Primes by Anton Felkel.
Short video visualizing the Prime Number Theorem.
Prime formulas and Prime number theorem at MathWorld.
How Many Primes Are There? Archived 2012-10-15 at the Wayback Machine and The Gaps between Primes by Chris Caldwell, University of Tennessee at Martin.
Tables of prime-counting functions by Tomás Oliveira e Silva
Eberl, Manuel and Paulson, L. C. The Prime Number Theorem (Formal proof development in Isabelle/HOL, Archive of Formal Proofs)
The Prime Number Theorem: the "elementary" proof −  An exposition of the elementary proof of the Prime Number Theorem of Atle Selberg and Paul Erdős at www.dimostriamogoldbach.it/en/