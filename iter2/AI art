Artificial intelligence art is any visual artwork created through the use of artificial intelligence (AI) programs.Artists began to create AI art in the mid to late-20th century, when the discipline was founded. In the early 21st century, the availability of AI art tools to the general public increased, providing opportunities for use outside of academia and professional artists. Throughout its history, artificial intelligence art has raised many philosophical concerns, including those related to copyright, deception, and its impact on traditional artists, including their incomes.

History
Early history
The concept of automated art dates back at least to the automata of ancient Greek civilization, where inventors such as Daedalus and Hero of Alexandria were described as having designed machines capable of writing text, generating sounds, and playing music.  The tradition of creative automatons has flourished throughout history, such as Maillardet's automaton, created in the early 1800s.The academic discipline of artificial intelligence was founded at a research workshop at Dartmouth College in 1956, and has experienced several waves of advancement and optimism in the decades since. Since its founding, researchers in the field have raised philosophical and ethical arguments about the nature of the human mind and the consequences of creating artificial beings with human-like intelligence; these issues have previously been explored by myth, fiction and philosophy since antiquity.

1950s to 2000s
Since the founding of AI in the 1950s, artists and researchers have used artificial intelligence to create artistic works. These works were sometimes referred to as algorithmic art, computer art, digital art or new media.One of the first significant AI art systems is AARON, developed by Harold Cohen beginning in the late 1960s at the University of California at San Diego. AARON is the most notable example of AI art in the era of GOFAI programming because of its use of a symbolic rule-based approach to generate technical images. Cohen developed AARON with the goal of being able to code the act of drawing. In its primitive form, AARON created simple black and white drawings. Cohen would later finish the drawings by painting them. Throughout the years, he also began to develop a way for AARON to also paint. Cohen designed AARON to paint using special brushes and dyes that were chosen by the program itself without mediation from Cohen. AARON was exhibited in 1972 at the Los Angeles County Museum of Art.In both 1991 and 1992, Karl Sims won the Golden Nica award at Prix Ars Electronica for his 3D AI animated videos using artificial evolution.In 2009, Eric Millikin won the Pulitzer Prize along with several other awards for his artificial intelligence art that was critical of government corruption in Detroit and resulted in the city's mayor being sent to jail.

2010s and deep learning
In 2014, Ian Goodfellow and colleagues at Université de Montréal developed the generative adversarial network (GAN), a type of deep neural network capable of learning to mimic the statistical distribution of input data such as images. The GAN uses a "generator" to create new images and a "discriminator" to decide which created images are considered successful. Unlike previous algorithmic art which followed hand-coded rules, generative adversarial networks could learn a specific aesthetic by analyzing a dataset of example images.In 2015, a team at Google released DeepDream, a program that uses a convolutional neural network to find and enhance patterns in images via algorithmic pareidolia. The process creates deliberately over-processed images with a dream-like appearance reminiscent of a psychedelic experience.In 2018, an auction sale of artificial intelligence art was held at Christie's Auction House in New York where the AI artwork Edmond de Belamy (a pun on Goodfellow's name) sold for $432,500, which was almost 45 times higher than its estimate of $7,000–$10,000. The artwork was created by "Obvious", a Paris-based collective.In 2019, Stephanie Dinkins won the Creative Capital award for her creation of an evolving artificial intelligence based on the "interests and culture(s) of people of color." Also in 2019, Sougwen Chung won the Lumen Prize for her performances with a robotic arm that uses AI to attempt to draw in a manner similar to Chung.

2020s and generative AI
In the 2020s, text-to-image models, which generate images based on prompts, began to approach the quality of real photographs and human-drawn art.In 2021, using the Transformer models used in GPT-2 and GPT-3, OpenAI developed DALL-E, a text-to-image AI model capable of producing high-quality images based on natural language prompts.Later in 2021, EleutherAI released the open source VQGAN+CLIP, based on OpenAI's CLIP model.In 2022, Midjourney was released, followed by the open source Stable Diffusion, leading to a dramatic growth in the use of AI to generate visual art.
In 2022, Refik Anadol created an artificial intelligence art installation at the Museum of Modern Art in New York, based on the museum's own collection.

Tools and processes
Imagery
Many mechanisms for creating AI art have been developed, including procedural "rule-based" generation of images using mathematical patterns, algorithms which simulate brush strokes and other painted effects, and deep learning algorithms, such as generative adversarial networks (GANs) and transformers.
Several companies have released apps that transform photos into art-like images with the style of well-known sets of paintings.
The website Artbreeder, launched in 2018, uses the models StyleGAN and BigGAN to allow users to generate and modify images such as faces, landscapes, and paintings.Several programs use text-to-image models to generate a variety of images based on various text prompts. They include EleutherAI's VQGAN+CLIP which was released in 2021, OpenAI's DALL-E which released a series of images in January 2021,  Google Brain's Imagen and Parti which was announced in May 2022, Microsoft's NUWA-Infinity, and Stable Diffusion which was released in August 2022.  Stability.ai has a Stable Diffusion web interface called DreamStudio. Stable Diffusion is source-available software, enabling further development such as plugins for Krita, Photoshop, Blender, and GIMP, as well as the Automatic1111 web-based open source user interface. Stable Diffusion's main pre-trained model is shared on the Hugging Face Hub.There are many other AI art generation programs including simple consumer-facing mobile apps and Jupyter notebooks that require powerful GPUs to run effectively.

Impact and applications
The exhibition "Thinking Machines: Art and Design in the Computer Age, 1959–1989" at MoMA provided an overview of AI applications for art, architecture, and design. Exhibitions showcasing the usage of AI to produce art include the 2016 Google-sponsored benefit and auction at the Gray Area Foundation in San Francisco, where artists experimented with the DeepDream algorithm and the 2017 exhibition "Unhuman: Art in the Age of AI", which took place in Los Angeles and Frankfurt. In spring 2018, the Association for Computing Machinery dedicated a magazine issue to the subject of computers and art. In June 2018, "Duet for Human and Machine", an art piece permitting viewers to interact with an artificial intelligence, premiered at the Beall Center for Art + Technology. The Austrian Ars Electronica and Museum of Applied Arts, Vienna opened exhibitions on AI in 2019. Ars Electronica's 2019 festival "Out of the box" explored art's role in a sustainable societal transformation.
Examples of such augmentation may include e.g. enabling expansion of noncommercial niche genres (common examples are cyberpunk derivatives like solarpunk) by amateurs, novel entertainment, novel imaginative childhood play, very fast prototyping, increasing art-making accessibility and artistic output per effort and/or expenses and/or time – e.g. via generating drafts, inspirations, draft-refinitions, and image-components (Inpainting).

Prompt engineering and sharing
Prompts for some text-to-image models can also include images and keywords and configurable parameters, such as artistic style, which is often used via keyphrases like "in the style of [name of an artist]" in the prompt and/or selection of a broad aesthetic/art style. There are platforms for sharing, trading, searching, forking/refining and/or collaborating on prompts for generating specific imagery from image generators. Prompts are often shared along with images on image-sharing websites such as Reddit and AI art-dedicated websites. A prompt is not the complete input needed for the generation of an image: additional inputs that determine the generated image include the output resolution, random seed, and random sampling parameters.

Related terminology
Synthetic media, which includes AI art, was described in 2022 as a major technology-driven trend that will affect business in the coming years. 'Synthography' is a proposed term for the practice of generating images that are similar to photographs using AI.

Development
Additional functionalities are under development and may improve various applications or enable new ones – such as "Textual Inversion" which refers to enabling the use of user-provided concepts (like an object or a style) learned from few images. With textual inversion, novel personalized art can be generated from the associated word(s) (the keywords that have been assigned to the learned, often abstract, concept) and model extensions/fine-tuning (see also: DreamBooth).
Generated images are sometimes used as sketches or low-cost experimentations or illustration of proof-of-concept-stage ideas – additional functionalities or improvements may also relate to post-generation manual editing (polishing or artistic usage) of prompts-based art (such as subsequent tweaking with an image editor).

Criticism, issues and controversy
Copyright
Legal scholars, artists, and media corporations have considered the legal and ethical implications of artificial intelligence art since the 20th century.
In 1985, intellectual property law professor Pamela Samuelson argued that US copyright to algorithmically generated artworks should be allocated to the user of the computer program. A 2019 Florida Law Review article presented three perspectives on the issue. In the first, the artificial intelligence itself would become the copyright owner. To do this, Section 101 of the US Copyright Act would need to be amended to define "author" as a natural person or a computer. In the second, following Samuelson's argument, the user, programmer, or artificial intelligence company would be the copyright owner. This would be an expansion of the "work for hire" doctrine, under which ownership of a copyright is transferred to the "employer." In the third situation, copyright assignment would never take place, and such works would be in the public domain, as copyright assignments require an act of authorship.In 2022, coinciding with the rising availability of consumer-grade AI image generation services, popular discussion renewed over the legality and ethics of AI-generated art. Of particular issue is the use of copyrighted art within AI training datasets: in September 2022, Reema Selhi, of the Design and Artists Copyright Society, stated that "there are no safeguards for artists to be able to identify works in databases that are being used and opt out." Some have claimed that images generated by these models can bear an uncanny resemblance to extant artwork, sometimes including remains of the original artist's signature. In December 2022, users of the portfolio platform ArtStation staged an online protest against nonconsensual use of their artwork within datasets: this resulted in opt-out services, such as "Have I Been Trained?," increasing in profile, as well as some online art platforms promising to offer their own opt-out options. According to the US Copyright Office, artificial intelligence programs are unable to hold copyright, a decision upheld at the Federal District level as of August 2023 followed the reasoning from the monkey selfie copyright dispute.An issue with many popular AI art programs is that they generate images based on artists' work without their consent. In January 2023 three artists — Sarah Andersen, Kelly McKernan, and Karla Ortiz — filed a copyright infringement lawsuit against Stability AI, Midjourney, and DeviantArt, claiming that these companies have infringed the rights of millions of artists by training AI tools on five billion images scraped from the web without the consent of the original artists. In July 2023, U.S. District Judge William Orrick inclined to dismiss most of the lawsuit filed by Andersen, McKernan, and Ortiz, but allowed them to file a new complaint.Also in 2023, Stability AI was sued by Getty Images for using its images in the training data.

Income and employment stability
As generative AI image software such as Stable Diffusion and DALL-E continue to advance and proliferate, the potential problems and concerns that these systems pose on creativity and artistry has risen. During 2022, artists working in various media raised concerns about the impact that generative artificial intelligence could have on their ability to earn money, particularly if AI-based images started replacing artists working in illustration and design industries.  In August 2022, digital artist R. J. Palmer stated that "I could easily envision a scenario where using AI, a single artist or art director could take the place of 5-10 entry level artists... I have seen a lot of self-published authors and such say how great it will be that they don’t have to hire an artist." Scholars Jiang et al. support this concern of job loss in creative fields by stating, “Leaders of companies like Open AI and Stability AI have openly stated that they expect generative AI systems to replace creatives imminently,” and adding that, “This labor displacement is evident across creative industries. For instance, according to an article on Rest of World, a Chinese gaming industry recruiter has noticed a 70% drop in illustrator jobs, in part due to the widespread use of image generators; another studio in China is reported to have laid off a third of its character design illustrators.” AI-based images have become more commonplace in art markets and search engines because AI-based text-to-image systems are trained from pre-existing artistic images, sometimes without the original artist's consent, allowing the software to mimic specific artists' styles. For example, Polish digital artist Greg Rutkowski has stated that it's more difficult to search for his work online because many of the images in the results are AI-generated specifically to mimic his style. Furthermore, some training databases on which AI systems are based aren't accessible to the public, which makes it impossible to know the extent to which their training data contains copyright protected images. For example, a tool built by Simon Willison allowed people to search 0.5% of the training data for Stable Diffusion V1.1, i.e., 12 million of 2.3 billion instances from LAION 2B. Artist Karen Hallion discovered that their copyrighted images were used as training data without their consent.The ability of AI-based art software to mimic or forge artistic style also raises concerns of malice or greed. Works of AI-generated art, such as Théâtre d'Opéra Spatial, a text-to-image AI illustration that won the grand prize in the August 2022 digital art competition at the Colorado State Fair, have begun to overwhelm art contests and other submission forums meant for small artists.AI-generated images have raised the concern that they can be made to damage an artist's reputation. Artist Sarah Hendersen had her art copied and then used to depict Neo-Nazi ideology. She stated that the spread of hate speech online can be worsened by the use of image generators. Jiang et al. also add to this sentiment by stating that "tools trained on artists' works and which allow users to mimic their style without their consent or compensation, can cause significant reputational damage [by] spreading messages that they do not endorse."

Deception
The 2023 winner of the "creative open" category in the Sony World Photography Awards, Boris Eldagsen, revealed after winning that his entry was actually generated by artificial intelligence. Photographer Feroz Khan commented to the BBC that Eldagsen had "clearly shown that even experienced photographers and art experts can be fooled". Smaller contests have been affected as well; in 2023 a contest called the "Self-Published Fantasy Blog-Off cover contest", run by author Mark Lawrence, was cancelled after the winning entry was allegedly exposed to be a collage of images generated by Midjourney.Wider issues extend beyond the art world. As with other types of photo manipulation since the early 19th century, some people in the early 21st century have been concerned that AI could be used to create content that is misleading, known as "deepfakes".In May 2023, widespread attention was given to a Midjourney-generated photo of Pope Francis wearing a white puffer coat and another showing the fictional arrest of Donald Trump, and an AI-generated image of an attack on the Pentagon went viral as a hoax news story on Twitter.

Ethics
AI produced images are causing many artist to be concerned about the way society values artist. Artists fear the production of AI will be seen as an improvement to the current system due to its ability to be quickly produced. AI systems gather data in order to create solutions, when gathering data from various sources there becomes the question of whether or not the data can be used to produce a work.Galanter introduces a question of determining how to give credit through the thought process of differentiating the artist and the artistic influences.

Analysis of existing art using AI
In addition to the creation of original art, research methods that utilize AI have been generated to quantitatively analyze digital art collections. This has been made possible due to large-scale digitization of artwork in the past few decades. Although the main goal of digitization was to allow for accessibility and exploration of these collections, the use of AI in analyzing them has brought about new research perspectives.Two computational methods, close reading and distant viewing, are the typical approaches used to analyze digitized art. Close reading focuses on specific visual aspects of one piece. Some tasks performed by machines in close reading methods include computational artist authentication and analysis of brushstrokes or texture properties. In contrast, through distant viewing methods, the similarity across an entire collection for a specific feature can be statistically visualized. Common tasks relating to this method include automatic classification, object detection, multimodal tasks, knowledge discovery in art history, and computational aesthetics. Whereas distant viewing includes the analysis of large collections, close reading involves one piece of artwork.Researchers have also introduced models that predict emotional responses to art such as ArtEmis, a large-scale dataset with machine learning models that contain emotional reactions to visual art as well as predictions of emotion from images or text.According to CETINIC and SHE (2022), using artificial intelligence to analyse already-existing art collections can provide fresh perspectives on the development of artistic styles and the identification of artistic influences. AI-assisted study of existing art can also aid in the organization of art exhibitions and support the decision-making process for curators and art historians.AI programs can automatically generate new images of artwork similar to those learned from the sample. Humans mainly just need to input data and discriminate output, the combination of AI mechanisms and human art creation mechanisms allows AI to produce works.

Other forms of art
Some prototype robots can create what may be considered forms of art – such as dynamic cooking robots that can taste and readjust.There also is AI-assisted writing beyond copy-editing (including support in the generation of fictional stories such as helping with writer's block or inspiration or rewriting segments).Generative AI has also been used in video game production beyond imagery, especially for level design (e.g. for custom maps) and creating new content or interactive stories in video games.

See also
Algorithmic art
Applications of artificial intelligence#Art
Computational creativity
Cybernetic art
Generative art
List of artificial intelligence artists
Music and artificial intelligence
Neural style transfer
Synthetic media


== References ==