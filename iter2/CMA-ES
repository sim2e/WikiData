Covariance matrix adaptation evolution strategy (CMA-ES) is a particular kind of strategy for numerical optimization. Evolution strategies (ES) are stochastic, derivative-free methods for numerical optimization  of non-linear or non-convex continuous optimization problems. They belong to the class of evolutionary algorithms and evolutionary computation.  An evolutionary algorithm is broadly based on the principle of biological evolution, namely the repeated interplay of variation (via recombination and mutation) and selection: in each generation (iteration) new individuals (candidate solutions, denoted as 
  
    
      
        x
      
    
    {\displaystyle x}
  ) are generated by variation, usually in a stochastic way, of the current parental individuals. Then, some individuals are selected to become the parents in the next generation based on their fitness or objective function value 
  
    
      
        f
        (
        x
        )
      
    
    {\displaystyle f(x)}
  . Like this, over the generation sequence, individuals with better and better 
  
    
      
        f
      
    
    {\displaystyle f}
  -values are generated.
In an evolution strategy, new candidate solutions are sampled according to a multivariate normal distribution in 
  
    
      
        
          
            R
          
          
            n
          
        
      
    
    {\displaystyle \mathbb {R} ^{n}}
  . Recombination amounts to selecting a new mean value for the distribution. Mutation amounts to adding a random vector, a perturbation with zero mean. Pairwise dependencies between the variables in the distribution are represented by a covariance matrix. The covariance matrix adaptation (CMA) is a method to update the covariance matrix of this distribution. This is particularly useful if the function 
  
    
      
        f
      
    
    {\displaystyle f}
   is ill-conditioned.
Adaptation of the covariance matrix amounts to learning a second order model of the underlying objective function similar to the approximation of the inverse Hessian matrix in the quasi-Newton method in classical optimization. In contrast to most classical methods, fewer assumptions on the underlying objective function are made. Because only a ranking (or, equivalently, sorting) of candidate solutions is exploited, neither derivatives nor even an (explicit) objective function is required by the method. For example, the ranking could come about from pairwise competitions between the candidate solutions in a Swiss-system tournament.

Principles
Two main principles for the adaptation of parameters of the search distribution are exploited in the CMA-ES algorithm.
First, a maximum-likelihood principle, based on the idea to increase the probability of successful candidate solutions and search steps. The mean of the distribution is updated such that the likelihood of previously successful candidate solutions is maximized. The covariance matrix of the distribution is updated (incrementally) such that the likelihood of previously successful search steps is increased. Both updates can be interpreted as a natural gradient descent. Also, in consequence, the CMA conducts an iterated principal components analysis of successful search steps while retaining all principal axes. Estimation of distribution algorithms and the Cross-Entropy Method are based on very similar ideas, but estimate (non-incrementally) the covariance matrix by maximizing the likelihood of successful solution points instead of successful search steps.
Second, two paths of the time evolution of the distribution mean of the strategy are recorded, called search or evolution paths. These paths contain significant information about the correlation between consecutive steps. Specifically, if consecutive steps are taken in a similar direction, the evolution paths become long. The evolution paths are exploited in two ways. One path is used for the covariance matrix adaptation procedure in place of single successful search steps and facilitates a possibly much faster variance increase of favorable directions. The other path is used to conduct an additional step-size control. This step-size control aims to make consecutive movements of the distribution mean orthogonal in expectation. The step-size control effectively prevents premature convergence yet allowing fast convergence to an optimum.

Algorithm
In the following the most commonly used (μ/μw, λ)-CMA-ES is outlined, where in each iteration step a weighted combination of the μ best out of λ new candidate solutions is used to update the distribution parameters. The main loop consists of three main parts: 1) sampling of new solutions, 2) re-ordering of the sampled solutions based on their fitness, 3) update of the internal state variables based on the re-ordered samples. A pseudocode of the algorithm looks as follows.

set 
  
    
      
        λ
      
    
    {\displaystyle \lambda }
    // number of samples per iteration, at least two, generally > 4
initialize 
  
    
      
        m
      
    
    {\displaystyle m}
  , 
  
    
      
        σ
      
    
    {\displaystyle \sigma }
  , 
  
    
      
        C
        =
        I
      
    
    {\displaystyle C=I}
  , 
  
    
      
        
          p
          
            σ
          
        
        =
        0
      
    
    {\displaystyle p_{\sigma }=0}
  , 
  
    
      
        
          p
          
            c
          
        
        =
        0
      
    
    {\displaystyle p_{c}=0}
    // initialize state variables
while not terminate do  // iterate
    for 
  
    
      
        i
      
    
    {\displaystyle i}
   in 
  
    
      
        {
        1
        …
        λ
        }
      
    
    {\displaystyle \{1\ldots \lambda \}}
   do  // sample 
  
    
      
        λ
      
    
    {\displaystyle \lambda }
   new solutions and evaluate them
        
  
    
      
        
          x
          
            i
          
        
        =
        

        
      
    
    {\displaystyle x_{i}={}}
  sample_multivariate_normal(mean
  
    
      
        

        
        =
        m
      
    
    {\displaystyle {}=m}
  , covariance_matrix
  
    
      
        

        
        =
        
          σ
          
            2
          
        
        C
      
    
    {\displaystyle {}=\sigma ^{2}C}
  )
        
  
    
      
        
          f
          
            i
          
        
        =
        fitness
        ⁡
        (
        
          x
          
            i
          
        
        )
      
    
    {\displaystyle f_{i}=\operatorname {fitness} (x_{i})}
  
    
  
    
      
        
          x
          
            1
            …
            λ
          
        
      
    
    {\displaystyle x_{1\ldots \lambda }}
   ← 
  
    
      
        
          x
          
            s
            (
            1
            )
            …
            s
            (
            λ
            )
          
        
      
    
    {\displaystyle x_{s(1)\ldots s(\lambda )}}
   with 
  
    
      
        s
        (
        i
        )
        =
        argsort
        ⁡
        (
        
          f
          
            1
            …
            λ
          
        
        ,
        i
        )
      
    
    {\displaystyle s(i)=\operatorname {argsort} (f_{1\ldots \lambda },i)}
   // sort solutions
    
  
    
      
        
          m
          ′
        
        =
        m
      
    
    {\displaystyle m'=m}
    // we need later 
  
    
      
        m
        −
        
          m
          ′
        
      
    
    {\displaystyle m-m'}
   and 
  
    
      
        
          x
          
            i
          
        
        −
        
          m
          ′
        
      
    
    {\displaystyle x_{i}-m'}
         
    
  
    
      
        m
      
    
    {\displaystyle m}
   ← update_m
  
    
      
        (
        
          x
          
            1
          
        
        ,
        …
        ,
        
          x
          
            λ
          
        
        )
      
    
    {\displaystyle (x_{1},\ldots ,x_{\lambda })}
    // move mean to better solutions 
    
  
    
      
        
          p
          
            σ
          
        
      
    
    {\displaystyle p_{\sigma }}
   ← update_ps
  
    
      
        (
        
          p
          
            σ
          
        
        ,
        
          σ
          
            −
            1
          
        
        
          C
          
            −
            1
            
              /
            
            2
          
        
        (
        m
        −
        
          m
          ′
        
        )
        )
      
    
    {\displaystyle (p_{\sigma },\sigma ^{-1}C^{-1/2}(m-m'))}
    // update isotropic evolution path
    
  
    
      
        
          p
          
            c
          
        
      
    
    {\displaystyle p_{c}}
   ← update_pc
  
    
      
        (
        
          p
          
            c
          
        
        ,
        
          σ
          
            −
            1
          
        
        (
        m
        −
        
          m
          ′
        
        )
        ,
        ‖
        
          p
          
            σ
          
        
        ‖
        )
      
    
    {\displaystyle (p_{c},\sigma ^{-1}(m-m'),\|p_{\sigma }\|)}
    // update anisotropic evolution path
    
  
    
      
        C
      
    
    {\displaystyle C}
   ← update_C
  
    
      
        (
        C
        ,
        
          p
          
            c
          
        
        ,
        (
        
          x
          
            1
          
        
        −
        
          m
          ′
        
        )
        
          /
        
        σ
        ,
        …
        ,
        (
        
          x
          
            λ
          
        
        −
        
          m
          ′
        
        )
        
          /
        
        σ
        )
      
    
    {\displaystyle (C,p_{c},(x_{1}-m')/\sigma ,\ldots ,(x_{\lambda }-m')/\sigma )}
    // update covariance matrix
    
  
    
      
        σ
      
    
    {\displaystyle \sigma }
   ← update_sigma
  
    
      
        (
        σ
        ,
        ‖
        
          p
          
            σ
          
        
        ‖
        )
      
    
    {\displaystyle (\sigma ,\|p_{\sigma }\|)}
    // update step-size using isotropic path length
return 
  
    
      
        m
      
    
    {\displaystyle m}
   or 
  
    
      
        
          x
          
            1
          
        
      
    
    {\displaystyle x_{1}}
  

The order of the five update assignments is relevant: 
  
    
      
        m
      
    
    {\displaystyle m}
   must be updated first, 
  
    
      
        
          p
          
            σ
          
        
      
    
    {\displaystyle p_{\sigma }}
   and 
  
    
      
        
          p
          
            c
          
        
      
    
    {\displaystyle p_{c}}
   must be updated before 
  
    
      
        C
      
    
    {\displaystyle C}
  , and 
  
    
      
        σ
      
    
    {\displaystyle \sigma }
   must be updated last. The update equations for the five state variables are specified in the following.
Given are the search space dimension 
  
    
      
        n
      
    
    {\displaystyle n}
   and the iteration step 
  
    
      
        k
      
    
    {\displaystyle k}
  . The five state variables are

  
    
      
        
          m
          
            k
          
        
        ∈
        
          
            R
          
          
            n
          
        
      
    
    {\displaystyle m_{k}\in \mathbb {R} ^{n}}
  , the distribution mean and current favorite solution to the optimization problem,
  
    
      
        
          σ
          
            k
          
        
        >
        0
      
    
    {\displaystyle \sigma _{k}>0}
  , the step-size,
  
    
      
        
          C
          
            k
          
        
      
    
    {\displaystyle C_{k}}
  , a symmetric and positive-definite 
  
    
      
        n
        ×
        n
      
    
    {\displaystyle n\times n}
   covariance matrix with 
  
    
      
        
          C
          
            0
          
        
        =
        I
      
    
    {\displaystyle C_{0}=I}
   and
  
    
      
        
          p
          
            σ
          
        
        ∈
        
          
            R
          
          
            n
          
        
        ,
        
          p
          
            c
          
        
        ∈
        
          
            R
          
          
            n
          
        
      
    
    {\displaystyle p_{\sigma }\in \mathbb {R} ^{n},p_{c}\in \mathbb {R} ^{n}}
  , two evolution paths, initially set to the zero vector.The iteration starts with sampling 
  
    
      
        λ
        >
        1
      
    
    {\displaystyle \lambda >1}
   candidate solutions 
  
    
      
        
          x
          
            i
          
        
        ∈
        
          
            R
          
          
            n
          
        
      
    
    {\displaystyle x_{i}\in \mathbb {R} ^{n}}
   from a multivariate normal distribution 
  
    
      
        
          
            
              N
            
          
          (
          
            m
            
              k
            
          
          ,
          
            σ
            
              k
            
            
              2
            
          
          
            C
            
              k
            
          
          )
        
      
    
    {\displaystyle \textstyle {\mathcal {N}}(m_{k},\sigma _{k}^{2}C_{k})}
  , i.e. 
for 
  
    
      
        i
        =
        1
        ,
        …
        ,
        λ
      
    
    {\displaystyle i=1,\ldots ,\lambda }
  

  
    
      
        
          
            
              
                
                  x
                  
                    i
                  
                
                 
              
              
                
                ∼
                 
                
                  
                    N
                  
                
                (
                
                  m
                  
                    k
                  
                
                ,
                
                  σ
                  
                    k
                  
                  
                    2
                  
                
                
                  C
                  
                    k
                  
                
                )
              
            
            
              
              
                
                ∼
                 
                
                  m
                  
                    k
                  
                
                +
                
                  σ
                  
                    k
                  
                
                ×
                
                  
                    N
                  
                
                (
                0
                ,
                
                  C
                  
                    k
                  
                
                )
              
            
          
        
      
    
    {\displaystyle {\begin{aligned}x_{i}\ &\sim \ {\mathcal {N}}(m_{k},\sigma _{k}^{2}C_{k})\\&\sim \ m_{k}+\sigma _{k}\times {\mathcal {N}}(0,C_{k})\end{aligned}}}
  The second line suggests the interpretation as unbiased perturbation (mutation) of the current favorite solution vector 
  
    
      
        
          m
          
            k
          
        
      
    
    {\displaystyle m_{k}}
   (the distribution mean vector). The candidate solutions 
  
    
      
        
          x
          
            i
          
        
      
    
    {\displaystyle x_{i}}
   are evaluated on the objective function 
  
    
      
        f
        :
        
          
            R
          
          
            n
          
        
        →
        
          R
        
      
    
    {\displaystyle f:\mathbb {R} ^{n}\to \mathbb {R} }
   to be minimized.  Denoting the 
  
    
      
        f
      
    
    {\displaystyle f}
  -sorted candidate solutions as

  
    
      
        {
        
          x
          
            i
            :
            λ
          
        
        ∣
        i
        =
        1
        …
        λ
        }
        =
        {
        
          x
          
            i
          
        
        ∣
        i
        =
        1
        …
        λ
        }
        
           and 
        
        f
        (
        
          x
          
            1
            :
            λ
          
        
        )
        ≤
        ⋯
        ≤
        f
        (
        
          x
          
            μ
            :
            λ
          
        
        )
        ≤
        f
        (
        
          x
          
            μ
            +
            1
            :
            λ
          
        
        )
        ≤
        ⋯
        ,
      
    
    {\displaystyle \{x_{i:\lambda }\mid i=1\dots \lambda \}=\{x_{i}\mid i=1\dots \lambda \}{\text{ and }}f(x_{1:\lambda })\leq \dots \leq f(x_{\mu :\lambda })\leq f(x_{\mu +1:\lambda })\leq \cdots ,}
  the new mean value is computed as

  
    
      
        
          
            
              
                
                  m
                  
                    k
                    +
                    1
                  
                
              
              
                
                =
                
                  ∑
                  
                    i
                    =
                    1
                  
                  
                    μ
                  
                
                
                  w
                  
                    i
                  
                
                
                
                  x
                  
                    i
                    :
                    λ
                  
                
              
            
            
              
              
                
                =
                
                  m
                  
                    k
                  
                
                +
                
                  ∑
                  
                    i
                    =
                    1
                  
                  
                    μ
                  
                
                
                  w
                  
                    i
                  
                
                
                (
                
                  x
                  
                    i
                    :
                    λ
                  
                
                −
                
                  m
                  
                    k
                  
                
                )
              
            
          
        
      
    
    {\displaystyle {\begin{aligned}m_{k+1}&=\sum _{i=1}^{\mu }w_{i}\,x_{i:\lambda }\\&=m_{k}+\sum _{i=1}^{\mu }w_{i}\,(x_{i:\lambda }-m_{k})\end{aligned}}}
  where the positive (recombination) weights 
  
    
      
        
          w
          
            1
          
        
        ≥
        
          w
          
            2
          
        
        ≥
        ⋯
        ≥
        
          w
          
            μ
          
        
        >
        0
      
    
    {\displaystyle w_{1}\geq w_{2}\geq \dots \geq w_{\mu }>0}
   sum to one. Typically, 
  
    
      
        μ
        ≤
        λ
        
          /
        
        2
      
    
    {\displaystyle \mu \leq \lambda /2}
   and the weights are chosen such that 
  
    
      
        
          
            μ
            
              w
            
          
          :=
          1
          
            /
          
          
            ∑
            
              i
              =
              1
            
            
              μ
            
          
          
            w
            
              i
            
            
              2
            
          
          ≈
          λ
          
            /
          
          4
        
      
    
    {\displaystyle \textstyle \mu _{w}:=1/\sum _{i=1}^{\mu }w_{i}^{2}\approx \lambda /4}
  . The only feedback used from the objective function here and in the following is an ordering of the sampled candidate solutions due to the indices 
  
    
      
        i
        :
        λ
      
    
    {\displaystyle i:\lambda }
  .
The step-size 
  
    
      
        
          σ
          
            k
          
        
      
    
    {\displaystyle \sigma _{k}}
   is updated using cumulative step-size adaptation (CSA), sometimes also denoted as path length control. The evolution path (or search path) 
  
    
      
        
          p
          
            σ
          
        
      
    
    {\displaystyle p_{\sigma }}
   is updated first.

  
    
      
        
          p
          
            σ
          
        
        ←
        
          
            
              
                (
                1
                −
                
                  c
                  
                    σ
                  
                
                )
              
              ⏟
            
          
          
            
            
            
            
            
            
              discount factor
            
            
            
            
            
            
          
        
        
        
          p
          
            σ
          
        
        +
        
          
            
              
                1
                −
                (
                1
                −
                
                  c
                  
                    σ
                  
                
                
                  )
                  
                    2
                  
                
              
              ⏞
            
          
          
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
              complements for discounted variance
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
          
        
        
          
            
              
                
                  
                    
                      μ
                      
                        w
                      
                    
                  
                
                
                
                  C
                  
                    k
                  
                  
                    
                    −
                    1
                    
                      /
                    
                    2
                  
                
                
                
                  
                    
                      
                        
                          
                            
                              m
                              
                                k
                                +
                                1
                              
                            
                            −
                            
                              m
                              
                                k
                              
                            
                          
                          ⏞
                        
                      
                      
                        
                        
                        
                        
                          displacement of 
                        
                        m
                        
                        
                        
                      
                    
                    
                      σ
                      
                        k
                      
                    
                  
                
              
              ⏟
            
          
          
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
              distributed as 
            
            
              
                N
              
            
            (
            0
            ,
            I
            )
            
               under neutral selection
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
          
        
      
    
    {\displaystyle p_{\sigma }\gets \underbrace {(1-c_{\sigma })} _{\!\!\!\!\!{\text{discount factor}}\!\!\!\!\!}\,p_{\sigma }+\overbrace {\sqrt {1-(1-c_{\sigma })^{2}}} ^{\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!{\text{complements for discounted variance}}\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!}\underbrace {{\sqrt {\mu _{w}}}\,C_{k}^{\;-1/2}\,{\frac {\overbrace {m_{k+1}-m_{k}} ^{\!\!\!{\text{displacement of }}m\!\!\!}}{\sigma _{k}}}} _{\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!{\text{distributed as }}{\mathcal {N}}(0,I){\text{ under neutral selection}}\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!}}
  

  
    
      
        
          σ
          
            k
            +
            1
          
        
        =
        
          σ
          
            k
          
        
        ×
        exp
        ⁡
        
          
            (
          
        
        
          
            
              c
              
                σ
              
            
            
              d
              
                σ
              
            
          
        
        
          
            
              
                (
                
                  
                    
                      
                        ‖
                        
                          p
                          
                            σ
                          
                        
                        ‖
                      
                      
                        E
                        ⁡
                        ‖
                        
                          
                            N
                          
                        
                        (
                        0
                        ,
                        I
                        )
                        ‖
                      
                    
                  
                  −
                  1
                
                )
              
              ⏟
            
          
          
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
              unbiased about 0 under neutral selection
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
          
        
        
          
            )
          
        
      
    
    {\displaystyle \sigma _{k+1}=\sigma _{k}\times \exp {\bigg (}{\frac {c_{\sigma }}{d_{\sigma }}}\underbrace {\left({\frac {\|p_{\sigma }\|}{\operatorname {E} \|{\mathcal {N}}(0,I)\|}}-1\right)} _{\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!{\text{unbiased about 0 under neutral selection}}\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!}{\bigg )}}
  where

  
    
      
        
          c
          
            σ
          
          
            −
            1
          
        
        ≈
        n
        
          /
        
        3
      
    
    {\displaystyle c_{\sigma }^{-1}\approx n/3}
   is the backward time horizon for the evolution path 
  
    
      
        
          p
          
            σ
          
        
      
    
    {\displaystyle p_{\sigma }}
   and larger than one (
  
    
      
        
          c
          
            σ
          
        
        ≪
        1
      
    
    {\displaystyle c_{\sigma }\ll 1}
   is reminiscent of an exponential decay constant as 
  
    
      
        (
        1
        −
        
          c
          
            σ
          
        
        
          )
          
            k
          
        
        ≈
        exp
        ⁡
        (
        −
        
          c
          
            σ
          
        
        k
        )
      
    
    {\displaystyle (1-c_{\sigma })^{k}\approx \exp(-c_{\sigma }k)}
   where 
  
    
      
        
          c
          
            σ
          
          
            −
            1
          
        
      
    
    {\displaystyle c_{\sigma }^{-1}}
   is the associated lifetime and 
  
    
      
        
          c
          
            σ
          
          
            −
            1
          
        
        ln
        ⁡
        (
        2
        )
        ≈
        0.7
        
          c
          
            σ
          
          
            −
            1
          
        
      
    
    {\displaystyle c_{\sigma }^{-1}\ln(2)\approx 0.7c_{\sigma }^{-1}}
   the half-life),
  
    
      
        
          μ
          
            w
          
        
        =
        
          
            (
            
              
                ∑
                
                  i
                  =
                  1
                
                
                  μ
                
              
              
                w
                
                  i
                
                
                  2
                
              
            
            )
          
          
            −
            1
          
        
      
    
    {\displaystyle \mu _{w}=\left(\sum _{i=1}^{\mu }w_{i}^{2}\right)^{-1}}
   is the variance effective selection mass and 
  
    
      
        1
        ≤
        
          μ
          
            w
          
        
        ≤
        μ
      
    
    {\displaystyle 1\leq \mu _{w}\leq \mu }
   by definition of 
  
    
      
        
          w
          
            i
          
        
      
    
    {\displaystyle w_{i}}
  ,
  
    
      
        
          C
          
            k
          
          
            
            −
            1
            
              /
            
            2
          
        
        =
        
          
            
              
                C
                
                  k
                
              
            
          
          
            
            −
            1
          
        
        =
        
          
            
              C
              
                k
              
              
                
                −
                1
              
            
          
        
      
    
    {\displaystyle C_{k}^{\;-1/2}={\sqrt {C_{k}}}^{\;-1}={\sqrt {C_{k}^{\;-1}}}}
   is the unique symmetric square root of the inverse of 
  
    
      
        
          C
          
            k
          
        
      
    
    {\displaystyle C_{k}}
  , and
  
    
      
        
          d
          
            σ
          
        
      
    
    {\displaystyle d_{\sigma }}
   is the damping parameter usually close to one. For 
  
    
      
        
          d
          
            σ
          
        
        =
        ∞
      
    
    {\displaystyle d_{\sigma }=\infty }
   or 
  
    
      
        
          c
          
            σ
          
        
        =
        0
      
    
    {\displaystyle c_{\sigma }=0}
   the step-size remains unchanged.The step-size 
  
    
      
        
          σ
          
            k
          
        
      
    
    {\displaystyle \sigma _{k}}
   is increased if and only if 
  
    
      
        ‖
        
          p
          
            σ
          
        
        ‖
      
    
    {\displaystyle \|p_{\sigma }\|}
   is larger than the expected value

  
    
      
        
          
            
              
                E
                ⁡
                ‖
                
                  
                    N
                  
                
                (
                0
                ,
                I
                )
                ‖
              
              
                
                =
                
                  
                    2
                  
                
                
                Γ
                (
                (
                n
                +
                1
                )
                
                  /
                
                2
                )
                
                  /
                
                Γ
                (
                n
                
                  /
                
                2
                )
              
            
            
              
              
                
                ≈
                
                  
                    n
                  
                
                
                (
                1
                −
                1
                
                  /
                
                (
                4
                
                n
                )
                +
                1
                
                  /
                
                (
                21
                
                
                  n
                  
                    2
                  
                
                )
                )
              
            
          
        
      
    
    {\displaystyle {\begin{aligned}\operatorname {E} \|{\mathcal {N}}(0,I)\|&={\sqrt {2}}\,\Gamma ((n+1)/2)/\Gamma (n/2)\\&\approx {\sqrt {n}}\,(1-1/(4\,n)+1/(21\,n^{2}))\end{aligned}}}
  and decreased if it is smaller. For this reason, the step-size update tends to make consecutive steps 
  
    
      
        
          C
          
            k
          
          
            −
            1
          
        
      
    
    {\displaystyle C_{k}^{-1}}
  -conjugate, in that  after the adaptation has been successful 
  
    
      
        
          
            
              (
              
                
                  
                    
                      m
                      
                        k
                        +
                        2
                      
                    
                    −
                    
                      m
                      
                        k
                        +
                        1
                      
                    
                  
                  
                    σ
                    
                      k
                      +
                      1
                    
                  
                
              
              )
            
            
              T
            
          
          
          
            C
            
              k
            
            
              −
              1
            
          
          
            
              
                
                  m
                  
                    k
                    +
                    1
                  
                
                −
                
                  m
                  
                    k
                  
                
              
              
                σ
                
                  k
                
              
            
          
          ≈
          0
        
      
    
    {\displaystyle \textstyle \left({\frac {m_{k+2}-m_{k+1}}{\sigma _{k+1}}}\right)^{T}\!C_{k}^{-1}{\frac {m_{k+1}-m_{k}}{\sigma _{k}}}\approx 0}
  .Finally, the covariance matrix is updated, where again the respective evolution path is updated first.

  
    
      
        
          p
          
            c
          
        
        ←
        
          
            
              
                (
                1
                −
                
                  c
                  
                    c
                  
                
                )
              
              ⏟
            
          
          
            
            
            
            
            
            
              discount factor
            
            
            
            
            
            
          
        
        
        
          p
          
            c
          
        
        +
        
          
            
              
                
                  
                    1
                  
                  
                    [
                    0
                    ,
                    α
                    
                      
                        n
                      
                    
                    ]
                  
                
                (
                ‖
                
                  p
                  
                    σ
                  
                
                ‖
                )
              
              ⏟
            
          
          
            indicator function
          
        
        
          
            
              
                1
                −
                (
                1
                −
                
                  c
                  
                    c
                  
                
                
                  )
                  
                    2
                  
                
              
              ⏞
            
          
          
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
              complements for discounted variance
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
          
        
        
          
            
              
                
                  
                    
                      μ
                      
                        w
                      
                    
                  
                
                
                
                  
                    
                      
                        m
                        
                          k
                          +
                          1
                        
                      
                      −
                      
                        m
                        
                          k
                        
                      
                    
                    
                      σ
                      
                        k
                      
                    
                  
                
              
              ⏟
            
          
          
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
              distributed as
            
            
            
              
                N
              
            
            (
            0
            ,
            
              C
              
                k
              
            
            )
            
            
              under neutral selection
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
          
        
      
    
    {\displaystyle p_{c}\gets \underbrace {(1-c_{c})} _{\!\!\!\!\!{\text{discount factor}}\!\!\!\!\!}\,p_{c}+\underbrace {\mathbf {1} _{[0,\alpha {\sqrt {n}}]}(\|p_{\sigma }\|)} _{\text{indicator function}}\overbrace {\sqrt {1-(1-c_{c})^{2}}} ^{\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!{\text{complements for discounted variance}}\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!}\underbrace {{\sqrt {\mu _{w}}}\,{\frac {m_{k+1}-m_{k}}{\sigma _{k}}}} _{\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!{\text{distributed as}}\;{\mathcal {N}}(0,C_{k})\;{\text{under neutral selection}}\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!}}
  
  
    
      
        
          C
          
            k
            +
            1
          
        
        =
        
          
            
              
                (
                1
                −
                
                  c
                  
                    1
                  
                
                −
                
                  c
                  
                    μ
                  
                
                +
                
                  c
                  
                    s
                  
                
                )
              
              ⏟
            
          
          
            
            
            
            
            
            
              discount factor
            
            
            
            
            
            
          
        
        
        
          C
          
            k
          
        
        +
        
          c
          
            1
          
        
        
          
            
              
                
                  p
                  
                    c
                  
                
                
                  p
                  
                    c
                  
                  
                    T
                  
                
              
              ⏟
            
          
          
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
              rank one matrix
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
          
        
        +
        
        
          c
          
            μ
          
        
        
          
            
              
                
                  ∑
                  
                    i
                    =
                    1
                  
                  
                    μ
                  
                
                
                  w
                  
                    i
                  
                
                
                  
                    
                      
                        x
                        
                          i
                          :
                          λ
                        
                      
                      −
                      
                        m
                        
                          k
                        
                      
                    
                    
                      σ
                      
                        k
                      
                    
                  
                
                
                  
                    (
                    
                      
                        
                          
                            x
                            
                              i
                              :
                              λ
                            
                          
                          −
                          
                            m
                            
                              k
                            
                          
                        
                        
                          σ
                          
                            k
                          
                        
                      
                    
                    )
                  
                  
                    T
                  
                
              
              ⏟
            
          
          
            rank
            ⁡
            min
            (
            μ
            ,
            n
            )
            
               matrix
            
          
        
      
    
    {\displaystyle C_{k+1}=\underbrace {(1-c_{1}-c_{\mu }+c_{s})} _{\!\!\!\!\!{\text{discount factor}}\!\!\!\!\!}\,C_{k}+c_{1}\underbrace {p_{c}p_{c}^{T}} _{\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!{\text{rank one matrix}}\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!}+\,c_{\mu }\underbrace {\sum _{i=1}^{\mu }w_{i}{\frac {x_{i:\lambda }-m_{k}}{\sigma _{k}}}\left({\frac {x_{i:\lambda }-m_{k}}{\sigma _{k}}}\right)^{T}} _{\operatorname {rank} \min(\mu ,n){\text{ matrix}}}}
  where 
  
    
      
        T
      
    
    {\displaystyle T}
   denotes the transpose and

  
    
      
        
          c
          
            c
          
          
            −
            1
          
        
        ≈
        n
        
          /
        
        4
      
    
    {\displaystyle c_{c}^{-1}\approx n/4}
   is the backward time horizon for the evolution path 
  
    
      
        
          p
          
            c
          
        
      
    
    {\displaystyle p_{c}}
   and larger than one,
  
    
      
        α
        ≈
        1.5
      
    
    {\displaystyle \alpha \approx 1.5}
   and the indicator function 
  
    
      
        
          
            1
          
          
            [
            0
            ,
            α
            
              
                n
              
            
            ]
          
        
        (
        ‖
        
          p
          
            σ
          
        
        ‖
        )
      
    
    {\displaystyle \mathbf {1} _{[0,\alpha {\sqrt {n}}]}(\|p_{\sigma }\|)}
   evaluates to one iff 
  
    
      
        ‖
        
          p
          
            σ
          
        
        ‖
        ∈
        [
        0
        ,
        α
        
          
            n
          
        
        ]
      
    
    {\displaystyle \|p_{\sigma }\|\in [0,\alpha {\sqrt {n}}]}
   or, in other words, 
  
    
      
        ‖
        
          p
          
            σ
          
        
        ‖
        ≤
        α
        
          
            n
          
        
      
    
    {\displaystyle \|p_{\sigma }\|\leq \alpha {\sqrt {n}}}
  , which is usually the case,
  
    
      
        
          c
          
            s
          
        
        =
        (
        1
        −
        
          
            1
          
          
            [
            0
            ,
            α
            
              
                n
              
            
            ]
          
        
        (
        ‖
        
          p
          
            σ
          
        
        ‖
        
          )
          
            2
          
        
        )
        
        
          c
          
            1
          
        
        
          c
          
            c
          
        
        (
        2
        −
        
          c
          
            c
          
        
        )
      
    
    {\displaystyle c_{s}=(1-\mathbf {1} _{[0,\alpha {\sqrt {n}}]}(\|p_{\sigma }\|)^{2})\,c_{1}c_{c}(2-c_{c})}
   makes partly up for the small variance loss in case the indicator is zero,
  
    
      
        
          c
          
            1
          
        
        ≈
        2
        
          /
        
        
          n
          
            2
          
        
      
    
    {\displaystyle c_{1}\approx 2/n^{2}}
   is the learning rate for the rank-one update of the covariance matrix and
  
    
      
        
          c
          
            μ
          
        
        ≈
        
          μ
          
            w
          
        
        
          /
        
        
          n
          
            2
          
        
      
    
    {\displaystyle c_{\mu }\approx \mu _{w}/n^{2}}
   is the learning rate for the rank-
  
    
      
        μ
      
    
    {\displaystyle \mu }
   update of the covariance matrix and must not exceed 
  
    
      
        1
        −
        
          c
          
            1
          
        
      
    
    {\displaystyle 1-c_{1}}
  .The covariance matrix update tends to increase the likelihood for 
  
    
      
        
          p
          
            c
          
        
      
    
    {\displaystyle p_{c}}
   and for 
  
    
      
        (
        
          x
          
            i
            :
            λ
          
        
        −
        
          m
          
            k
          
        
        )
        
          /
        
        
          σ
          
            k
          
        
      
    
    {\displaystyle (x_{i:\lambda }-m_{k})/\sigma _{k}}
   to be sampled from 
  
    
      
        
          
            N
          
        
        (
        0
        ,
        
          C
          
            k
            +
            1
          
        
        )
      
    
    {\displaystyle {\mathcal {N}}(0,C_{k+1})}
  . This completes the iteration step.
The number of candidate samples per iteration, 
  
    
      
        λ
      
    
    {\displaystyle \lambda }
  , is not determined a priori and can vary in a wide range. Smaller values, for example 
  
    
      
        λ
        =
        10
      
    
    {\displaystyle \lambda =10}
  , lead to more local search behavior. Larger values, for example 
  
    
      
        λ
        =
        10
        n
      
    
    {\displaystyle \lambda =10n}
   with default value 
  
    
      
        
          μ
          
            w
          
        
        ≈
        λ
        
          /
        
        4
      
    
    {\displaystyle \mu _{w}\approx \lambda /4}
  , render the search more global. Sometimes the algorithm is repeatedly restarted with increasing 
  
    
      
        λ
      
    
    {\displaystyle \lambda }
   by a factor of two for each restart. Besides of setting 
  
    
      
        λ
      
    
    {\displaystyle \lambda }
   (or possibly 
  
    
      
        μ
      
    
    {\displaystyle \mu }
   instead, if for example 
  
    
      
        λ
      
    
    {\displaystyle \lambda }
   is predetermined by the number of available processors), the above introduced parameters are not specific to the given objective function and therefore not meant to be modified by the user.

Example code in MATLAB/Octave
Theoretical foundations
Given the distribution parameters—mean, variances and covariances—the normal probability distribution for sampling new candidate solutions is the maximum entropy probability distribution over 
  
    
      
        
          
            R
          
          
            n
          
        
      
    
    {\displaystyle \mathbb {R} ^{n}}
  , that is, the sample distribution with the minimal amount of prior information built into the distribution. More considerations on the update equations of CMA-ES are made in the following.

Variable metric
The CMA-ES implements a stochastic variable-metric method. In the very particular case of a convex-quadratic objective function

  
    
      
        f
        (
        x
        )
        =
        
          
            
              
                1
                2
              
            
          
        
        (
        x
        −
        
          x
          
            ∗
          
        
        
          )
          
            T
          
        
        H
        (
        x
        −
        
          x
          
            ∗
          
        
        )
      
    
    {\displaystyle f(x)={\textstyle {\frac {1}{2}}}(x-x^{*})^{T}H(x-x^{*})}
  the covariance matrix 
  
    
      
        
          C
          
            k
          
        
      
    
    {\displaystyle C_{k}}
   adapts to the inverse of the Hessian matrix 
  
    
      
        H
      
    
    {\displaystyle H}
  , up to a scalar factor and small random fluctuations. More general, also on the function 
  
    
      
        g
        ∘
        f
      
    
    {\displaystyle g\circ f}
  , where 
  
    
      
        g
      
    
    {\displaystyle g}
   is strictly increasing and therefore order preserving, the covariance matrix 
  
    
      
        
          C
          
            k
          
        
      
    
    {\displaystyle C_{k}}
   adapts to 
  
    
      
        
          H
          
            −
            1
          
        
      
    
    {\displaystyle H^{-1}}
  , up to a scalar factor and small random fluctuations. 
For selection ratio 
  
    
      
        λ
        
          /
        
        μ
        →
        ∞
      
    
    {\displaystyle \lambda /\mu \to \infty }
   (and hence population size 
  
    
      
        λ
        →
        ∞
      
    
    {\displaystyle \lambda \to \infty }
  ), the 
  
    
      
        μ
      
    
    {\displaystyle \mu }
   selected solutions yield an empirical covariance matrix reflective of the inverse-Hessian even in evolution strategies without adaptation of the covariance matrix. This result has been proven for 
  
    
      
        μ
        =
        1
      
    
    {\displaystyle \mu =1}
   on a static model, relying on the quadratic approximation.

Maximum-likelihood updates
The update equations for mean and covariance matrix maximize a likelihood while resembling an expectation-maximization algorithm. The update of the mean vector 
  
    
      
        m
      
    
    {\displaystyle m}
   maximizes a log-likelihood, such that

  
    
      
        
          m
          
            k
            +
            1
          
        
        =
        arg
        ⁡
        
          max
          
            m
          
        
        
          ∑
          
            i
            =
            1
          
          
            μ
          
        
        
          w
          
            i
          
        
        log
        ⁡
        
          p
          
            
              N
            
          
        
        (
        
          x
          
            i
            :
            λ
          
        
        ∣
        m
        )
      
    
    {\displaystyle m_{k+1}=\arg \max _{m}\sum _{i=1}^{\mu }w_{i}\log p_{\mathcal {N}}(x_{i:\lambda }\mid m)}
  where

  
    
      
        log
        ⁡
        
          p
          
            
              N
            
          
        
        (
        x
        )
        =
        −
        
          
            1
            2
          
        
        log
        ⁡
        det
        (
        2
        π
        C
        )
        −
        
          
            1
            2
          
        
        (
        x
        −
        m
        
          )
          
            T
          
        
        
          C
          
            −
            1
          
        
        (
        x
        −
        m
        )
      
    
    {\displaystyle \log p_{\mathcal {N}}(x)=-{\frac {1}{2}}\log \det(2\pi C)-{\frac {1}{2}}(x-m)^{T}C^{-1}(x-m)}
  denotes the log-likelihood of 
  
    
      
        x
      
    
    {\displaystyle x}
   from a multivariate normal distribution with mean 
  
    
      
        m
      
    
    {\displaystyle m}
   and any positive definite covariance matrix 
  
    
      
        C
      
    
    {\displaystyle C}
  . To see that 
  
    
      
        
          m
          
            k
            +
            1
          
        
      
    
    {\displaystyle m_{k+1}}
   is independent of 
  
    
      
        C
      
    
    {\displaystyle C}
   remark first that this is the case for any diagonal matrix 
  
    
      
        C
      
    
    {\displaystyle C}
  , because the coordinate-wise maximizer is independent of a scaling factor. Then, rotation of the data points or choosing 
  
    
      
        C
      
    
    {\displaystyle C}
   non-diagonal are equivalent.
The rank-
  
    
      
        μ
      
    
    {\displaystyle \mu }
   update of the covariance matrix, that is, the right most summand in the update equation of 
  
    
      
        
          C
          
            k
          
        
      
    
    {\displaystyle C_{k}}
  , maximizes a log-likelihood in that

  
    
      
        
          ∑
          
            i
            =
            1
          
          
            μ
          
        
        
          w
          
            i
          
        
        
          
            
              
                x
                
                  i
                  :
                  λ
                
              
              −
              
                m
                
                  k
                
              
            
            
              σ
              
                k
              
            
          
        
        
          
            (
            
              
                
                  
                    x
                    
                      i
                      :
                      λ
                    
                  
                  −
                  
                    m
                    
                      k
                    
                  
                
                
                  σ
                  
                    k
                  
                
              
            
            )
          
          
            T
          
        
        =
        arg
        ⁡
        
          max
          
            C
          
        
        
          ∑
          
            i
            =
            1
          
          
            μ
          
        
        
          w
          
            i
          
        
        log
        ⁡
        
          p
          
            
              N
            
          
        
        
          (
          
            
              
              
                
                  
                    
                      x
                      
                        i
                        :
                        λ
                      
                    
                    −
                    
                      m
                      
                        k
                      
                    
                  
                  
                    σ
                    
                      k
                    
                  
                
              
              |
            
            C
          
          )
        
      
    
    {\displaystyle \sum _{i=1}^{\mu }w_{i}{\frac {x_{i:\lambda }-m_{k}}{\sigma _{k}}}\left({\frac {x_{i:\lambda }-m_{k}}{\sigma _{k}}}\right)^{T}=\arg \max _{C}\sum _{i=1}^{\mu }w_{i}\log p_{\mathcal {N}}\left(\left.{\frac {x_{i:\lambda }-m_{k}}{\sigma _{k}}}\right|C\right)}
  for 
  
    
      
        μ
        ≥
        n
      
    
    {\displaystyle \mu \geq n}
   (otherwise 
  
    
      
        C
      
    
    {\displaystyle C}
   is singular, but substantially the same result holds for 
  
    
      
        μ
        <
        n
      
    
    {\displaystyle \mu <n}
  ). Here, 
  
    
      
        
          p
          
            
              N
            
          
        
        (
        x
        
          |
        
        C
        )
      
    
    {\displaystyle p_{\mathcal {N}}(x|C)}
   denotes the likelihood of 
  
    
      
        x
      
    
    {\displaystyle x}
   from a multivariate normal distribution with zero mean and covariance matrix 
  
    
      
        C
      
    
    {\displaystyle C}
  . Therefore, for 
  
    
      
        
          c
          
            1
          
        
        =
        0
      
    
    {\displaystyle c_{1}=0}
   and 
  
    
      
        
          c
          
            μ
          
        
        =
        1
      
    
    {\displaystyle c_{\mu }=1}
  , 
  
    
      
        
          C
          
            k
            +
            1
          
        
      
    
    {\displaystyle C_{k+1}}
   is the above maximum-likelihood estimator. See estimation of covariance matrices for details on the derivation.

Natural gradient descent in the space of sample distributions
Akimoto et al. and Glasmachers et al. discovered independently that the update of the distribution parameters resembles the descent in direction of a sampled natural gradient of the expected objective function value 
  
    
      
        E
        f
        (
        x
        )
      
    
    {\displaystyle Ef(x)}
   (to be minimized), where the expectation is taken under the sample distribution. With the parameter setting of 
  
    
      
        
          c
          
            σ
          
        
        =
        0
      
    
    {\displaystyle c_{\sigma }=0}
   and 
  
    
      
        
          c
          
            1
          
        
        =
        0
      
    
    {\displaystyle c_{1}=0}
  , i.e. without step-size control and rank-one update, CMA-ES can thus be viewed as an instantiation of Natural Evolution Strategies (NES).
The natural gradient is independent of the parameterization of the distribution. Taken with respect to the parameters θ of the sample distribution p, the gradient of 
  
    
      
        E
        f
        (
        x
        )
      
    
    {\displaystyle Ef(x)}
   can be expressed as

  
    
      
        
          
            
              
                
                  
                    ∇
                  
                  
                    
                    θ
                  
                
                E
                (
                f
                (
                x
                )
                ∣
                θ
                )
              
              
                
                =
                
                  ∇
                  
                    
                    θ
                  
                
                
                  ∫
                  
                    
                      
                        R
                      
                      
                        n
                      
                    
                  
                
                f
                (
                x
                )
                p
                (
                x
                )
                
                
                  d
                
                x
              
            
            
              
              
                
                =
                
                  ∫
                  
                    
                      
                        R
                      
                      
                        n
                      
                    
                  
                
                f
                (
                x
                )
                
                  ∇
                  
                    
                    θ
                  
                
                p
                (
                x
                )
                
                
                  d
                
                x
              
            
            
              
              
                
                =
                
                  ∫
                  
                    
                      
                        R
                      
                      
                        n
                      
                    
                  
                
                f
                (
                x
                )
                p
                (
                x
                )
                
                  ∇
                  
                    
                    θ
                  
                
                ln
                ⁡
                p
                (
                x
                )
                
                
                  d
                
                x
              
            
            
              
              
                
                =
                E
                ⁡
                (
                f
                (
                x
                )
                
                  ∇
                  
                    
                    θ
                  
                
                ln
                ⁡
                p
                (
                x
                ∣
                θ
                )
                )
              
            
          
        
      
    
    {\displaystyle {\begin{aligned}{\nabla }_{\!\theta }E(f(x)\mid \theta )&=\nabla _{\!\theta }\int _{\mathbb {R} ^{n}}f(x)p(x)\,\mathrm {d} x\\&=\int _{\mathbb {R} ^{n}}f(x)\nabla _{\!\theta }p(x)\,\mathrm {d} x\\&=\int _{\mathbb {R} ^{n}}f(x)p(x)\nabla _{\!\theta }\ln p(x)\,\mathrm {d} x\\&=\operatorname {E} (f(x)\nabla _{\!\theta }\ln p(x\mid \theta ))\end{aligned}}}
  where 
  
    
      
        p
        (
        x
        )
        =
        p
        (
        x
        ∣
        θ
        )
      
    
    {\displaystyle p(x)=p(x\mid \theta )}
   depends on the parameter vector 
  
    
      
        θ
      
    
    {\displaystyle \theta }
  . The so-called score function, 
  
    
      
        
          ∇
          
            
            θ
          
        
        ln
        ⁡
        p
        (
        x
        ∣
        θ
        )
        =
        
          
            
              
                ∇
                
                  
                  θ
                
              
              p
              (
              x
              )
            
            
              p
              (
              x
              )
            
          
        
      
    
    {\displaystyle \nabla _{\!\theta }\ln p(x\mid \theta )={\frac {\nabla _{\!\theta }p(x)}{p(x)}}}
  , indicates the relative sensitivity of p w.r.t. θ, and the expectation is taken with respect to the distribution p. The natural gradient of 
  
    
      
        E
        f
        (
        x
        )
      
    
    {\displaystyle Ef(x)}
  , complying with the Fisher information metric (an informational distance measure between probability distributions and the curvature of the relative entropy), now reads

  
    
      
        
          
            
              
                
                  
                    
                      ∇
                      ~
                    
                  
                
                E
                ⁡
                (
                f
                (
                x
                )
                ∣
                θ
                )
              
              
                
                =
                
                  F
                  
                    θ
                  
                  
                    −
                    1
                  
                
                
                  ∇
                  
                    
                    θ
                  
                
                E
                ⁡
                (
                f
                (
                x
                )
                ∣
                θ
                )
              
            
          
        
      
    
    {\displaystyle {\begin{aligned}{\tilde {\nabla }}\operatorname {E} (f(x)\mid \theta )&=F_{\theta }^{-1}\nabla _{\!\theta }\operatorname {E} (f(x)\mid \theta )\end{aligned}}}
  where the Fisher information matrix 
  
    
      
        
          F
          
            θ
          
        
      
    
    {\displaystyle F_{\theta }}
   is the expectation of the Hessian of −lnp and renders the expression independent of the chosen parameterization. Combining the previous equalities we get

  
    
      
        
          
            
              
                
                  
                    
                      ∇
                      ~
                    
                  
                
                E
                ⁡
                (
                f
                (
                x
                )
                ∣
                θ
                )
              
              
                
                =
                
                  F
                  
                    θ
                  
                  
                    −
                    1
                  
                
                E
                ⁡
                (
                f
                (
                x
                )
                
                  ∇
                  
                    
                    θ
                  
                
                ln
                ⁡
                p
                (
                x
                ∣
                θ
                )
                )
              
            
            
              
              
                
                =
                E
                ⁡
                (
                f
                (
                x
                )
                
                  F
                  
                    θ
                  
                  
                    −
                    1
                  
                
                
                  ∇
                  
                    
                    θ
                  
                
                ln
                ⁡
                p
                (
                x
                ∣
                θ
                )
                )
              
            
          
        
      
    
    {\displaystyle {\begin{aligned}{\tilde {\nabla }}\operatorname {E} (f(x)\mid \theta )&=F_{\theta }^{-1}\operatorname {E} (f(x)\nabla _{\!\theta }\ln p(x\mid \theta ))\\&=\operatorname {E} (f(x)F_{\theta }^{-1}\nabla _{\!\theta }\ln p(x\mid \theta ))\end{aligned}}}
  A Monte Carlo approximation of the latter expectation takes the average over λ samples from p

  
    
      
        
          
            
              ∇
              ~
            
          
        
        
          
            
              
                E
                ^
              
            
          
          
            θ
          
        
        (
        f
        )
        :=
        −
        
          ∑
          
            i
            =
            1
          
          
            λ
          
        
        
          
            
              
                w
                
                  i
                
              
              ⏞
            
          
          
            
            
            
            
            
              preference weight
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
          
        
        
          
            
              
                
                  F
                  
                    θ
                  
                  
                    −
                    1
                  
                
                
                  ∇
                  
                    
                    θ
                  
                
                ln
                ⁡
                p
                (
                
                  x
                  
                    i
                    :
                    λ
                  
                
                ∣
                θ
                )
              
              ⏟
            
          
          
            
            
            
            
            
            
              candidate direction from 
            
            
              x
              
                i
                :
                λ
              
            
            
            
            
            
            
          
        
        
        
          with 
        
        
          w
          
            i
          
        
        =
        −
        f
        (
        
          x
          
            i
            :
            λ
          
        
        )
        
          /
        
        λ
      
    
    {\displaystyle {\tilde {\nabla }}{\widehat {E}}_{\theta }(f):=-\sum _{i=1}^{\lambda }\overbrace {w_{i}} ^{\!\!\!\!{\text{preference weight}}\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!}\underbrace {F_{\theta }^{-1}\nabla _{\!\theta }\ln p(x_{i:\lambda }\mid \theta )} _{\!\!\!\!\!{\text{candidate direction from }}x_{i:\lambda }\!\!\!\!\!}\quad {\text{with }}w_{i}=-f(x_{i:\lambda })/\lambda }
  where the notation 
  
    
      
        i
        :
        λ
      
    
    {\displaystyle i:\lambda }
   from above is used and therefore 
  
    
      
        
          w
          
            i
          
        
      
    
    {\displaystyle w_{i}}
   are monotonically decreasing in 
  
    
      
        i
      
    
    {\displaystyle i}
  .
Ollivier et al.
finally found a rigorous derivation for the weights, 
  
    
      
        
          w
          
            i
          
        
      
    
    {\displaystyle w_{i}}
  , as they are defined in the CMA-ES. The weights are an asymptotically consistent estimator of the CDF of 
  
    
      
        f
        (
        X
        )
      
    
    {\displaystyle f(X)}
   at the points of the 
  
    
      
        i
      
    
    {\displaystyle i}
  th order statistic 
  
    
      
        f
        (
        
          x
          
            i
            :
            λ
          
        
        )
      
    
    {\displaystyle f(x_{i:\lambda })}
  , as defined above, where 
  
    
      
        X
        ∼
        p
        (
        .
        
          |
        
        θ
        )
      
    
    {\displaystyle X\sim p(.|\theta )}
  , composed with a fixed monotonically decreasing transformation 
  
    
      
        w
      
    
    {\displaystyle w}
  , that is,

  
    
      
        
          w
          
            i
          
        
        =
        w
        
          (
          
            
              
                
                  
                    r
                    a
                    n
                    k
                  
                
                (
                f
                (
                
                  x
                  
                    i
                    :
                    λ
                  
                
                )
                )
                −
                1
                
                  /
                
                2
              
              λ
            
          
          )
        
      
    
    {\displaystyle w_{i}=w\left({\frac {{\mathsf {rank}}(f(x_{i:\lambda }))-1/2}{\lambda }}\right)}
  .These weights make the algorithm insensitive to the specific 
  
    
      
        f
      
    
    {\displaystyle f}
  -values. More concisely, using the CDF estimator of 
  
    
      
        f
      
    
    {\displaystyle f}
   instead of 
  
    
      
        f
      
    
    {\displaystyle f}
   itself let the algorithm only depend on the ranking of 
  
    
      
        f
      
    
    {\displaystyle f}
  -values but not on their underlying distribution. This renders the algorithm invariant to strictly increasing 
  
    
      
        f
      
    
    {\displaystyle f}
  -transformations. Now we define

  
    
      
        θ
        =
        [
        
          m
          
            k
          
          
            T
          
        
        vec
        ⁡
        (
        
          C
          
            k
          
        
        
          )
          
            T
          
        
        
          σ
          
            k
          
        
        
          ]
          
            T
          
        
        ∈
        
          
            R
          
          
            n
            +
            
              n
              
                2
              
            
            +
            1
          
        
      
    
    {\displaystyle \theta =[m_{k}^{T}\operatorname {vec} (C_{k})^{T}\sigma _{k}]^{T}\in \mathbb {R} ^{n+n^{2}+1}}
  such that 
  
    
      
        p
        (
        ⋅
        ∣
        θ
        )
      
    
    {\displaystyle p(\cdot \mid \theta )}
   is the density of the multivariate normal distribution 
  
    
      
        
          
            N
          
        
        (
        
          m
          
            k
          
        
        ,
        
          σ
          
            k
          
          
            2
          
        
        
          C
          
            k
          
        
        )
      
    
    {\displaystyle {\mathcal {N}}(m_{k},\sigma _{k}^{2}C_{k})}
  . Then, we have an explicit expression for the inverse of the Fisher information matrix where 
  
    
      
        
          σ
          
            k
          
        
      
    
    {\displaystyle \sigma _{k}}
   is fixed

  
    
      
        
          F
          
            θ
            ∣
            
              σ
              
                k
              
            
          
          
            −
            1
          
        
        =
        
          [
          
            
              
                
                  
                    σ
                    
                      k
                    
                    
                      2
                    
                  
                  
                    C
                    
                      k
                    
                  
                
                
                  0
                
              
              
                
                  0
                
                
                  2
                  
                    C
                    
                      k
                    
                  
                  ⊗
                  
                    C
                    
                      k
                    
                  
                
              
            
          
          ]
        
      
    
    {\displaystyle F_{\theta \mid \sigma _{k}}^{-1}=\left[{\begin{array}{cc}\sigma _{k}^{2}C_{k}&0\\0&2C_{k}\otimes C_{k}\end{array}}\right]}
  and for

  
    
      
        ln
        ⁡
        p
        (
        x
        ∣
        θ
        )
        =
        ln
        ⁡
        p
        (
        x
        ∣
        
          m
          
            k
          
        
        ,
        
          σ
          
            k
          
          
            2
          
        
        
          C
          
            k
          
        
        )
        =
        −
        
          
            1
            2
          
        
        (
        x
        −
        
          m
          
            k
          
        
        
          )
          
            T
          
        
        
          σ
          
            k
          
          
            −
            2
          
        
        
          C
          
            k
          
          
            −
            1
          
        
        (
        x
        −
        
          m
          
            k
          
        
        )
        −
        
          
            1
            2
          
        
        ln
        ⁡
        det
        (
        2
        π
        
          σ
          
            k
          
          
            2
          
        
        
          C
          
            k
          
        
        )
      
    
    {\displaystyle \ln p(x\mid \theta )=\ln p(x\mid m_{k},\sigma _{k}^{2}C_{k})=-{\frac {1}{2}}(x-m_{k})^{T}\sigma _{k}^{-2}C_{k}^{-1}(x-m_{k})-{\frac {1}{2}}\ln \det(2\pi \sigma _{k}^{2}C_{k})}
  and, after some calculations, the updates in the CMA-ES turn out as

where mat forms the proper matrix from the respective natural gradient sub-vector. That means, setting 
  
    
      
        
          c
          
            1
          
        
        =
        
          c
          
            σ
          
        
        =
        0
      
    
    {\displaystyle c_{1}=c_{\sigma }=0}
  , the CMA-ES updates descend in direction of the approximation 
  
    
      
        
          
            
              ∇
              ~
            
          
        
        
          
            
              
                E
                ^
              
            
          
          
            θ
          
        
        (
        f
        )
      
    
    {\displaystyle {\tilde {\nabla }}{\widehat {E}}_{\theta }(f)}
   of the natural gradient while using different step-sizes (learning rates 1 and 
  
    
      
        
          c
          
            μ
          
        
      
    
    {\displaystyle c_{\mu }}
  ) for the orthogonal parameters 
  
    
      
        m
      
    
    {\displaystyle m}
   and 
  
    
      
        C
      
    
    {\displaystyle C}
   respectively. More recent versions allow a different learning rate for the mean 
  
    
      
        m
      
    
    {\displaystyle m}
   as well. The most recent version of CMA-ES also use a different function 
  
    
      
        w
      
    
    {\displaystyle w}
   for 
  
    
      
        m
      
    
    {\displaystyle m}
   and 
  
    
      
        C
      
    
    {\displaystyle C}
   with negative values only for the latter (so-called active CMA).

Stationarity or unbiasedness
It is comparatively easy to see that the update equations of CMA-ES satisfy some stationarity conditions, in that they are essentially unbiased. Under neutral selection, where 
  
    
      
        
          x
          
            i
            :
            λ
          
        
        ∼
        
          
            N
          
        
        (
        
          m
          
            k
          
        
        ,
        
          σ
          
            k
          
          
            2
          
        
        
          C
          
            k
          
        
        )
      
    
    {\displaystyle x_{i:\lambda }\sim {\mathcal {N}}(m_{k},\sigma _{k}^{2}C_{k})}
  ,  we find that

  
    
      
        E
        ⁡
        (
        
          m
          
            k
            +
            1
          
        
        ∣
        
          m
          
            k
          
        
        )
        =
        
          m
          
            k
          
        
      
    
    {\displaystyle \operatorname {E} (m_{k+1}\mid m_{k})=m_{k}}
  and under some mild additional assumptions on the initial conditions

  
    
      
        E
        ⁡
        (
        log
        ⁡
        
          σ
          
            k
            +
            1
          
        
        ∣
        
          σ
          
            k
          
        
        )
        =
        log
        ⁡
        
          σ
          
            k
          
        
      
    
    {\displaystyle \operatorname {E} (\log \sigma _{k+1}\mid \sigma _{k})=\log \sigma _{k}}
  and with an additional minor correction in the covariance matrix update for the case where the indicator function evaluates to zero, we find

  
    
      
        E
        ⁡
        (
        
          C
          
            k
            +
            1
          
        
        ∣
        
          C
          
            k
          
        
        )
        =
        
          C
          
            k
          
        
      
    
    {\displaystyle \operatorname {E} (C_{k+1}\mid C_{k})=C_{k}}

Invariance
Invariance properties imply uniform performance on a class of objective functions. They have been argued to be an advantage, because they allow to generalize and predict the behavior of the algorithm and therefore strengthen the meaning of empirical results obtained on single functions. The following invariance properties have been established for CMA-ES.

Invariance under order-preserving transformations of the objective function value 
  
    
      
        f
      
    
    {\displaystyle f}
  , in that for any 
  
    
      
        h
        :
        
          
            R
          
          
            n
          
        
        →
        
          R
        
      
    
    {\displaystyle h:\mathbb {R} ^{n}\to \mathbb {R} }
   the behavior is identical on 
  
    
      
        f
        :
        x
        ↦
        g
        (
        h
        (
        x
        )
        )
      
    
    {\displaystyle f:x\mapsto g(h(x))}
   for all strictly increasing 
  
    
      
        g
        :
        
          R
        
        →
        
          R
        
      
    
    {\displaystyle g:\mathbb {R} \to \mathbb {R} }
  . This invariance is easy to verify, because only the 
  
    
      
        f
      
    
    {\displaystyle f}
  -ranking is used in the algorithm, which is invariant under the choice of 
  
    
      
        g
      
    
    {\displaystyle g}
  .
Scale-invariance, in that for any 
  
    
      
        h
        :
        
          
            R
          
          
            n
          
        
        →
        
          R
        
      
    
    {\displaystyle h:\mathbb {R} ^{n}\to \mathbb {R} }
   the behavior is independent of 
  
    
      
        α
        >
        0
      
    
    {\displaystyle \alpha >0}
   for the objective function 
  
    
      
        f
        :
        x
        ↦
        h
        (
        α
        x
        )
      
    
    {\displaystyle f:x\mapsto h(\alpha x)}
   given 
  
    
      
        
          σ
          
            0
          
        
        ∝
        1
        
          /
        
        α
      
    
    {\displaystyle \sigma _{0}\propto 1/\alpha }
   and 
  
    
      
        
          m
          
            0
          
        
        ∝
        1
        
          /
        
        α
      
    
    {\displaystyle m_{0}\propto 1/\alpha }
  .
Invariance under rotation of the search space in that for any 
  
    
      
        h
        :
        
          
            R
          
          
            n
          
        
        →
        
          R
        
      
    
    {\displaystyle h:\mathbb {R} ^{n}\to \mathbb {R} }
   and any 
  
    
      
        z
        ∈
        
          
            R
          
          
            n
          
        
      
    
    {\displaystyle z\in \mathbb {R} ^{n}}
   the behavior on 
  
    
      
        f
        :
        x
        ↦
        h
        (
        R
        x
        )
      
    
    {\displaystyle f:x\mapsto h(Rx)}
    is independent of the orthogonal matrix 
  
    
      
        R
      
    
    {\displaystyle R}
  , given 
  
    
      
        
          m
          
            0
          
        
        =
        
          R
          
            −
            1
          
        
        z
      
    
    {\displaystyle m_{0}=R^{-1}z}
  . More general, the algorithm is also invariant under general linear transformations 
  
    
      
        R
      
    
    {\displaystyle R}
   when additionally the initial covariance matrix is chosen as 
  
    
      
        
          R
          
            −
            1
          
        
        
          
            
              R
              
                −
                1
              
            
          
          
            T
          
        
      
    
    {\displaystyle R^{-1}{R^{-1}}^{T}}
  .Any serious parameter optimization method should be translation invariant, but most methods do not exhibit all the above described invariance properties. A prominent example with the same invariance properties is the Nelder–Mead method, where the initial simplex must be chosen respectively.

Convergence
Conceptual considerations like the scale-invariance property of the algorithm, the analysis of simpler evolution strategies, and overwhelming empirical evidence suggest that the algorithm converges on a large class of functions fast to the global optimum, denoted as 
  
    
      
        
          x
          
            ∗
          
        
      
    
    {\displaystyle x^{*}}
  . On some functions, convergence occurs independently of the initial conditions with probability one. On some functions the probability is smaller than one and typically depends on the initial 
  
    
      
        
          m
          
            0
          
        
      
    
    {\displaystyle m_{0}}
   and 
  
    
      
        
          σ
          
            0
          
        
      
    
    {\displaystyle \sigma _{0}}
  . Empirically, the fastest possible convergence rate in 
  
    
      
        k
      
    
    {\displaystyle k}
   for rank-based direct search methods can often be observed (depending on the context denoted as linear or log-linear or exponential convergence). Informally, we can write

  
    
      
        ‖
        
          m
          
            k
          
        
        −
        
          x
          
            ∗
          
        
        ‖
        
        ≈
        
        ‖
        
          m
          
            0
          
        
        −
        
          x
          
            ∗
          
        
        ‖
        ×
        
          e
          
            −
            c
            k
          
        
      
    
    {\displaystyle \|m_{k}-x^{*}\|\;\approx \;\|m_{0}-x^{*}\|\times e^{-ck}}
  for some 
  
    
      
        c
        >
        0
      
    
    {\displaystyle c>0}
  , and more rigorously

  
    
      
        
          
            1
            k
          
        
        
          ∑
          
            i
            =
            1
          
          
            k
          
        
        log
        ⁡
        
          
            
              ‖
              
                m
                
                  i
                
              
              −
              
                x
                
                  ∗
                
              
              ‖
            
            
              ‖
              
                m
                
                  i
                  −
                  1
                
              
              −
              
                x
                
                  ∗
                
              
              ‖
            
          
        
        
        =
        
        
          
            1
            k
          
        
        log
        ⁡
        
          
            
              ‖
              
                m
                
                  k
                
              
              −
              
                x
                
                  ∗
                
              
              ‖
            
            
              ‖
              
                m
                
                  0
                
              
              −
              
                x
                
                  ∗
                
              
              ‖
            
          
        
        
        →
        
        −
        c
        <
        0
        
        
          for 
        
        k
        →
        ∞
        
        ,
      
    
    {\displaystyle {\frac {1}{k}}\sum _{i=1}^{k}\log {\frac {\|m_{i}-x^{*}\|}{\|m_{i-1}-x^{*}\|}}\;=\;{\frac {1}{k}}\log {\frac {\|m_{k}-x^{*}\|}{\|m_{0}-x^{*}\|}}\;\to \;-c<0\quad {\text{for }}k\to \infty \;,}
  or similarly,

  
    
      
        E
        ⁡
        log
        ⁡
        
          
            
              ‖
              
                m
                
                  k
                
              
              −
              
                x
                
                  ∗
                
              
              ‖
            
            
              ‖
              
                m
                
                  k
                  −
                  1
                
              
              −
              
                x
                
                  ∗
                
              
              ‖
            
          
        
        
        →
        
        −
        c
        <
        0
        
        
          for 
        
        k
        →
        ∞
        
        .
      
    
    {\displaystyle \operatorname {E} \log {\frac {\|m_{k}-x^{*}\|}{\|m_{k-1}-x^{*}\|}}\;\to \;-c<0\quad {\text{for }}k\to \infty \;.}
  This means that on average the distance to the optimum decreases in each iteration by a "constant" factor, namely by 
  
    
      
        exp
        ⁡
        (
        −
        c
        )
      
    
    {\displaystyle \exp(-c)}
  . The convergence rate 
  
    
      
        c
      
    
    {\displaystyle c}
   is roughly 
  
    
      
        0.1
        λ
        
          /
        
        n
      
    
    {\displaystyle 0.1\lambda /n}
  , given 
  
    
      
        λ
      
    
    {\displaystyle \lambda }
   is not much larger than the dimension 
  
    
      
        n
      
    
    {\displaystyle n}
  . Even with optimal 
  
    
      
        σ
      
    
    {\displaystyle \sigma }
   and 
  
    
      
        C
      
    
    {\displaystyle C}
  , the convergence rate 
  
    
      
        c
      
    
    {\displaystyle c}
    cannot largely exceed 
  
    
      
        0.25
        λ
        
          /
        
        n
      
    
    {\displaystyle 0.25\lambda /n}
  , given the above recombination weights 
  
    
      
        
          w
          
            i
          
        
      
    
    {\displaystyle w_{i}}
   are all non-negative. The actual linear dependencies in 
  
    
      
        λ
      
    
    {\displaystyle \lambda }
   and 
  
    
      
        n
      
    
    {\displaystyle n}
   are remarkable and they are in both cases the best one can hope for in this kind of algorithm. Yet, a rigorous proof of convergence is missing.

Interpretation as coordinate-system transformation
Using a non-identity covariance matrix for the multivariate normal distribution in evolution strategies is equivalent to a coordinate system transformation of the solution vectors, mainly because the sampling equation

  
    
      
        
          
            
              
                
                  x
                  
                    i
                  
                
              
              
                
                ∼
                 
                
                  m
                  
                    k
                  
                
                +
                
                  σ
                  
                    k
                  
                
                ×
                
                  
                    N
                  
                
                (
                0
                ,
                
                  C
                  
                    k
                  
                
                )
              
            
            
              
              
                
                ∼
                 
                
                  m
                  
                    k
                  
                
                +
                
                  σ
                  
                    k
                  
                
                ×
                
                  C
                  
                    k
                  
                  
                    1
                    
                      /
                    
                    2
                  
                
                
                  
                    N
                  
                
                (
                0
                ,
                I
                )
              
            
          
        
      
    
    {\displaystyle {\begin{aligned}x_{i}&\sim \ m_{k}+\sigma _{k}\times {\mathcal {N}}(0,C_{k})\\&\sim \ m_{k}+\sigma _{k}\times C_{k}^{1/2}{\mathcal {N}}(0,I)\end{aligned}}}
  can be equivalently expressed in an "encoded space" as 

  
    
      
        
          
            
              
                
                  C
                  
                    k
                  
                  
                    −
                    1
                    
                      /
                    
                    2
                  
                
                
                  x
                  
                    i
                  
                
              
              ⏟
            
          
          
            
              represented in the encode space
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
          
        
        ∼
         
        
          
            
              
                C
                
                  k
                
                
                  −
                  1
                  
                    /
                  
                  2
                
              
              
                m
                
                  k
                
              
            
            ⏟
          
        
        

        
        +
        
          σ
          
            k
          
        
        ×
        
          
            N
          
        
        (
        0
        ,
        I
        )
      
    
    {\displaystyle \underbrace {C_{k}^{-1/2}x_{i}} _{{\text{represented in the encode space}}\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!}\sim \ \underbrace {C_{k}^{-1/2}m_{k}} {}+\sigma _{k}\times {\mathcal {N}}(0,I)}
  The covariance matrix defines a bijective transformation (encoding) for all solution vectors into a space, where the sampling takes place with identity covariance matrix. Because the update equations in the CMA-ES are invariant under linear coordinate system transformations, the CMA-ES can be re-written as an adaptive encoding procedure applied to a simple evolution strategy with identity covariance matrix.
This adaptive encoding procedure is not confined to algorithms that sample from a multivariate normal distribution (like evolution strategies), but can in principle be applied to any iterative search method.

Performance in practice
In contrast to most other evolutionary algorithms, the CMA-ES is, from the user's perspective, quasi-parameter-free. The user has to choose an initial solution point, 
  
    
      
        
          m
          
            0
          
        
        ∈
        
          
            R
          
          
            n
          
        
      
    
    {\displaystyle m_{0}\in \mathbb {R} ^{n}}
  , and the initial step-size, 
  
    
      
        
          σ
          
            0
          
        
        >
        0
      
    
    {\displaystyle \sigma _{0}>0}
  . Optionally, the number of candidate samples λ (population size) can be modified by the user in order to change the characteristic search behavior (see above) and termination conditions can or should be adjusted to the problem at hand.
The CMA-ES has been empirically successful in hundreds of applications and is considered to be useful in particular on non-convex, non-separable, ill-conditioned, multi-modal or noisy objective functions. One survey of Black-Box optimizations found it outranked 31 other optimization algorithms, performing especially strongly on "difficult functions" or larger-dimensional search spaces.The search space dimension ranges typically between two and a few hundred. Assuming a black-box optimization scenario, where gradients are not available (or not useful) and function evaluations are the only considered cost of search, the CMA-ES method is likely to be outperformed by other methods in the following conditions:

on low-dimensional functions, say 
  
    
      
        n
        <
        5
      
    
    {\displaystyle n<5}
  , for example by the downhill simplex method or surrogate-based methods (like kriging with expected improvement);
on separable functions without or with only negligible dependencies between the design variables in particular in the case of multi-modality or large dimension, for example by differential evolution;
on (nearly) convex-quadratic functions with low or moderate condition number of the Hessian matrix, where BFGS or NEWUOA or SLSQP are typically at least ten times faster;
on functions that can already be solved with a comparatively small number of function evaluations, say no more than 
  
    
      
        10
        n
      
    
    {\displaystyle 10n}
  , where CMA-ES is often slower than, for example, NEWUOA or Multilevel Coordinate Search (MCS).On separable functions, the performance disadvantage is likely to be most significant in that CMA-ES might not be able to find at all comparable solutions. On the other hand, on non-separable functions that are ill-conditioned or rugged or can only be solved with more than 
  
    
      
        100
        n
      
    
    {\displaystyle 100n}
   function evaluations, the CMA-ES shows most often superior performance.

Variations and extensions
The (1+1)-CMA-ES generates only one candidate solution per iteration step which becomes the new distribution mean if it is better than the current mean. For 
  
    
      
        
          c
          
            c
          
        
        =
        1
      
    
    {\displaystyle c_{c}=1}
   the (1+1)-CMA-ES is a close variant of Gaussian adaptation. Some Natural Evolution Strategies are close variants of the CMA-ES with specific parameter settings. Natural Evolution Strategies do not utilize evolution paths (that means in CMA-ES setting 
  
    
      
        
          c
          
            c
          
        
        =
        
          c
          
            σ
          
        
        =
        1
      
    
    {\displaystyle c_{c}=c_{\sigma }=1}
  ) and they formalize the update of variances and covariances on a Cholesky factor instead of a covariance matrix. The CMA-ES has also been extended to multiobjective optimization as MO-CMA-ES. Another remarkable extension has been the addition of a negative update of the covariance matrix with the so-called active CMA.
Using the additional active CMA update is considered as the default variant nowadays.

See also
Global optimization
Stochastic optimization
Derivative-free optimization
Estimation of distribution algorithm

References
Bibliography
Hansen N, Ostermeier A (2001). Completely derandomized self-adaptation in evolution strategies. Evolutionary Computation, 9(2) pp. 159–195. [1]
Hansen N, Müller SD, Koumoutsakos P (2003). Reducing the time complexity of the derandomized evolution strategy with covariance matrix adaptation (CMA-ES). Evolutionary Computation, 11(1) pp. 1–18.  [2]
Hansen N, Kern S (2004). Evaluating the CMA evolution strategy on multimodal test functions. In Xin Yao et al., editors, Parallel Problem Solving from Nature – PPSN VIII, pp. 282–291, Springer. [3]
Igel C, Hansen N, Roth S (2007). Covariance Matrix Adaptation for Multi-objective Optimization. Evolutionary Computation, 15(1) pp. 1–28. [4]

External links
A short introduction to CMA-ES by N. Hansen
The CMA Evolution Strategy: A Tutorial
CMA-ES source code page