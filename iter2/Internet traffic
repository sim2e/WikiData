Internet traffic is the flow of data within the entire Internet, or in certain network links of its constituent networks. Common traffic measurements are total volume, in units of multiples of the byte, or as transmission rates in bytes per certain time units.
As the topology of the Internet is not hierarchical, no single point of measurement is possible for total Internet traffic. Traffic data may be obtained from the Tier 1 network providers' peering points for indications of volume and growth. However, Such data excludes traffic that remains within a single service provider's network and traffic that crosses private peering points.
As of December 2022 almost half (48%) of Internet traffic is in India and China, while North America and Europe have about a quarter of global internet traffic.

Traffic sources
File sharing constitutes a fraction of Internet traffic. The prevalent technology for file sharing is the BitTorrent protocol, which is a peer-to-peer (P2P) system mediated through indexing sites that provide resource directories. According to a Sandvine Research in 2013, Bit Torrent's share of Internet traffic decreased by 20% to 7.4% overall, reduced from 31% in 2008. As of 2023, roughly 65% of all internet traffic came from video sites, up from 51% in 2016.In 2022, roughly 47% of all traffic was estimated to be from automated bots.

Traffic management
Internet traffic management, also known as application traffic management.
The Internet does not employ any formally centralized facilities for traffic management. Its progenitor networks, especially the ARPANET established an early backbone infrastructure which carried traffic between major interchange centers for traffic, resulting in a tiered, hierarchical system of internet service providers (ISPs) within which the tier 1 networks provided traffic exchange through settlement-free peering and routing of traffic to lower-level tiers of ISPs.  The dynamic growth of the worldwide network resulted in ever-increasing interconnections at all peering levels of the Internet, so a robust system was developed that could mediate link failures, bottlenecks, and other congestion at many levels.Economic traffic management (ETM) is the term that is sometimes used to point out the opportunities for seeding as a practice that caters to contribution within peer-to-peer file sharing and the distribution of content in the digital world in general.

Internet use tax
A planned tax on Internet use in Hungary introduced a 150-forint (US$0.62, €0.47) tax per gigabyte of data traffic, in a move intended to reduce Internet traffic and also assist companies to offset corporate income tax against the new levy.  Hungary achieved 1.15 billion gigabytes in 2013 and another 18 million gigabytes accumulated by mobile devices. This would have resulted in extra revenue of 175 billion forints under the new tax based on the consultancy firm eNet.According to Yahoo News, economy minister Mihály Varga defended the move saying "the tax was fair as it reflected a shift by consumers to the Internet away from phone lines" and that "150 forints on each transferred gigabyte of data – was needed to plug holes in the 2015 budget of one of the EU's most indebted nations".Some people argue that the new plan on Internet tax would prove disadvantageous to the country's economic development, limit access to information and hinder the freedom of expression. Approximately 36,000 people have signed up to take part in an event on Facebook to be held outside the Economy Ministry to protest against the possible tax.

Traffic classification
Traffic classification describes the methods of classifying traffic by observing features passively in the traffic and line with particular classification goals. There might be some that only have a vulgar classification goal. For example, whether it is bulk transfer, peer-to-peer file-sharing, or transaction-orientated. Some others will set a finer-grained classification goal, for instance, the exact number of applications represented by the traffic. Traffic features included port number, application payload, temporal, packet size, and the characteristic of the traffic. There is a vast range of methods to allocate Internet traffic including exact traffic, for instance, port (computer networking) number, payload, heuristic, or statistical machine learning.
Accurate network traffic classification is elementary to quite a few Internet activities, from security monitoring to accounting and from the quality of service to providing operators with useful forecasts for long-term provisioning. Yet, classification schemes are extremely complex to operate accurately due to the shortage of available knowledge of the network. For example, the packet header-related information is always insufficient to allow for a precise methodology.

Bayesian analysis techniques
Work involving supervised machine learning to classify network traffic. Data are hand-classified (based upon flow content) to one of a number of categories. A combination of data set (hand-assigned) category and descriptions of the classified flows (such as flow length, port numbers, time between consecutive flows) are used to train the classifier. To give a better insight of the technique itself, initial assumptions are made as well as applying two other techniques in reality. One is to improve the quality and separation of the input of information leading to an increase in accuracy of the Naive Bayes classifier technique.
The basis of categorizing work is to classify the type of Internet traffic; this is done by putting common groups of applications into different categories, e.g., "normal" versus "malicious", or more complex definitions, e.g., the identification of specific applications or specific Transmission Control Protocol (TCP) implementations. Adapted from Logg et al.

Survey
Traffic classification is a major component of automated intrusion detection systems. They are used to identify patterns as well as an indication of network resources for priority customers, or to identify customer use of network resources that in some way contravenes the operator's terms of service.
Generally deployed Internet Protocol (IP) traffic classification techniques are based approximately on a direct inspection of each packet's contents at some point on the network. Source address, port and destination address are included in successive IP packets with similar if not the same 5-tuple of protocol type. ort are considered to belong to a flow whose controlling application we wish to determine. Simple classification infers the controlling application's identity by assuming that most applications consistently use well-known TCP or UDP port numbers. Even though, many candidates are increasingly using unpredictable port numbers. As a result, more sophisticated classification techniques infer application types by looking for application-specific data within the TCP or User Datagram Protocol (UDP) payloads.

Global Internet traffic
Aggregating from multiple sources and applying usage and bitrate assumptions, Cisco Systems, a major network systems company, has published the following historical Internet Protocol (IP) and Internet traffic figures:
"Fixed Internet traffic" refers perhaps to traffic from residential and commercial subscribers to ISPs, cable companies, and other service providers. "Mobile Internet traffic" refers perhaps to backhaul traffic from cellphone towers and providers. The overall "Internet traffic" figures, which can be 30% higher than the sum of the other two, perhaps factors in traffic in the core of the national backbone, whereas the other figures seem to be derived principally from the network periphery.
Cisco also publishes 5-year projections.

Internet backbone traffic in the United States
The following data for the Internet backbone in the US comes from the Minnesota Internet Traffic Studies (MINTS):
The Cisco data can be seven times higher than the Minnesota Internet Traffic Studies (MINTS) data not only because the Cisco figures are estimates for the global—not just the domestic US—Internet, but also because Cisco counts "general IP traffic (thus including closed networks that are not truly part of the Internet, but use IP, the Internet Protocol, such as the IPTV services of various telecom firms)".  The MINTS estimate of US national backbone traffic for 2004, which may be interpolated as 200 petabytes/month, is a plausible three-fold multiple of the traffic of the US's largest backbone carrier, Level(3) Inc., which claims an average traffic level of 60 petabytes/month.

Edholm's law
Internet bandwidth in telecommunication networks has been doubling every 18 months, an observation expressed as Edholm's law. This follows the advances in semiconductor technology, such as metal-oxide-silicon (MOS) scaling, exemplified by the MOSFET transistor, which has shown similar scaling described by Moore's law. In the 1980s, fiber-optical technology using laser light as information carriers accelerated the transmission speed and bandwidth of telecommunication circuits. This has led to the bandwidths of communication networks achieving terabit per second transmission speeds.

See also
ETOMIC
Internet rush hour
Web traffic
Zettabyte Era
Traffic flow

References
Further reading
Williamson, Carey (2001). "Internet Traffic Measurement". IEEE Internet Computing. 5 (6): 70–74. doi:10.1109/4236.968834.

External links
"The Size and Growth Rate of the Internet", K.G. Coffman and Andrew Odlyzki, First Monday, Volume 3, Number 5, October 1998
Internet Traffic Report from AnalogX
Internet Health Report from Keynote Systems
Cooperative Association for Internet Data Analysis Archived 2014-05-14 at the Wayback Machine (CAIDA), based at the University of California, San Diego Supercomputer Center