The Artificial Intelligence Act (AI Act) is a proposed regulation of the European Union. Proposed by the European Commission on 21 April 2021, it aims to introduce a common regulatory and legal framework for artificial intelligence. Its scope encompasses all sectors (except for military), and to all types of artificial intelligence. As a piece of product regulation, it would not confer rights on individuals, but would regulate the providers of artificial intelligence systems, and entities making use of them in a professional capacity.
The proposed EU Artificial Intelligence Act aims to classify and regulate artificial intelligence applications based on their risk to cause harm. This classification primarily falls into three categories: banned practices, high-risk systems, and other AI systems.Banned practices are those that employ artificial intelligence to cause subliminal manipulation or exploit people's vulnerabilities that may result in physical or psychological harm, make indiscriminate use of real-time remote biometric identification in public spaces for law enforcement, or use AI-derived 'social scores' by authorities to unfairly disadvantage individuals or groups. The Act entirely prohibits the latter, while an authorisation regime is proposed for the first three in the context of law enforcement.High-risk systems, as per the Act, are those that pose significant threats to health, safety, or the fundamental rights of persons. They require a compulsory conformity assessment, undertaken as self-assessment by the provider, before being launched in the market. Particularly critical applications, such as those for medical devices, require the provider's self-assessment under AI Act requirements to be considered by the notified body conducting the assessment under existing EU regulations, like the Medical Devices Regulation.
AI systems outside the categories above are not subject to any regulation, with Member States largely prevented from further regulating them via maximum harmonisation. Existing national laws related to the design or use of such systems are disapplied. However, a voluntary code of conduct for such systems is envisaged, though not from the outset.The Act further proposes the introduction of a European Artificial Intelligence Board to promote national cooperation and ensure compliance with the regulation.Like the European Union's General Data Protection Regulation, the AI Act could become a global standard. It is already having impact beyond Europe; in September 2021, Brazil's Congress passed a bill that creates a legal framework for artificial intelligence. The European Council adopted its general approach on the AI Act on 6 December 2022. Germany supports the Council's position but still sees some need for further improvement as formulated in an accompanying statement by the member state. Among the measures likely to be proposed is for AI developers for products such as Open AI's ChatGPT to declare whether copyrighted material was used to train their technology.

Enforcement
The Act regulates the entry to the EU internal market. To this extent it uses the New Legislative Framework, which can be traced back to the New Approach which dates back to 1985. How this works is as follows: The EU legislator creates the AI-act, this Act contains the most important provisions that all AI-systems that want access to the EU internal market will have to comply with. These requirements are called 'essential requirements'. Under the New Legislative Framework, these essential requirements are passed on to European Standardisation Organisations who draw up technical standards that further specify the essential requirements.
As mentioned above, the Act requires Member States to set up their own notifying bodies. To check whether AI-systems are indeed conform the standards as set out in the AI-Act conformity assessment takes place. This conformity assessment is either done by self-assessment, which means that the provider of the AI-system checks for conformity themselves, or this is done through third party conformity assessment which means that the notifying body will carry out the assessment. Notifying bodies do retain the possibility to carry out audits to check whether conformity assessment is carried out properly.Under the current proposal it seems to be the case that many high-risk AI-systems do not require third party conformity assessment which is critiqued by some. These critiques are based on the fact that high-risk AI-systems should be assessed by an independent third party to fully secure its safety.

See also
Ethics of artificial intelligence
Regulation of algorithms
Regulation of artificial intelligence
Algorithmic bias

References
External links
Proposal for a Regulation of the European Parliament and of the Council Laying Down Harmonised Rules on Artificial Intelligence (Artificial Intelligence Act) on EUR-Lex
Procedure 2021/0106/COD on EUR-Lex
Procedure 2021/0106(COD) on Å’IL